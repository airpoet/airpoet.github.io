<!DOCTYPE html>




<html class="theme-next pisces" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">


  <link rel="manifest" href="/images/manifest.json">


  <meta name="msapplication-config" content="/images/browserconfig.xml" />



  <meta name="keywords" content="原创,技术,Spark," />





  <link rel="alternate" href="/atom.xml" title="A.P的文艺杂谈" type="application/atom+xml" />






<meta name="description" content="一. Spark 与 MapReduce 区别Apache Spark™ is a fast and general engine for large-scale data processing. 与mapreduce比较 ：  Spark大多数执行过程是基于内存的迭代  MapReduce 的 优点, SparkCore 都有  Hive 能做的操作, SparkSQL 都能做, 可以写 SQL">
<meta name="keywords" content="原创,技术,Spark">
<meta property="og:type" content="article">
<meta property="og:title" content="Spark重点解析(一) =&gt; SparkCore">
<meta property="og:url" content="https://airpoet.github.io/2018/07/25/Spark/Spark重点解析(一) => SparkCore/index.html">
<meta property="og:site_name" content="A.P的文艺杂谈">
<meta property="og:description" content="一. Spark 与 MapReduce 区别Apache Spark™ is a fast and general engine for large-scale data processing. 与mapreduce比较 ：  Spark大多数执行过程是基于内存的迭代  MapReduce 的 优点, SparkCore 都有  Hive 能做的操作, SparkSQL 都能做, 可以写 SQL">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="http://p6i5vzkfk.bkt.clouddn.com/study/2018-07-25-070107.png">
<meta property="og:image" content="http://p6i5vzkfk.bkt.clouddn.com/study/2018-07-25-070716.png">
<meta property="og:image" content="http://p6i5vzkfk.bkt.clouddn.com/study/2018-07-26-093416.png">
<meta property="og:image" content="http://p6i5vzkfk.bkt.clouddn.com/study/2018-07-26-093433.png">
<meta property="og:image" content="http://p6i5vzkfk.bkt.clouddn.com/study/2018-07-25-075654.png">
<meta property="og:image" content="http://p6i5vzkfk.bkt.clouddn.com/study/2018-07-25-084407.png">
<meta property="og:image" content="http://p6i5vzkfk.bkt.clouddn.com/study/2018-07-26-090621.png">
<meta property="og:image" content="http://p6i5vzkfk.bkt.clouddn.com/study/2018-07-26-090907.png">
<meta property="og:image" content="http://p6i5vzkfk.bkt.clouddn.com/study/2018-07-26-165721.png">
<meta property="og:image" content="http://p6i5vzkfk.bkt.clouddn.com/study/2018-07-26-165858.png">
<meta property="og:image" content="http://p6i5vzkfk.bkt.clouddn.com/study/2018-07-26-170442.png">
<meta property="og:image" content="http://p6i5vzkfk.bkt.clouddn.com/study/2018-07-26-172557.png">
<meta property="og:image" content="http://p6i5vzkfk.bkt.clouddn.com/study/2018-07-26-173025.png">
<meta property="og:image" content="http://p6i5vzkfk.bkt.clouddn.com/study/2018-07-26-spark%E6%89%A7%E8%A1%8C%E6%B5%81%E7%A8%8B%E5%9B%BE%E8%A7%A3.png">
<meta property="og:updated_time" content="2018-07-28T03:23:35.440Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Spark重点解析(一) =&gt; SparkCore">
<meta name="twitter:description" content="一. Spark 与 MapReduce 区别Apache Spark™ is a fast and general engine for large-scale data processing. 与mapreduce比较 ：  Spark大多数执行过程是基于内存的迭代  MapReduce 的 优点, SparkCore 都有  Hive 能做的操作, SparkSQL 都能做, 可以写 SQL">
<meta name="twitter:image" content="http://p6i5vzkfk.bkt.clouddn.com/study/2018-07-25-070107.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":true,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":false,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'airpoet'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://airpoet.github.io/2018/07/25/Spark/Spark重点解析(一) => SparkCore/"/>





  <title>Spark重点解析(一) => SparkCore | A.P的文艺杂谈</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">A.P的文艺杂谈</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off"
             placeholder="搜索..." spellcheck="false"
             type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://airpoet.github.io/2018/07/25/Spark/Spark重点解析(一) => SparkCore/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="airpoet">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="http://p6i5vzkfk.bkt.clouddn.com/study/2018-06-14-045043.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="A.P的文艺杂谈">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">Spark重点解析(一) => SparkCore</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-07-25T14:58:04+08:00">
                2018-07-25
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">更新于&#58;</span>
              
              <time title="更新于" itemprop="dateModified" datetime="2018-07-28T11:23:35+08:00">
                2018-07-28
              </time>
            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Spark/" itemprop="url" rel="index">
                    <span itemprop="name">Spark</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Spark/精讲/" itemprop="url" rel="index">
                    <span itemprop="name">精讲</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2018/07/25/Spark/Spark重点解析(一) => SparkCore/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2018/07/25/Spark/Spark重点解析(一) => SparkCore/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          
            <span class="post-meta-divider">|</span>
            <span class="page-pv">本文总阅读量
            <span class="busuanzi-value" id="busuanzi_value_page_pv" ></span>次
            </span>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h1 id="一-Spark-与-MapReduce-区别"><a href="#一-Spark-与-MapReduce-区别" class="headerlink" title="一. Spark 与 MapReduce 区别"></a>一. Spark 与 MapReduce 区别</h1><p><strong>Apache Spark™</strong> is a fast and general engine for large-scale data processing.</p>
<p><strong>与mapreduce比较 </strong>：</p>
<ul>
<li><p>Spark大多数执行过程是基于内存的迭代</p>
</li>
<li><p>MapReduce 的 优点, SparkCore 都有</p>
</li>
<li><p>Hive 能做的操作, SparkSQL 都能做, 可以写 SQL 语句转换为 SparkCore 代码</p>
</li>
<li><p>Spark Streaming 提供近实时流</p>
</li>
<li><p>超过80个类似于 map, reduce 这样的操作</p>
</li>
<li><p>可以在<a href="http://www.alluxio.org/" target="_blank" rel="noopener">Tachyon</a>（基于内存的分布式的文件系统 (HDFS 是基于磁盘)) 上运行Spark, 会更快</p>
</li>
</ul>
<p><img src="http://p6i5vzkfk.bkt.clouddn.com/study/2018-07-25-070107.png" alt="image-20180725150106695"></p>
<hr>
<h1 id="二-什么是RDD"><a href="#二-什么是RDD" class="headerlink" title="二. 什么是RDD"></a>二. 什么是RDD</h1><p>1、RDD是Spark提供的核心<strong>抽象</strong>，全称为Resillient Distributed Dataset，即<strong>弹性</strong>分布式数据集。</p>
<p>2、RDD在抽象上来说是一种元素集合，包含了数据。它是<strong>被分区的</strong>，分为多个分区，每个分区分布在集群中的不同节点上，从而让RDD中的数据可以被并行操作。（分布式数据集）</p>
<ul>
<li>如果读取的文件本来就存在于3个分区, 这些操作会并行操作, 如何并行操作?  :TODO</li>
<li>如果存在于3个分区, 手动规定了2个分区, 那么是如何工作的 ? :TODO</li>
</ul>
<p>3、RDD通常<strong>通过Hadoop上的文件</strong>，即HDFS文件或者Hive表，来进行<strong>创建</strong>；有时也可以<strong>通过应用程序中的集合来创建</strong>。</p>
<ul>
<li><strong>从文件系统读取</strong>: local 或 HDFS <code>sc.textFile(&quot;/Users/shixuanji/Documents/a.txt&quot;,2);</code></li>
<li>Hive 表: : TODO</li>
<li>并行化的方式创建(多用于测试): <code>val rdd = sc.makeRDD(1 to 10)</code>  或者 <code>val rdd = sc.parallelize(arr);</code></li>
</ul>
<p>4、RDD最重要的特性就是，提供了<strong>容错性</strong>，可以自动从节点失败中恢复过来。即如果某个节点上的RDD partition，因为节点故障，导致数据丢了，那么<strong>RDD会自动通过自己的数据来源重新计算该partition</strong>。这一切对使用者是透明的。</p>
<p>5、RDD的数据<strong>默认</strong>情况下存<strong>放在内存</strong>中的，但是在<strong>内存资源不足时</strong>，Spark<strong>会自动将RDD数据写入磁盘</strong>。（弹性 == 灵活）</p>
<blockquote>
<p><strong>下图中画橙色框的都是 RDD </strong></p>
</blockquote>
<p><img src="http://p6i5vzkfk.bkt.clouddn.com/study/2018-07-25-070716.png" alt="image-20180725150715950"></p>
<h4 id="源码中的注释说明"><a href="#源码中的注释说明" class="headerlink" title="源码中的注释说明"></a><strong>源码中的注释说明</strong></h4><p>1、A list of partitions：一组分片（Partition），即数据集的基本组成单位</p>
<p>2、A function for computing each split：一个计算每个分区的函数</p>
<p>3、A list of dependencies on other RDDs：RDD 之间的依赖关系</p>
<ul>
<li>NarrowDependency   完全依赖, 窄依赖</li>
<li>ShuffleDependency   部分依赖, ‘’宽依赖’’</li>
</ul>
<p>4、Optionally, a Partitioner for <strong>key-value RDDs</strong> (e.g. to say that the RDD is hash-partitioned)：</p>
<ul>
<li>Partitioner: 自定义分区使用</li>
</ul>
<p>5、Optionally, a list of preferred locations to compute each split on (e.g. block locations for an HDFS file)：一个列表，存储存取每个 Partition 的优先位置（preferred location）。</p>
<h4 id="Spark-中其它重要概念"><a href="#Spark-中其它重要概念" class="headerlink" title="Spark 中其它重要概念"></a>Spark 中其它重要概念</h4><p><strong>Cluster Manager</strong>：Spark 的集群管理器，主要负责资源的分配与管理。集群管理器分配的资 源属于一级分配，它将各个 Worker 上的内存、CPU 等资源分配给应用程序，但是并不负责 对 Executor 的资源分配。目前，Standalone、YARN、Mesos、K8S，EC2 等都可以作为 Spark 的集群管理器。</p>
<p><strong>Master</strong>：Spark 集群的主节点。</p>
<p><strong>Worker</strong>：Spark 集群的工作节点。对 Spark 应用程序来说，由集群管理器分配得到资源的 Worker 节点主要负责以下工作：创建 Executor，将资源和任务进一步分配给 Executor，同步 资源信息给 Cluster Manager。</p>
<p><strong>Executor</strong>：执行计算任务的一些进程。主要负责任务的执行以及与 Worker、Driver Application 的信息同步。</p>
<p><strong>Driver Appication：</strong>客户端驱动程序，也可以理解为客户端应用程序，用于将任务程序转换 为 RDD 和 DAG，并与 Cluster Manager 进行通信与调度。</p>
<p><strong>关系</strong>:</p>
<p><img src="http://p6i5vzkfk.bkt.clouddn.com/study/2018-07-26-093416.png" alt="image-20180726173416513"></p>
<hr>
<p><img src="http://p6i5vzkfk.bkt.clouddn.com/study/2018-07-26-093433.png" alt="image-20180726173433286"></p>
<p>1、用户使用 SparkContext 提供的 API（常用的有 textFile、sequenceFile、runJob、stop 等） 编写 Driver Application 程序。此外 SQLContext、HiveContext 及 StreamingContext 对 SparkContext 进行封装，并提供了 SQL、Hive 及流式计算相关的 API。</p>
<p>2、使用 SparkContext 提交的用户应用程序，首先会使用 BlockManager 和 BroadcastManager 将任务的 Hadoop 配置进行广播。然后由 DAGScheduler 将任务转换为 RDD 并组织成 DAG， DAG 还将被划分为不同的 Stage。<strong>最后由 TaskScheduler 借助 ActorSystem 将任务提交给集群 管理器（Cluster Manager）。</strong></p>
<p>3、集群管理器（ClusterManager）给任务分配资源，即将具体任务分配到 Worker 上，Worker 创建 Executor 来处理任务的运行。Standalone、YARN、Mesos、EC2 等都可以作为 Spark 的集 群管理器。</p>
<p><strong>注意:</strong>  如果是 –deploy-mode <strong>client</strong> 模式, <strong>client 就是 Driver</strong>,   –deploy-mode <strong>cluster</strong> 模式, <strong>Driver 是由集群分配的一台 worker节点</strong></p>
<h1 id="三-Spark-的架构-standalone"><a href="#三-Spark-的架构-standalone" class="headerlink" title="三. Spark 的架构(standalone)"></a>三. Spark 的架构(standalone)</h1><p>涉及到的名词: <strong>Driver</strong>, <strong>Master</strong>, <strong>Worker</strong>, <strong>Executor</strong> , <strong>Task</strong></p>
<p><img src="http://p6i5vzkfk.bkt.clouddn.com/study/2018-07-25-075654.png" alt="image-20180725155654170"></p>
<hr>
<h1 id="四-Spark-任务提交"><a href="#四-Spark-任务提交" class="headerlink" title="四. Spark 任务提交"></a>四. Spark 任务提交</h1><p>参考官网 <a href="http://spark.apache.org/docs/latest/submitting-applications.html" target="_blank" rel="noopener">http://spark.apache.org/docs/latest/submitting-applications.html</a></p>
<p><strong>Client</strong>模式</p>
<p>不指定<code>deploy-mode</code> ,默认就是<strong>client</strong>模式，也就是<strong>哪一台服务器提交</strong>spark代码，那么<strong>哪一台就是driver服务器</strong>。</p>
<p><strong>Cluster</strong>模式</p>
<p>需要指定<code>deploy-mode</code>，driver服务器并不是提交代码的那一台服务器，而是在提交代码的时候，在<strong>worker</strong>主机上，<strong>随机挑选一台作为driver服务器</strong>，那么<u>如果提交10个应用，那么就有可能10台driver服务器</u>。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Run application locally on 8 cores</span></span><br><span class="line">./bin/spark-submit \</span><br><span class="line">  --class org.apache.spark.examples.SparkPi \</span><br><span class="line">  --master <span class="built_in">local</span>[8] \</span><br><span class="line">  /path/to/examples.jar \</span><br><span class="line">  100</span><br><span class="line"></span><br><span class="line"><span class="comment"># Run on a Spark standalone cluster in client deploy mode</span></span><br><span class="line">./bin/spark-submit \</span><br><span class="line">  --class org.apache.spark.examples.SparkPi \</span><br><span class="line">  --master spark://207.184.161.138:7077 \</span><br><span class="line">  --executor-memory 20G \</span><br><span class="line">  --total-executor-cores 100 \</span><br><span class="line">  /path/to/examples.jar \</span><br><span class="line">  1000</span><br><span class="line"></span><br><span class="line"><span class="comment"># Run on a Spark standalone cluster in cluster deploy mode with supervise</span></span><br><span class="line">./bin/spark-submit \</span><br><span class="line">  --class org.apache.spark.examples.SparkPi \</span><br><span class="line">  --master spark://207.184.161.138:7077 \</span><br><span class="line">  --deploy-mode cluster \</span><br><span class="line">  --supervise \</span><br><span class="line">  --executor-memory 20G \</span><br><span class="line">  --total-executor-cores 100 \</span><br><span class="line">  /path/to/examples.jar \</span><br><span class="line">  1000</span><br><span class="line"></span><br><span class="line"><span class="comment"># Run on a YARN cluster</span></span><br><span class="line"><span class="built_in">export</span> HADOOP_CONF_DIR=XXX</span><br><span class="line">./bin/spark-submit \</span><br><span class="line">  --class org.apache.spark.examples.SparkPi \</span><br><span class="line">  --master yarn \</span><br><span class="line">  --deploy-mode cluster \  <span class="comment"># can be client for client mode</span></span><br><span class="line">  --executor-memory 20G \</span><br><span class="line">  --num-executors 50 \</span><br><span class="line">  /path/to/examples.jar \</span><br><span class="line">  1000</span><br><span class="line"></span><br><span class="line"><span class="comment"># Run a Python application on a Spark standalone cluster</span></span><br><span class="line">./bin/spark-submit \</span><br><span class="line">  --master spark://207.184.161.138:7077 \</span><br><span class="line">  examples/src/main/python/pi.py \</span><br><span class="line">  1000</span><br><span class="line"></span><br><span class="line"><span class="comment"># Run on a Mesos cluster in cluster deploy mode with supervise</span></span><br><span class="line">./bin/spark-submit \</span><br><span class="line">  --class org.apache.spark.examples.SparkPi \</span><br><span class="line">  --master mesos://207.184.161.138:7077 \</span><br><span class="line">  --deploy-mode cluster \</span><br><span class="line">  --supervise \</span><br><span class="line">  --executor-memory 20G \</span><br><span class="line">  --total-executor-cores 100 \</span><br><span class="line">  http://path/to/examples.jar \</span><br><span class="line">  1000</span><br><span class="line"></span><br><span class="line"><span class="comment"># Run on a Kubernetes cluster in cluster deploy mode</span></span><br><span class="line">./bin/spark-submit \</span><br><span class="line">  --class org.apache.spark.examples.SparkPi \</span><br><span class="line">  --master k8s://xx.yy.zz.ww:443 \</span><br><span class="line">  --deploy-mode cluster \</span><br><span class="line">  --executor-memory 20G \</span><br><span class="line">  --num-executors 50 \</span><br><span class="line">  http://path/to/examples.jar \</span><br><span class="line">  1000</span><br></pre></td></tr></table></figure>
<hr>
<h1 id="五-Transformation和action原理"><a href="#五-Transformation和action原理" class="headerlink" title="五. Transformation和action原理"></a>五. Transformation和action原理</h1><p><strong>Spark支持两种RDD操作：<code>transformation</code>和<code>action</code></strong>。</p>
<ul>
<li><code>transformation</code>操作会<strong>针对已有的RDD创建一个新的RDD</strong>；</li>
<li>而<code>action</code>则主要是对RDD进行最后的操作，比如遍历、reduce、保存到文件等，并可以<strong>返回结果给Driver程序</strong>。</li>
</ul>
<p>例如，map就是一种transformation操作，它用于将已有RDD的每个元素传入一个自定义的函数，并获取一个新的元素，然后将所有的新元素组成一个新的RDD。而reduce就是一种action操作，它用于对RDD中的所有元素进行聚合操作，并获取一个最终的结果，然后返回给Driver程序。</p>
<p><strong>transformation的特点就是lazy特性</strong>。lazy特性指的是，如果一个spark应用中只定义了transformation操作，那么即使你执行该应用，这些操作也不会执行。也就是说，transformation是不会触发spark程序的执行的，它们只是记录了对RDD所做的操作，但是不会自发的执行。只有当transformation之后，接着执行了一个action操作，那么所有的transformation才会执行。<strong>Spark通过这种lazy特性，来进行底层的spark应用执行的优化，<u>避免产生过多中间结果</u>。</strong></p>
<p><strong>action操作执行，会触发一个<code>spark job</code>的运行，从而触发这个action之前所有的transformation的执行。</strong>这是action的特性。</p>
<p><img src="http://p6i5vzkfk.bkt.clouddn.com/study/2018-07-25-084407.png" alt="image-20180725164407028"></p>
<hr>
<h1 id="六-Transformation-和-Action-算子"><a href="#六-Transformation-和-Action-算子" class="headerlink" title="六. Transformation 和 Action 算子"></a>六. Transformation 和 Action 算子</h1><h2 id="1-Transformation-算子"><a href="#1-Transformation-算子" class="headerlink" title="1.Transformation 算子"></a>1.Transformation 算子</h2><p><a href="https://github.com/airpoet/bigdata/blob/master/Spark_Project/SparkDemo-1/src/main/java/com/rox/spark/java/TransfromationOperation.java" target="_blank" rel="noopener">Java 版代码, 见这里 &amp; 上层目录</a> </p>
<p><a href="https://github.com/airpoet/bigdata/blob/master/Spark_Project/SparkDemo-1/src/main/java/com/rox/spark/scala/TransformationOperations.scala" target="_blank" rel="noopener">Scala 版代码, 见这里 &amp; 上层目录</a></p>
<p><strong>或 ../</strong></p>
<h4 id="map"><a href="#map" class="headerlink" title="map:"></a>map:</h4><p>对调用map的RDD数据集中的每个element都使用func，然后返回一个新的RDD,这个返回的数据集是分布式的数据集</p>
<h4 id="filter"><a href="#filter" class="headerlink" title="filter:"></a>filter:</h4><p>对调用filter的RDD数据集中的每个元素都使用func，然后返回一个包含使func为true的元素构成的RDD</p>
<h4 id="flatMap"><a href="#flatMap" class="headerlink" title="flatMap:"></a>flatMap:</h4><p>和map差不多，但是flatMap生成的是多个结果</p>
<h4 id="groupByKey-reduceByKey-sortByKey"><a href="#groupByKey-reduceByKey-sortByKey" class="headerlink" title="groupByKey, reduceByKey, sortByKey :"></a>groupByKey, reduceByKey, sortByKey :</h4><p>凡是这种.. ByKey 的, 必须传入一个对偶元祖,  Java中是 JavaPairRdd</p>
<h4 id="cogroup-与-join-与-union-区别"><a href="#cogroup-与-join-与-union-区别" class="headerlink" title="cogroup 与 join 与 union 区别:"></a>cogroup 与 join 与 union 区别:</h4><p><a href="http://lxw1234.com/archives/2015/07/384.htm" target="_blank" rel="noopener">详情可参考</a></p>
<ul>
<li><strong>cogroup</strong><ul>
<li>相当于SQL中的<strong>全外关联full outer join</strong>，返回左右RDD中的记录，<strong>关联不上的为空。</strong></li>
<li>return:   JavaPairRDD[K, (JIterable[V], JIterable[W])</li>
<li>RDD的value是一个Pair的实例,这个实例包含两个Iterable的值, <code>V</code>表示的是RDD1中相同KEY的值, <code>W</code>表示的是RDD2中相同key的值. </li>
</ul>
</li>
<li><strong>join</strong><ul>
<li>相当于SQL中的<strong>内关联join</strong>，<strong>只返回两个RDD根据K可以关联上的结果</strong>，join只能用于两个RDD之间的关联，如果要多个RDD关联，多关联几次即可。</li>
</ul>
</li>
<li><strong>union</strong><ul>
<li>求rdd并集，但是不去重</li>
</ul>
</li>
</ul>
<h4 id="Intersection，Distinct，Cartesian"><a href="#Intersection，Distinct，Cartesian" class="headerlink" title="Intersection，Distinct，Cartesian"></a>Intersection，Distinct，Cartesian</h4><ul>
<li><strong>intersection</strong> <ul>
<li>intersection <strong>求交集</strong>,提取两个rdd中都含有的元素。</li>
<li>Returns a new RDD that contains the intersection of elements in the source dataset and the argument.</li>
</ul>
</li>
<li><strong>Distinct</strong> (独特的,有区别的)<ul>
<li>去重 </li>
<li>Return a new RDD containing the distinct elements in this RDD.</li>
</ul>
</li>
<li><strong>Cartesian</strong> (笛卡尔积)<ul>
<li>笛卡尔积, 全连接, 前后集合个数为a,b,  a x b  种组合</li>
</ul>
</li>
</ul>
<h4 id="mapPartition，reparation，coalesce"><a href="#mapPartition，reparation，coalesce" class="headerlink" title="mapPartition，reparation，coalesce"></a>mapPartition，reparation，coalesce</h4><ul>
<li><p><strong>mapPartition</strong></p>
<ul>
<li>该函数和map函数类似，只不过映射函数的参数<strong>由RDD中的每一个元素</strong>变成了<strong><code>RDD</code>中每一个分区的迭代器</strong>。如果在映射的过程中需要频繁创建额外的对象，使用mapPartitions要比map高效的多。 </li>
<li>比如，将RDD中的所有数据通过JDBC连接写入数据库，如果使用map函数，可能要为每一个元素都创建一个<code>connection</code>，这样开销很大，如果使用<code>mapPartitions</code>，那么只需要针对每一个分区建立一个<code>connection</code>。 </li>
</ul>
</li>
<li><p><strong>coalesce</strong> </p>
<ul>
<li><strong>coalesce: 只能用于减少分区的数量</strong>，而且<strong>可以选择不发生shuffle</strong> 其实说白了他就是<strong>合并分区</strong></li>
<li><strong>repartition:可以增加分区，也可以减少分区</strong>，<strong>必须会发生shuffle</strong>，相当于就是进行<strong>重新分区</strong></li>
</ul>
</li>
<li><p><strong>reparation</strong></p>
<ul>
<li>reparition是<code>coalesce shuffle</code>为<code>true</code>的简易实现 </li>
</ul>
</li>
</ul>
<h4 id="sample-和-aggregateByKey"><a href="#sample-和-aggregateByKey" class="headerlink" title="sample   和  aggregateByKey"></a>sample   和  aggregateByKey</h4><ul>
<li><p><strong>sample</strong></p>
<ul>
<li><p>对RDD中的集合内元素进行采样，第一个参数withReplacement是true表示有放回取样，false表示无放回。第二个参数表示比例 </p>
</li>
<li><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> *- @param withReplacement can elements be sampled multiple times (replaced when sampled out)</span></span><br><span class="line"><span class="comment">    @param fraction expected size of the sample as a fraction of this RDD's size</span></span><br><span class="line"><span class="comment">    	   seed  最好不要动</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sample</span></span>(</span><br><span class="line">      withReplacement: <span class="type">Boolean</span>,</span><br><span class="line">      fraction: <span class="type">Double</span>,</span><br><span class="line">      seed: <span class="type">Long</span> = <span class="type">Utils</span>.random.nextLong): <span class="type">RDD</span>[<span class="type">T</span>]</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
</ul>
<ul>
<li><p><strong>aggregateByKey</strong></p>
<ul>
<li><code>aggregateByKey(zeroValue)(seqOp, combOp, [numTasks])</code>            //按照key进行聚合 </li>
<li>其实<code>reduceBykey</code> 就是<code>aggregateByKey</code>的简化版。  </li>
<li><code>aggregateByKey</code>多提供了一个函数 seqOp 类似于Mapreduce的combine操作（就在map端执行reduce的操作）</li>
</ul>
</li>
</ul>
<h4 id="mapPartitionsWithIndex-和-repartitionAndSortWithinPartitions"><a href="#mapPartitionsWithIndex-和-repartitionAndSortWithinPartitions" class="headerlink" title="mapPartitionsWithIndex 和 repartitionAndSortWithinPartitions"></a>mapPartitionsWithIndex 和 repartitionAndSortWithinPartitions</h4><ul>
<li><strong>mapPartitionsWithIndex</strong> <ul>
<li>说白了就是可以打印出当前所在分区数</li>
</ul>
</li>
<li><strong>repartitionAndSortWithinPartitions</strong><ul>
<li><strong>该方法依据partitioner对RDD进行分区，并且在每个结果分区中按key进行排序；通过对比sortByKey发现，这种方式比先分区，然后在每个分区中进行排序效率高，这是因为它可以将排序融入到shuffle阶段。</strong> </li>
</ul>
</li>
</ul>
<h2 id="2-Action-算子"><a href="#2-Action-算子" class="headerlink" title="2. Action 算子"></a>2. Action 算子</h2><p><a href="https://github.com/airpoet/bigdata/blob/master/Spark_Project/SparkDemo-1/src/main/java/com/rox/spark/java/ActionOperations.java" target="_blank" rel="noopener"><strong>Java 代码见这里</strong></a></p>
<h4 id="reduce"><a href="#reduce" class="headerlink" title="reduce();"></a>reduce();</h4><ul>
<li>def reduce(f: JFunction2[T, T, T]): T = rdd.reduce(f)</li>
</ul>
<h4 id="collect"><a href="#collect" class="headerlink" title="collect();"></a>collect();</h4><ul>
<li>Return an array that contains all of the elements in this RDD.</li>
<li>this method should only be used if the resulting array is expected to be small, as all the data is loaded into the driver’s memory.</li>
</ul>
<h4 id="take-n"><a href="#take-n" class="headerlink" title="take(n);"></a>take(n);</h4><ul>
<li>Take the first num elements of the RDD. This currently scans the partitions <em>one by one</em>, so it will be slow if a lot of partitions are required. In that case, use collect() to get the  whole RDD instead.</li>
<li>this method should only be used if the resulting array is expected to be small, as all the data is loaded into the driver’s memory.</li>
</ul>
<h4 id="count"><a href="#count" class="headerlink" title="count();"></a>count();</h4><ul>
<li>Return the number of elements in the RDD.</li>
</ul>
<h4 id="takeOrdered"><a href="#takeOrdered" class="headerlink" title="takeOrdered();"></a>takeOrdered();</h4><ul>
<li>Returns the <strong>first k (smallest)</strong> elements from this RDD using the  <strong>natural ordering</strong> for T while maintain the order.</li>
<li>top(n): 自然排序后,最大的前 n</li>
</ul>
<h4 id="saveAsTextFile"><a href="#saveAsTextFile" class="headerlink" title="saveAsTextFile();"></a>saveAsTextFile();</h4><ul>
<li>Save this RDD as a text file, using string representations of elements.</li>
</ul>
<h4 id="countByKey"><a href="#countByKey" class="headerlink" title="countByKey();"></a>countByKey();</h4><ul>
<li>return  map&lt;String, Integer&gt;, key 为 key, value 为 key 的数量</li>
</ul>
<h4 id="takeSample"><a href="#takeSample" class="headerlink" title="takeSample();"></a>takeSample();</h4><ul>
<li>withReplacement：元素可以多次(重复)抽样(在抽样时替换) 如果为 false, 在抽样数 &gt; 样本数时, 只能返回样本数的样本</li>
<li>num：返回的样本的大小</li>
<li>seed：随机数生成器的种子</li>
</ul>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">takeSample</span></span>(</span><br><span class="line">    withReplacement: <span class="type">Boolean</span>,</span><br><span class="line">    num: <span class="type">Int</span>,</span><br><span class="line">    seed: <span class="type">Long</span> = <span class="type">Utils</span>.random.nextLong): <span class="type">Array</span>[<span class="type">T</span>]</span><br></pre></td></tr></table></figure>
<hr>
<h1 id="七-RDD-的持久化"><a href="#七-RDD-的持久化" class="headerlink" title="七. RDD 的持久化"></a>七. RDD 的持久化</h1><p>将数据通过操作持久化（或缓存）在内存中是Spark的重要能力之一。当你缓存了一个RDD，每个节点都缓存了RDD的所有分区。这样就可以在内存中进行计算。这样可以使以后在RDD上的动作更快（通常可以提高10倍）。</p>
<p>你可以对希望缓存的RDD通过使用persist或cache方法进行标记。它通过动作操作第一次在RDD上进行计算后，它就会被缓存在节点上的内存中。Spark的缓存具有容错性，如果RDD的某一分区丢失，它会自动使用最初创建RDD时的转换操作进行重新计算。</p>
<p>另外，RDD可以被持久化成不同的级别。比如，可以允许你存储在磁盘，内存，甚至是序列化的<strong>Java</strong>对象（节省空间），备份在不同的节点上，或者存储在基于内存的文件系统Tachyon上。通过向persist()方法传递StorageLevel对象来设置。cache方法是使用默认级别<code>StorageLevel.MEMORY_ONLY</code>的方法。</p>
<h4 id="选持久化方案建议："><a href="#选持久化方案建议：" class="headerlink" title="选持久化方案建议："></a><strong>选持久化方案建议：</strong></h4><ol>
<li>优先选择MEMORY_ONLY，如果可以用内存缓存所有的数据，那么也就意味着我的计算是纯内存的计算，速度当然快。 </li>
<li>如果MEMORY_ONLY 缓存不了所有的数据，MEMORY_ONLY_SER 把数据实现序列化然后进行存储。这样也是纯内存操作，速度也快，只不过需要耗费一点cpu资源需要反序列化。 </li>
<li>也可以选用带_2这种方式, 此方式会存2份, 一份存在本地, 另一份会存到另外的节点。恢复速度的时候可以使用备份。</li>
<li>能不能使用DISK的，就不使用DISK，有时候从磁盘读，还不如从新计算一次。 </li>
</ol>
<h4 id="关于tachyon"><a href="#关于tachyon" class="headerlink" title="关于tachyon "></a>关于<strong><a href="http://www.alluxio.org/" target="_blank" rel="noopener">tachyon</a> </strong></h4><p>Spark2.0开始就不把tachyon(现在成为alluxio)集成在自身内部了, 依然可以直接用</p>
<p><strong>基于内存的分布式文件系统</strong> </p>
<p><strong>出现原因</strong>:</p>
<ul>
<li>spark运行以 JVM为基础，所以spark的任务会把数据存入JVM的堆中，随着计算的迭代，JVM堆中存放的数据量迅速增大，对于spark而言，spark的计算引擎和存储引擎处在同一个JVM中，所以会有重复的GC方面的开销。这样就增大了系统的延时。</li>
<li>当JVM崩溃时，缓存在JVM堆中的数据也会消失，这个时候spark不得不根据RDD的血缘关系重新计算数据。</li>
<li>如果spark需要其他的框架的共享数据，比如就是hadoop的Mapreduce，这个时候就必须通过第三方来共享，比如借助HDFS，那么这样的话，就需要额外的开销，借助的是HDFS，那么就需要磁盘IO的开销。</li>
<li>因为我们基于内存的分布式计算框架有以上的问题，那么就促使了内存分布式文件系统的诞生，比如tachyon。</li>
</ul>
<p><strong>Tachyon可以解决spark的什么问题呢？</strong></p>
<p>如果我们把数据存放到tachyon上面：</p>
<ul>
<li><strong>减少Spark GC的开销。</strong> </li>
<li><strong>当spark 的JVM崩溃的时候，存放在tachyon上的数据不受影响。</strong> </li>
<li><strong>spark如果要想跟被的计算工具共享数据，只要通过tachyon的Client就可以做到了。并且延迟远低于HDFS等系统。</strong> </li>
</ul>
<hr>
<h1 id="八-广播变量-和-累加器"><a href="#八-广播变量-和-累加器" class="headerlink" title="八. 广播变量 和  累加器"></a>八. 广播变量 和  累加器</h1><h2 id="1-广播变量"><a href="#1-广播变量" class="headerlink" title="1. 广播变量"></a>1. 广播变量</h2><p>每个 executor 拥有一份， 这个 executor 启动的 task 会共享这个变量</p>
<p>使用了广播变量之后, executor 中所有的 task 都会共享此变量, 否则每个 task 都会发一份</p>
<p>在 Driver 端可以修改广播变量的值，在 Executor 端无法修改广播变量的值。</p>
<p><strong>使用:</strong></p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 定义</span></span><br><span class="line"><span class="keyword">val</span> a = <span class="number">3</span></span><br><span class="line"><span class="keyword">val</span> broadcast = sc.broadcast(a)</span><br><span class="line"><span class="comment">// 获取</span></span><br><span class="line"><span class="keyword">val</span> c = broadcast.value</span><br></pre></td></tr></table></figure>
<p><img src="http://p6i5vzkfk.bkt.clouddn.com/study/2018-07-26-090621.png" alt="image-20180726170621192"></p>
<h2 id="2-累加器"><a href="#2-累加器" class="headerlink" title="2. 累加器"></a>2. 累加器</h2><p><strong>使用场景</strong>: 异常监控，调试，记录符合某特性的数据的数目等</p>
<p><strong>如果一个变量不被声明为一个累加器</strong>，那么它将在 被改变时不会在 driver 端进行全局汇总，即在<strong>分布式运行时每个 task 运行的只是原始变量的一个副本</strong>，并不能改变原始变量的值</p>
<p>但是当这个变量被声明为<strong>累加器</strong>后，<strong>该变量就会有分布式计数的功能。</strong></p>
<p>累加器<strong>在 Driver 端定义赋初始值</strong>，累加器只能在 <strong>Driver 端读取最后的值</strong>，在 <strong>Excutor 端更 新</strong>。</p>
<p><strong>使用:</strong> </p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 定义</span></span><br><span class="line"><span class="keyword">val</span> a = sc.longAccumulator(<span class="number">0</span>)</span><br><span class="line"><span class="comment">// 获取</span></span><br><span class="line"><span class="keyword">val</span> b = a.value</span><br></pre></td></tr></table></figure>
<p><img src="http://p6i5vzkfk.bkt.clouddn.com/study/2018-07-26-090907.png" alt="image-20180726170906622"></p>
<hr>
<h1 id="九-Spark-on-Yarn-模式"><a href="#九-Spark-on-Yarn-模式" class="headerlink" title="九. Spark on Yarn 模式"></a>九. Spark on Yarn 模式</h1><p><strong>配置</strong>: 只需要在<code>conf/spark-env.sh</code> 中配置<code>export HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop</code> 就可以了</p>
<p><strong>使用YARN模式的时候，不需要启动master和worker了。</strong> </p>
<p><strong>只需要启动HDFS和YARN即可。</strong> </p>
<p><strong>与 <code>Standalone</code>主要区别是</strong>: <code>spark-submit</code>后面的参数中<code>--master</code>后面的不是 spark://….,   而是 <code>yarn</code>,  这样:<code>--master yarn</code></p>
<h4 id="–deploy-mode-client"><a href="#–deploy-mode-client" class="headerlink" title="–deploy-mode client"></a>–deploy-mode client</h4><p><img src="http://p6i5vzkfk.bkt.clouddn.com/study/2018-07-26-165721.png" alt="image-20180727005721062"></p>
<h4 id="–deploy-mode-cluster"><a href="#–deploy-mode-cluster" class="headerlink" title="–deploy-mode cluster"></a>–deploy-mode cluster</h4><p><img src="http://p6i5vzkfk.bkt.clouddn.com/study/2018-07-26-165858.png" alt="image-20180727005857420"></p>
<h1 id="十-宽窄依赖"><a href="#十-宽窄依赖" class="headerlink" title="十. 宽窄依赖"></a>十. 宽窄依赖</h1><p><strong>窄依赖是指父RDD的每个分区都只被子RDD一个分区使用。</strong>(独生, NarrowDependency)</p>
<p><strong>宽依赖就是指父RDD的分区被多个子RDD的分区所依赖。</strong> (超生, ShuffleDependency)</p>
<p><img src="http://p6i5vzkfk.bkt.clouddn.com/study/2018-07-26-170442.png" alt="image-20180727010441959"></p>
<h1 id="十一-Stage-划分"><a href="#十一-Stage-划分" class="headerlink" title="十一. Stage 划分"></a>十一. Stage 划分</h1><p>开发完一个应用以后，把应用提交到集群，那么这个应用就叫做Application</p>
<p>这个应用里面我们开发了好多代码，这些代码里面凡是遇到一个action操作，就会产生一个job任务。</p>
<p>也就意味着，一个Application有一个或者一个以上的job任务。</p>
<p>然后这些job任务划分为不同stage去执行，stage里面就是运行不同的task任务。</p>
<p>遇到一个 shuffle 算子, 就会从中间分开, 划分为2个 stage</p>
<p>Task计算的就是分区上面的数据。</p>
<p><img src="http://p6i5vzkfk.bkt.clouddn.com/study/2018-07-26-172557.png" alt="image-20180727012556575"></p>
<h1 id="十二-Spark-任务调度"><a href="#十二-Spark-任务调度" class="headerlink" title="十二. Spark 任务调度"></a><strong>十二. Spark 任务调度</strong></h1><p><strong>Shuffle 机制见下一篇</strong></p>
<h2 id="1-简版"><a href="#1-简版" class="headerlink" title="1.简版"></a>1.简版</h2><p><img src="http://p6i5vzkfk.bkt.clouddn.com/study/2018-07-26-173025.png" alt="image-20180727013025763"></p>
<h2 id="2-完整版"><a href="#2-完整版" class="headerlink" title="2.完整版"></a>2.完整版</h2><p><img src="http://p6i5vzkfk.bkt.clouddn.com/study/2018-07-26-spark%E6%89%A7%E8%A1%8C%E6%B5%81%E7%A8%8B%E5%9B%BE%E8%A7%A3.png" alt=""></p>
<p><strong>注意:</strong> </p>
<ul>
<li>AppClient / clientActor：在 Standalone 模式下的实现是 <code>StandaloneAppClient</code> 类</li>
<li>dirverActor:  :TODO</li>
</ul>
<h1 id="十三-TopN-案例"><a href="#十三-TopN-案例" class="headerlink" title="十三. TopN 案例"></a>十三. TopN 案例</h1><p><strong>对一个文件里面的单词进行单词计数，然后取前3个出现次数最多的三个单词。</strong> </p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">TopN</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">     <span class="keyword">val</span> conf=<span class="keyword">new</span> <span class="type">SparkConf</span>().setMaster(<span class="string">"local"</span>).setAppName(<span class="string">"TopN"</span>)</span><br><span class="line">     <span class="keyword">val</span> sc=<span class="keyword">new</span> <span class="type">SparkContext</span>(conf);</span><br><span class="line">     <span class="keyword">val</span> file=sc.textFile(<span class="string">"file://..."</span>)</span><br><span class="line">     <span class="keyword">val</span> topN=file.flatMap &#123; line =&gt; line.split(<span class="string">"\t"</span>) &#125;</span><br><span class="line">     .map &#123; word =&gt; (word,<span class="number">1</span>) &#125;</span><br><span class="line">     .reduceByKey(_+_)  <span class="comment">//key word  value:count</span></span><br><span class="line">     .map(tuple =&gt;(tuple._2,tuple._1))	<span class="comment">// swap k,v</span></span><br><span class="line">     .sortByKey(<span class="literal">false</span>)				   <span class="comment">// sort the count</span></span><br><span class="line">     .take(<span class="number">3</span>)						  <span class="comment">// take top 3</span></span><br><span class="line">     <span class="keyword">for</span>( i &lt;- topN)&#123;</span><br><span class="line">       println(i._2 + <span class="string">"  出现次数："</span>+i._1);</span><br><span class="line">     &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h1 id="十四-网站访问日志分析"><a href="#十四-网站访问日志分析" class="headerlink" title="十四. 网站访问日志分析"></a>十四. 网站访问日志分析</h1><h3 id="需求分析"><a href="#需求分析" class="headerlink" title="需求分析"></a>需求分析</h3><p><strong>需求一 ：</strong></p>
<p>The average, min, and max content size of responses returned from the server.</p>
<p><strong>需求二： </strong></p>
<p>A count of response code’s returned.</p>
<p><strong>需求三： </strong></p>
<p>All IPAddresses that have accessed this server more than N times.</p>
<p><strong>需求四：</strong></p>
<p>The top endpoints requested by count.  TopN 找出被访问次数最多的地址的前三个</p>
<h3 id="Data"><a href="#Data" class="headerlink" title="Data"></a>Data</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">log.txt</span><br><span class="line">------------</span><br><span class="line">10.0.0.153<span class="comment">#-#-#[12/Mar/2004:12:23:18-0800]#"GET /cgi-bin/mailgraph.cgi/mailgraph_3_err.png HTTP/1.1"#200#5554</span></span><br><span class="line">10.0.0.153<span class="comment">#-#-#[12/Mar/2004:12:23:40-0800]#"GET /dccstats/index.html HTTP/1.1"#304#2000</span></span><br><span class="line">10.0.0.153<span class="comment">#-#-#[12/Mar/2004:12:23:41-0800]#"GET /dccstats/stats-spam.1day.png HTTP/1.1"#200#2964</span></span><br></pre></td></tr></table></figure>
<h3 id="Code"><a href="#Code" class="headerlink" title="Code"></a>Code</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ApacheAccesslog</span></span></span><br><span class="line"><span class="class"><span class="title">-----------------------</span></span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class"><span class="title">case</span> <span class="title">class</span> <span class="title">ApacheAccesslog</span>(<span class="params"></span></span></span><br><span class="line"><span class="class"><span class="params">    ipAddress:<span class="type">String</span>, // ip地址</span></span></span><br><span class="line"><span class="class"><span class="params">    clientIndentd:<span class="type">String</span>, //标识符</span></span></span><br><span class="line"><span class="class"><span class="params">    userId:<span class="type">String</span> ,//用户<span class="type">ID</span></span></span></span><br><span class="line"><span class="class"><span class="params">    dateTime:<span class="type">String</span> ,//时间</span></span></span><br><span class="line"><span class="class"><span class="params">    method:<span class="type">String</span> ,//请求方式</span></span></span><br><span class="line"><span class="class"><span class="params">    endPoint:<span class="type">String</span> ,//目标地址</span></span></span><br><span class="line"><span class="class"><span class="params">    protocol:<span class="type">String</span> ,//协议</span></span></span><br><span class="line"><span class="class"><span class="params">    responseCode:<span class="type">Int</span> ,//网页请求响应类型</span></span></span><br><span class="line"><span class="class"><span class="params">    contenSize:<span class="type">Long</span>   //内容长度</span></span></span><br><span class="line"><span class="class"><span class="params">    </span></span></span><br><span class="line"><span class="class"><span class="params">    </span>)</span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class"><span class="title">object</span> <span class="title">ApacheAccesslog</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">parseLog</span></span>(log:<span class="type">String</span>):<span class="type">ApacheAccesslog</span>=&#123;</span><br><span class="line">  <span class="keyword">val</span> logArray= log.split(<span class="string">"#"</span>);</span><br><span class="line">  <span class="keyword">val</span> url=logArray(<span class="number">4</span>).split(<span class="string">" "</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="type">ApacheAccesslog</span>(logArray(<span class="number">0</span>),logArray(<span class="number">1</span>),logArray(<span class="number">2</span>),logArray(<span class="number">3</span>),url(<span class="number">0</span>),url(<span class="number">1</span>),url(<span class="number">2</span>),logArray(<span class="number">5</span>).toInt,logArray(<span class="number">6</span>).toLong);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LogAnalyer</span></span></span><br><span class="line"><span class="class"><span class="title">--------------------</span></span></span><br><span class="line"><span class="class"><span class="title">import</span> <span class="title">org</span>.<span class="title">apache</span>.<span class="title">spark</span>.<span class="title">SparkConf</span></span></span><br><span class="line"><span class="class"><span class="title">import</span> <span class="title">org</span>.<span class="title">apache</span>.<span class="title">spark</span>.<span class="title">SparkContext</span></span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class"><span class="title">object</span> <span class="title">LogAnalyer</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">      <span class="keyword">val</span> conf=<span class="keyword">new</span> <span class="type">SparkConf</span>().setMaster(<span class="string">"local"</span>).setAppName(<span class="string">"LogAnalyer"</span>)</span><br><span class="line">     <span class="keyword">val</span> sc=<span class="keyword">new</span> <span class="type">SparkContext</span>(conf);</span><br><span class="line">     <span class="keyword">val</span> logsRDD=sc.textFile(<span class="string">"file://...."</span>)</span><br><span class="line">          .map &#123; line =&gt; <span class="type">ApacheAccesslog</span>.parseLog(line) &#125;</span><br><span class="line">          .cache()</span><br><span class="line">     <span class="comment">/**</span></span><br><span class="line"><span class="comment">      * 需求一 </span></span><br><span class="line"><span class="comment">      * The average, min, and max content size of responses returned from the server.</span></span><br><span class="line"><span class="comment">      */</span></span><br><span class="line">     <span class="keyword">val</span> contextSize=logsRDD.map &#123; log =&gt; log.contenSize &#125;</span><br><span class="line">        <span class="comment">// get max</span></span><br><span class="line">      <span class="keyword">val</span> maxSize=contextSize.max()</span><br><span class="line">       <span class="comment">//get min</span></span><br><span class="line">      <span class="keyword">val</span> minSize=contextSize.min()</span><br><span class="line">      <span class="comment">// total / count</span></span><br><span class="line">      <span class="comment">//get average</span></span><br><span class="line">      <span class="keyword">val</span> averageSize=contextSize.reduce(_+_)/contextSize.count()</span><br><span class="line">      println(<span class="string">"=============================需求一-=============================="</span>);</span><br><span class="line">      println(<span class="string">"最大值："</span>+maxSize  + <span class="string">"  最小值："</span>+minSize + <span class="string">"   平均值："</span>+averageSize);</span><br><span class="line">     <span class="comment">/**</span></span><br><span class="line"><span class="comment">      * 需求二</span></span><br><span class="line"><span class="comment">      * A count of response code's returned.</span></span><br><span class="line"><span class="comment">      */</span></span><br><span class="line">        println(<span class="string">"=============================需求二-=============================="</span>);</span><br><span class="line">     logsRDD.map &#123; log =&gt; (log.responseCode,<span class="number">1</span>) &#125;</span><br><span class="line">     .reduceByKey(_+_)</span><br><span class="line">     .foreach(result =&gt; println(<span class="string">" 响应状态："</span>+result._1 + <span class="string">"  出现的次数："</span>+result._2))</span><br><span class="line">        <span class="comment">/**</span></span><br><span class="line"><span class="comment">      * 需求三</span></span><br><span class="line"><span class="comment">      * All IPAddresses that have accessed this server more than N times.</span></span><br><span class="line"><span class="comment">      */</span></span><br><span class="line">      println(<span class="string">"=============================需求三-=============================="</span>);</span><br><span class="line">     <span class="keyword">val</span> result= logsRDD.map &#123; log =&gt;( log.ipAddress,<span class="number">1</span>) &#125;</span><br><span class="line">     .reduceByKey(_+_)</span><br><span class="line">     .filter(result =&gt; result._2 &gt; <span class="number">1</span>)   <span class="comment">// &gt; 10000 </span></span><br><span class="line">     .take(<span class="number">2</span>)  <span class="comment">//  &gt;  10</span></span><br><span class="line">     <span class="keyword">for</span>( tuple &lt;- result)&#123;</span><br><span class="line">       println(<span class="string">"ip : "</span>+tuple._1 + <span class="string">"  出现的次数："</span>+tuple._2);</span><br><span class="line">     &#125;</span><br><span class="line">        <span class="comment">/**</span></span><br><span class="line"><span class="comment">      * 需求四</span></span><br><span class="line"><span class="comment">      * The top endpoints requested by count.  TopN</span></span><br><span class="line"><span class="comment">      */</span></span><br><span class="line">      println(<span class="string">"=============================需求四-=============================="</span>);</span><br><span class="line">     <span class="keyword">val</span> topN=logsRDD.map &#123; log =&gt; (log.endPoint,<span class="number">1</span>) &#125;</span><br><span class="line">     .reduceByKey(_+_)</span><br><span class="line">     .map(result =&gt; (result._2,result._1))</span><br><span class="line">     .sortByKey(<span class="literal">false</span>)</span><br><span class="line">     .take(<span class="number">2</span>)</span><br><span class="line">     <span class="keyword">for</span>(tuple &lt;- topN)&#123;</span><br><span class="line">        println(<span class="string">"目标地址 : "</span>+tuple._2 + <span class="string">"  出现的次数："</span>+tuple._1);</span><br><span class="line">     &#125;</span><br><span class="line">     logsRDD.unpersist(<span class="literal">true</span>)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

      
    </div>
    
    
    

    

    
      <div>
        <div style="padding: 10px 0; margin: 20px auto; width: 90%; text-align: center;">
  <div>如果帮到你, 可以给我赞助杯咖啡☕️</div>
  <button id="rewardButton" disable="enable" onclick="var qr = document.getElementById('QR'); if (qr.style.display === 'none') {qr.style.display='block';} else {qr.style.display='none'}">
    <span>打赏</span>
  </button>
  <div id="QR" style="display: none;">

    
      <div id="wechat" style="display: inline-block">
        <img id="wechat_qr" src="/uploads/images/wechat-reward.jpg" alt="airpoet 微信支付"/>
        <p>微信支付</p>
      </div>
    

    

    

  </div>
</div>

      </div>
    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/原创/" rel="tag"># 原创</a>
          
            <a href="/tags/技术/" rel="tag"># 技术</a>
          
            <a href="/tags/Spark/" rel="tag"># Spark</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2018/07/25/Spark/i-Spark-5/" rel="next" title="i-Spark-5">
                <i class="fa fa-chevron-left"></i> i-Spark-5
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2018/07/27/Spark/Spark重点解析(二) => Spark调优/" rel="prev" title="">
                 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  
    <div class="comments" id="comments">
      <div id="disqus_thread">
        <noscript>
          Please enable JavaScript to view the
          <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a>
        </noscript>
      </div>
    </div>

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="http://p6i5vzkfk.bkt.clouddn.com/study/2018-06-14-045043.jpg"
                alt="airpoet" />
            
              <p class="site-author-name" itemprop="name">airpoet</p>
              <p class="site-description motion-element" itemprop="description">没有边界就没有自由.</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">116</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">42</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">40</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://www.jianshu.com/u/3b9b97fe7e04" target="_blank" title="我的简书">
                      
                        <i class="fa fa-fw fa-globe"></i>我的简书</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="mailto:airpoet@qq.com" target="_blank" title="Mile2Me">
                      
                        <i class="fa fa-fw fa-envelope"></i>Mile2Me</a>
                  </span>
                
            </div>
          

          
          

          
          
            <div class="links-of-blogroll motion-element links-of-blogroll-block">
              <div class="links-of-blogroll-title">
                <i class="fa  fa-fw fa-link"></i>
                友情链接
              </div>
              <ul class="links-of-blogroll-list">
                
                  <li class="links-of-blogroll-item">
                    <a href="https://www.jianshu.com/u/8ee264c6557d" title="女神凉姨" target="_blank">女神凉姨</a>
                  </li>
                
              </ul>
            </div>
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#一-Spark-与-MapReduce-区别"><span class="nav-text">一. Spark 与 MapReduce 区别</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#二-什么是RDD"><span class="nav-text">二. 什么是RDD</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#源码中的注释说明"><span class="nav-text">源码中的注释说明</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Spark-中其它重要概念"><span class="nav-text">Spark 中其它重要概念</span></a></li></ol></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#三-Spark-的架构-standalone"><span class="nav-text">三. Spark 的架构(standalone)</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#四-Spark-任务提交"><span class="nav-text">四. Spark 任务提交</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#五-Transformation和action原理"><span class="nav-text">五. Transformation和action原理</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#六-Transformation-和-Action-算子"><span class="nav-text">六. Transformation 和 Action 算子</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-Transformation-算子"><span class="nav-text">1.Transformation 算子</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#map"><span class="nav-text">map:</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#filter"><span class="nav-text">filter:</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#flatMap"><span class="nav-text">flatMap:</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#groupByKey-reduceByKey-sortByKey"><span class="nav-text">groupByKey, reduceByKey, sortByKey :</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#cogroup-与-join-与-union-区别"><span class="nav-text">cogroup 与 join 与 union 区别:</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Intersection，Distinct，Cartesian"><span class="nav-text">Intersection，Distinct，Cartesian</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#mapPartition，reparation，coalesce"><span class="nav-text">mapPartition，reparation，coalesce</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#sample-和-aggregateByKey"><span class="nav-text">sample   和  aggregateByKey</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#mapPartitionsWithIndex-和-repartitionAndSortWithinPartitions"><span class="nav-text">mapPartitionsWithIndex 和 repartitionAndSortWithinPartitions</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-Action-算子"><span class="nav-text">2. Action 算子</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#reduce"><span class="nav-text">reduce();</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#collect"><span class="nav-text">collect();</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#take-n"><span class="nav-text">take(n);</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#count"><span class="nav-text">count();</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#takeOrdered"><span class="nav-text">takeOrdered();</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#saveAsTextFile"><span class="nav-text">saveAsTextFile();</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#countByKey"><span class="nav-text">countByKey();</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#takeSample"><span class="nav-text">takeSample();</span></a></li></ol></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#七-RDD-的持久化"><span class="nav-text">七. RDD 的持久化</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#选持久化方案建议："><span class="nav-text">选持久化方案建议：</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#关于tachyon"><span class="nav-text">关于tachyon </span></a></li></ol></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#八-广播变量-和-累加器"><span class="nav-text">八. 广播变量 和  累加器</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-广播变量"><span class="nav-text">1. 广播变量</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-累加器"><span class="nav-text">2. 累加器</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#九-Spark-on-Yarn-模式"><span class="nav-text">九. Spark on Yarn 模式</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#–deploy-mode-client"><span class="nav-text">–deploy-mode client</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#–deploy-mode-cluster"><span class="nav-text">–deploy-mode cluster</span></a></li></ol></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#十-宽窄依赖"><span class="nav-text">十. 宽窄依赖</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#十一-Stage-划分"><span class="nav-text">十一. Stage 划分</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#十二-Spark-任务调度"><span class="nav-text">十二. Spark 任务调度</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-简版"><span class="nav-text">1.简版</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-完整版"><span class="nav-text">2.完整版</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#十三-TopN-案例"><span class="nav-text">十三. TopN 案例</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#十四-网站访问日志分析"><span class="nav-text">十四. 网站访问日志分析</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#需求分析"><span class="nav-text">需求分析</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Data"><span class="nav-text">Data</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Code"><span class="nav-text">Code</span></a></li></ol></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">airpoet</span>

  
</div>









        
<div class="busuanzi-count">
  <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv">
      本站访客数
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
      人次
    </span>
  

  
    <span class="site-pv">
      本站总访问量
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
      次
    </span>
  
</div>








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
          <span id="scrollpercent"><span>0</span>%</span>
        
      </div>
    

    
      <div id="needsharebutton-float">
        <span class="btn">
          <i class="fa fa-share-alt" aria-hidden="true"></i>
        </span>
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  

    
      <script id="dsq-count-scr" src="https://A.P.disqus.com/count.js" async></script>
    

    
      <script type="text/javascript">
        var disqus_config = function () {
          this.page.url = 'https://airpoet.github.io/2018/07/25/Spark/Spark重点解析(一) => SparkCore/';
          this.page.identifier = '2018/07/25/Spark/Spark重点解析(一) => SparkCore/';
          this.page.title = 'Spark重点解析(一) => SparkCore';
        };
        var d = document, s = d.createElement('script');
        s.src = 'https://A.P.disqus.com/embed.js';
        s.setAttribute('data-timestamp', '' + +new Date());
        (d.head || d.body).appendChild(s);
      </script>
    

  




	





  














  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  

  
  
  
  <link rel="stylesheet" href="/lib/needsharebutton/needsharebutton.css">

  
  
  <script src="/lib/needsharebutton/needsharebutton.js"></script>

  <script>
    
    
      flOptions = {};
      
          flOptions.iconStyle = "box";
      
          flOptions.boxForm = "horizontal";
      
          flOptions.position = "middleRight";
      
          flOptions.networks = "Weibo,Twitter,Facebook";
      
      new needShareButton('#needsharebutton-float', flOptions);
    
  </script>

  

  

  
  <script type="text/javascript" src="/js/src/js.cookie.js?v=5.1.4"></script>
  <script type="text/javascript" src="/js/src/scroll-cookie.js?v=5.1.4"></script>


  

</body>
</html>
