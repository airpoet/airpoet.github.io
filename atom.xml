<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>A.P的文艺杂谈</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://airpoet.github.io/"/>
  <updated>2018-06-09T17:19:40.887Z</updated>
  <id>https://airpoet.github.io/</id>
  
  <author>
    <name>airpoet</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>▍开始</title>
    <link href="https://airpoet.github.io/2018/06/10/Poetry/%E5%BC%80%E5%A7%8B/"/>
    <id>https://airpoet.github.io/2018/06/10/Poetry/开始/</id>
    <published>2018-06-09T17:03:10.001Z</published>
    <updated>2018-06-09T17:19:40.887Z</updated>
    
    <content type="html"><![CDATA[<blockquote class="blockquote-center"><p><img src="http://p6i5vzkfk.bkt.clouddn.com/study/2018-06-09-601528563678_.pic.jpg" alt=""></p><p>月亮落下一两片羽毛在田野上。</p><p>黑暗中的麦子聆听着。</p><p>快静下来。</p><p>快。</p><p>就在那儿，月亮的孩子们正试着</p><p>挥动翅膀。</p><p>在两棵树之间，身材修长的女子抬起面庞，</p><p>美丽的剪影。接着，她步入空中，接着，</p><p>她完全消失在空中。</p><p>我独自站在一棵接骨木旁，不敢呼吸，</p><p>也不敢动。</p><p>我聆听着。</p><p>麦子向后靠着自己的黑暗，</p><p>而我靠着我的。</p><p><br></p><p><strong>作者 / [美国] 詹姆斯·赖特</strong></p><p>翻译 / 张文武</p><hr><h3 id="▍Beginning"><a href="#▍Beginning" class="headerlink" title="▍Beginning"></a><strong>▍Beginning</strong></h3><p><br></p><p>The moon drops one or two feathers into the fields.</p><p>The dark wheat listens.</p><p>Be still.</p><p>Now.</p><p>There they are, the moon’s young, trying</p><p>Their wings.</p><p>Between trees, a slender woman lifts up the lovely shadow</p><p>Of her face, and now she steps into the air, now she is gone</p><p>Wholly, into the air.</p><p>I stand alone by an elder tree, I do not dare breathe</p><p>Or move.</p><p>I listen.</p><p>The wheat leans back toward its own darkness,</p><p>And I lean toward mine.</p><p><br></p><p><strong>Author / James Wright</strong></p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote class=&quot;blockquote-center&quot;&gt;&lt;p&gt;&lt;img src=&quot;http://p6i5vzkfk.bkt.clouddn.com/study/2018-06-09-601528563678_.pic.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;月
      
    
    </summary>
    
      <category term="文艺" scheme="https://airpoet.github.io/categories/%E6%96%87%E8%89%BA/"/>
    
      <category term="诗歌" scheme="https://airpoet.github.io/categories/%E6%96%87%E8%89%BA/%E8%AF%97%E6%AD%8C/"/>
    
    
      <category term="诗歌" scheme="https://airpoet.github.io/tags/%E8%AF%97%E6%AD%8C/"/>
    
  </entry>
  
  <entry>
    <title>Markdown高阶语法</title>
    <link href="https://airpoet.github.io/2018/06/10/Tools/Markdown/Markdown%E9%AB%98%E9%98%B6%E8%AF%AD%E6%B3%95/"/>
    <id>https://airpoet.github.io/2018/06/10/Tools/Markdown/Markdown高阶语法/</id>
    <published>2018-06-09T16:49:50.407Z</published>
    <updated>2018-06-09T17:00:02.378Z</updated>
    
    <content type="html"><![CDATA[<h3 id="时序图的写法"><a href="#时序图的写法" class="headerlink" title="时序图的写法"></a>时序图的写法</h3><p><img src="http://p6i5vzkfk.bkt.clouddn.com/study/2018-06-09-165900.png" alt="image-20180610005859980"></p><div id="sequence-0"></div><h3 id="流程图的写法"><a href="#流程图的写法" class="headerlink" title="流程图的写法"></a>流程图的写法</h3><p><img src="http://p6i5vzkfk.bkt.clouddn.com/study/2018-06-09-165930.png" alt="image-20180610005930019"></p><div id="flowchart-0" class="flow-chart"></div><h3 id="类图的写法"><a href="#类图的写法" class="headerlink" title="类图的写法"></a>类图的写法</h3><p><img src="http://p6i5vzkfk.bkt.clouddn.com/study/2018-06-09-165948.png" alt="image-20180610005948130"></p><p><img src="https://www.plantuml.com/plantuml/svg/SoWkIImgAStDuKhEIImkLl2jz4qiA4Wjud98pKi12WC0"></p><p><script src="https://cdnjs.cloudflare.com/ajax/libs/raphael/2.2.7/raphael.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/flowchart/1.6.5/flowchart.min.js"></script><textarea id="flowchart-0-code" style="display: none">st=>start: Start|past:>http://www.google.com[blank]e=>end: End:>http://www.google.comop1=>operation: My Operation|pastop2=>operation: Stuff|currentsub1=>subroutine: My Subroutine|invalidcond=>condition: Yesor No?|approved:>http://www.google.comc2=>condition: Good idea|rejectedio=>inputoutput: catch something...|requestst->op1(right)->condcond(yes, right)->c2cond(no)->sub1(left)->op1c2(yes)->io->ec2(no)->op2->e</textarea><textarea id="flowchart-0-options" style="display: none">{"theme":"simple","scale":1,"line-width":2,"line-length":50,"text-margin":10,"font-size":12}</textarea><script>  var code = document.getElementById("flowchart-0-code").value;  var options = JSON.parse(decodeURIComponent(document.getElementById("flowchart-0-options").value));  var diagram = flowchart.parse(code);  diagram.drawSVG("flowchart-0", options);</script><script src="https://cdnjs.cloudflare.com/ajax/libs/webfont/1.6.27/webfontloader.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/snap.svg/0.4.1/snap.svg-min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/underscore.js/1.8.3/underscore-min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/js-sequence-diagrams/1.0.6/sequence-diagram-min.js"></script><textarea id="sequence-0-code" style="display: none">Alice->Bob: Hello Bob, how are you?Note right of Bob: Bob thinksBob-->Alice: I am good thanks!</textarea><textarea id="sequence-0-options" style="display: none">{"theme":"simple","scale":1,"line-width":2,"line-length":50,"text-margin":10,"font-size":12}</textarea><script>  var code = document.getElementById("sequence-0-code").value;  var options = JSON.parse(decodeURIComponent(document.getElementById("sequence-0-options").value));  var diagram = Diagram.parse(code);  diagram.drawSVG("sequence-0", options);</script></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;时序图的写法&quot;&gt;&lt;a href=&quot;#时序图的写法&quot; class=&quot;headerlink&quot; title=&quot;时序图的写法&quot;&gt;&lt;/a&gt;时序图的写法&lt;/h3&gt;&lt;p&gt;&lt;img src=&quot;http://p6i5vzkfk.bkt.clouddn.com/study/2018-
      
    
    </summary>
    
      <category term="工具" scheme="https://airpoet.github.io/categories/%E5%B7%A5%E5%85%B7/"/>
    
      <category term="Markdown" scheme="https://airpoet.github.io/categories/%E5%B7%A5%E5%85%B7/Markdown/"/>
    
    
      <category term="原创" scheme="https://airpoet.github.io/tags/%E5%8E%9F%E5%88%9B/"/>
    
      <category term="工具" scheme="https://airpoet.github.io/tags/%E5%B7%A5%E5%85%B7/"/>
    
      <category term="Markdown" scheme="https://airpoet.github.io/tags/Markdown/"/>
    
  </entry>
  
  <entry>
    <title>About Sublime Text3</title>
    <link href="https://airpoet.github.io/2018/06/09/Tools/Sublime/%E5%AE%89%E8%A3%85%E4%B8%BB%E9%A2%98/"/>
    <id>https://airpoet.github.io/2018/06/09/Tools/Sublime/安装主题/</id>
    <published>2018-06-09T04:43:17.189Z</published>
    <updated>2018-06-09T17:32:59.833Z</updated>
    
    <content type="html"><![CDATA[<h3 id="主题"><a href="#主题" class="headerlink" title="主题"></a>主题</h3><p><a href="https://scotch.io/bar-talk/best-sublime-text-3-themes-of-2015-and-2016" target="_blank" rel="noopener">详情参见这个网站</a></p><h3 id="详细操作"><a href="#详细操作" class="headerlink" title="详细操作"></a>详细操作</h3><p><a href="http://zh.lucida.me/blog/sublime-text-complete-guide/" target="_blank" rel="noopener">见此站</a></p><div id="sequence-0"></div><p><script src="https://cdnjs.cloudflare.com/ajax/libs/webfont/1.6.27/webfontloader.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/snap.svg/0.4.1/snap.svg-min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/underscore.js/1.8.3/underscore-min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/js-sequence-diagrams/1.0.6/sequence-diagram-min.js"></script><textarea id="sequence-0-code" style="display: none">ff->fa: fa-->bd:</textarea><textarea id="sequence-0-options" style="display: none">{"theme":"simple","scale":1,"line-width":2,"line-length":50,"text-margin":10,"font-size":12}</textarea><script>  var code = document.getElementById("sequence-0-code").value;  var options = JSON.parse(decodeURIComponent(document.getElementById("sequence-0-options").value));  var diagram = Diagram.parse(code);  diagram.drawSVG("sequence-0", options);</script></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;主题&quot;&gt;&lt;a href=&quot;#主题&quot; class=&quot;headerlink&quot; title=&quot;主题&quot;&gt;&lt;/a&gt;主题&lt;/h3&gt;&lt;p&gt;&lt;a href=&quot;https://scotch.io/bar-talk/best-sublime-text-3-themes-of-2015
      
    
    </summary>
    
      <category term="工具" scheme="https://airpoet.github.io/categories/%E5%B7%A5%E5%85%B7/"/>
    
      <category term="Sublime" scheme="https://airpoet.github.io/categories/%E5%B7%A5%E5%85%B7/Sublime/"/>
    
    
      <category term="原创" scheme="https://airpoet.github.io/tags/%E5%8E%9F%E5%88%9B/"/>
    
      <category term="工具" scheme="https://airpoet.github.io/tags/%E5%B7%A5%E5%85%B7/"/>
    
      <category term="Sublime" scheme="https://airpoet.github.io/tags/Sublime/"/>
    
  </entry>
  
  <entry>
    <title>MapReduce笔记-Bug汇总</title>
    <link href="https://airpoet.github.io/2018/06/09/Hadoop/Study/MapReduce%E7%AC%94%E8%AE%B0-Bug%E6%B1%87%E6%80%BB/"/>
    <id>https://airpoet.github.io/2018/06/09/Hadoop/Study/MapReduce笔记-Bug汇总/</id>
    <published>2018-06-09T03:11:48.470Z</published>
    <updated>2018-06-09T03:25:45.830Z</updated>
    
    <content type="html"><![CDATA[<h4 id="1、reduce-输出路径必须是新创建的。不能已经存在"><a href="#1、reduce-输出路径必须是新创建的。不能已经存在" class="headerlink" title="1、reduce 输出路径必须是新创建的。不能已经存在"></a>1、reduce 输出路径必须是新创建的。不能已经存在</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Exception in thread <span class="string">"main"</span> org.apache.hadoop.mapred.FileAlreadyExistsException: Output directory hdfs:<span class="comment">//cs1:9000/flowout01 already exists</span></span><br></pre></td></tr></table></figure><h4 id="2、在初始化-job-的时候，-没有传-conf-，-导致后面一直找不到文件，-因为不知道到哪里去找"><a href="#2、在初始化-job-的时候，-没有传-conf-，-导致后面一直找不到文件，-因为不知道到哪里去找" class="headerlink" title="2、在初始化 job 的时候， 没有传 conf ， 导致后面一直找不到文件， 因为不知道到哪里去找"></a>2、在初始化 job 的时候， 没有传 <code>conf</code> ， 导致后面一直找不到文件， 因为不知道到哪里去找</h4><h4 id="3、Text导包倒错-导的时候要注意"><a href="#3、Text导包倒错-导的时候要注意" class="headerlink" title="3、Text导包倒错, 导的时候要注意"></a>3、Text导包倒错, 导的时候要注意</h4><p><strong>应该是这个 <code>import org.apache.hadoop.io.Text;</code></strong></p><h4 id="4、进行字符串拼接的时候，把-StringBuilder-写到了-reduce-方法外，-这样导致-sb-会越来越多，当然，也可以每次拼接完了清空"><a href="#4、进行字符串拼接的时候，把-StringBuilder-写到了-reduce-方法外，-这样导致-sb-会越来越多，当然，也可以每次拼接完了清空" class="headerlink" title="4、进行字符串拼接的时候，把 StringBuilder 写到了 reduce 方法外， 这样导致 sb 会越来越多，当然，也可以每次拼接完了清空"></a>4、进行字符串拼接的时候，把 <strong>StringBuilder 写到了 reduce 方法外</strong>， 这样导致 sb 会越来越多，当然，也可以每次拼接完了清空</h4><p>类似于这样</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">AF,I,O,K,G,D,C,H,B</span><br><span class="line">BF,I,O,K,G,D,C,H,B,E,J,F,A</span><br><span class="line">CF,I,O,K,G,D,C,H,B,E,J,F,A,B,E,K,A,H,G,F</span><br><span class="line">DF,I,O,K,G,D,C,H,B,E,J,F,A,B,E,K,A,H,G,F,H,C,G,F,E,A,K,L</span><br><span class="line">EF,I,O,K,G,D,C,H,B,E,J,F,A,B,E,K,A,H,G,F,H,C,G,F,E,A,K,L,A,B,L,G,M,F,D,H</span><br><span class="line">FF,I,O,K,G,D,C,H,B,E,J,F,A,B,E,K,A,H,G,F,H,C,G,F,E,A,K,L,A,B,L,G,M,F,D,H,C,M,L,A,D,G</span><br><span class="line">GF,I,O,K,G,D,C,H,B,E,J,F,A,B,E,K,A,H,G,F,H,C,G,F,E,A,K,L,A,B,L,G,M,F,D,H,C,M,L,A,D,G,M</span><br><span class="line">HF,I,O,K,G,D,C,H,B,E,J,F,A,B,E,K,A,H,G,F,H,C,G,F,E,A,K,L,A,B,L,G,M,F,D,H,C,M,L,A,D,G,M,O</span><br><span class="line">IF,I,O,K,G,D,C,H,B,E,J,F,A,B,E,K,A,H,G,F,H,C,G,F,E,A,K,L,A,B,L,G,M,F,D,H,C,M,L,A,D,G,M,O,O,C</span><br><span class="line">JF,I,O,K,G,D,C,H,B,E,J,F,A,B,E,K,A,H,G,F,H,C,G,F,E,A,K,L,A,B,L,G,M,F,D,H,C,M,L,A,D,G,M,O,O,C,O</span><br><span class="line">KF,I,O,K,G,D,C,H,B,E,J,F,A,B,E,K,A,H,G,F,H,C,G,F,E,A,K,L,A,B,L,G,M,F,D,H,C,M,L,A,D,G,M,O,O,C,O,O,B</span><br><span class="line">LF,I,O,K,G,D,C,H,B,E,J,F,A,B,E,K,A,H,G,F,H,C,G,F,E,A,K,L,A,B,L,G,M,F,D,H,C,M,L,A,D,G,M,O,O,C,O,O,B,D,E</span><br><span class="line">MF,I,O,K,G,D,C,H,B,E,J,F,A,B,E,K,A,H,G,F,H,C,G,F,E,A,K,L,A,B,L,G,M,F,D,H,C,M,L,A,D,G,M,O,O,C,O,O,B,D,E,E,F</span><br><span class="line">OF,I,O,K,G,D,C,H,B,E,J,F,A,B,E,K,A,H,G,F,H,C,G,F,E,A,K,L,A,B,L,G,M,F,D,H,C,M,L,A,D,G,M,O,O,C,O,O,B,D,E,E,F,A,H,I,J,F</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;1、reduce-输出路径必须是新创建的。不能已经存在&quot;&gt;&lt;a href=&quot;#1、reduce-输出路径必须是新创建的。不能已经存在&quot; class=&quot;headerlink&quot; title=&quot;1、reduce 输出路径必须是新创建的。不能已经存在&quot;&gt;&lt;/a&gt;1、red
      
    
    </summary>
    
      <category term="Hadoop" scheme="https://airpoet.github.io/categories/Hadoop/"/>
    
      <category term="学习笔记" scheme="https://airpoet.github.io/categories/Hadoop/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="原创" scheme="https://airpoet.github.io/tags/%E5%8E%9F%E5%88%9B/"/>
    
      <category term="技术" scheme="https://airpoet.github.io/tags/%E6%8A%80%E6%9C%AF/"/>
    
      <category term="Hadoop" scheme="https://airpoet.github.io/tags/Hadoop/"/>
    
      <category term="MapReduce" scheme="https://airpoet.github.io/tags/MapReduce/"/>
    
  </entry>
  
  <entry>
    <title>MapReduce笔记-练习</title>
    <link href="https://airpoet.github.io/2018/06/09/Hadoop/Study/MapReduce%E7%AC%94%E8%AE%B0-%E7%BB%83%E4%B9%A0/"/>
    <id>https://airpoet.github.io/2018/06/09/Hadoop/Study/MapReduce笔记-练习/</id>
    <published>2018-06-09T03:11:16.234Z</published>
    <updated>2018-06-09T17:34:37.604Z</updated>
    
    <content type="html"><![CDATA[<h2 id="求微博共同粉丝"><a href="#求微博共同粉丝" class="headerlink" title="求微博共同粉丝"></a>求微博共同粉丝</h2><h3 id="题目"><a href="#题目" class="headerlink" title="题目"></a>题目</h3><p><strong>涉及知识点： 多 Job 串联</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">A:B,C,D,F,E,O</span><br><span class="line">B:A,C,E,K</span><br><span class="line">C:F,A,D,I</span><br><span class="line">D:A,E,F,L</span><br><span class="line">E:B,C,D,M,L</span><br><span class="line">F:A,B,C,D,E,O,M</span><br><span class="line">G:A,C,D,E,F</span><br><span class="line">H:A,C,D,E,O</span><br><span class="line">I:A,O</span><br><span class="line">J:B,O</span><br><span class="line">K:A,C,D</span><br><span class="line">L:D,E,F</span><br><span class="line">M:E,F,G</span><br><span class="line">O:A,H,I,J,K</span><br></pre></td></tr></table></figure><blockquote><p>以上是数据：<br>A:B,C,D,F,E,O<br>表示：A用户 关注B,C,D,E,F,O</p><blockquote><p>求所有两两用户之间的共同关注对象</p></blockquote></blockquote><h3 id="答案："><a href="#答案：" class="headerlink" title="答案："></a>答案：</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.rox.mapreduce.mr3._01_多Job串联;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.LongWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Job;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Mapper;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Reducer;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.jobcontrol.JobControl;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CommonFansDemo</span> </span>&#123;</span><br><span class="line"><span class="meta">@SuppressWarnings</span>(<span class="string">"deprecation"</span>)</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line"><span class="comment">// Job 逻辑</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 指定 HDFS 相关的参数</span></span><br><span class="line">Configuration conf = <span class="keyword">new</span> Configuration();</span><br><span class="line">conf.set(<span class="string">"fs.defaultFS"</span>, <span class="string">"hdfs://cs1:9000"</span>);</span><br><span class="line">System.setProperty(<span class="string">"HADOOP_USER_NAME"</span>, <span class="string">"ap"</span>);</span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// 新建一个 job1</span></span><br><span class="line">Job job1 = Job.getInstance(conf);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 设置 Jar 包所在路径</span></span><br><span class="line">job1.setJarByClass(CommonFansDemo.class);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 指定 mapper 类和 reducer 类</span></span><br><span class="line">job1.setMapperClass(MyMapper_Step1.class);</span><br><span class="line">job1.setReducerClass(MyReducer_Step1.class);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 指定 maptask 的输出类型</span></span><br><span class="line">job1.setMapOutputKeyClass(Text.class);</span><br><span class="line">job1.setMapOutputValueClass(Text.class);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 指定最终的输出类型(reduce存在时,就是指 ReduceTask 的输出类型)</span></span><br><span class="line">job1.setOutputKeyClass(Text.class);</span><br><span class="line">job1.setOutputValueClass(Text.class);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 指定该 MapReduce 程序数据的输入输出路径</span></span><br><span class="line">FileInputFormat.setInputPaths(job1, <span class="keyword">new</span> Path(<span class="string">"/in/commonfriend"</span>));</span><br><span class="line">FileOutputFormat.setOutputPath(job1, <span class="keyword">new</span> Path(<span class="string">"/out/job1"</span>));</span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// 新建一个 job2</span></span><br><span class="line">Job job2 = Job.getInstance(conf);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 设置 Jar 包所在路径</span></span><br><span class="line">job2.setJarByClass(CommonFansDemo.class);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 指定 mapper 类和 reducer 类</span></span><br><span class="line">job2.setMapperClass(MyMapper_Step2.class);</span><br><span class="line">job2.setReducerClass(MyReducer_Step2.class);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 指定 maptask 的输出类型</span></span><br><span class="line">job2.setMapOutputKeyClass(Text.class);</span><br><span class="line">job2.setMapOutputValueClass(Text.class);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 指定最终的输出类型(reduce存在时,就是指 ReduceTask 的输出类型)</span></span><br><span class="line">job2.setOutputKeyClass(Text.class);</span><br><span class="line">job2.setOutputValueClass(Text.class);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 指定该 MapReduce 程序数据的输入输出路径</span></span><br><span class="line">FileInputFormat.setInputPaths(job2, <span class="keyword">new</span> Path(<span class="string">"/out/job1"</span>));</span><br><span class="line">FileOutputFormat.setOutputPath(job2, <span class="keyword">new</span> Path(<span class="string">"/out/job2"</span>));</span><br><span class="line"></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 将多个 job 当做一个组中的 job 提交, 参数名是组名</span></span><br><span class="line"><span class="comment"> * 注意: JobControl 是实现了 Runnable 接口的 </span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line">JobControl jControl = <span class="keyword">new</span> JobControl(<span class="string">"common_friend"</span>);</span><br><span class="line"><span class="comment">// 将原生的 job携带配置 转换为可控的 job</span></span><br><span class="line">ControlledJob aJob = <span class="keyword">new</span> ControlledJob(job1.getConfiguration());</span><br><span class="line">ControlledJob bJob = <span class="keyword">new</span> ControlledJob(job2.getConfiguration());</span><br><span class="line"><span class="comment">// 添加依赖关系</span></span><br><span class="line">bJob.addDependingJob(aJob);</span><br><span class="line"><span class="comment">// 添加 job 到组中</span></span><br><span class="line">jControl.addJob(aJob);</span><br><span class="line">jControl.addJob(bJob);</span><br><span class="line"><span class="comment">// 启动一个线程</span></span><br><span class="line">Thread jobThread = <span class="keyword">new</span> Thread(jControl);</span><br><span class="line">jobThread.start();</span><br><span class="line"><span class="keyword">while</span> (!jControl.allFinished()) &#123;</span><br><span class="line">Thread.sleep(<span class="number">500</span>);</span><br><span class="line">&#125;</span><br><span class="line">jobThread.stop();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">MyMapper_Step1</span> <span class="keyword">extends</span> <span class="title">Mapper</span>&lt;<span class="title">LongWritable</span>, <span class="title">Text</span>, <span class="title">Text</span>, <span class="title">Text</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">String[] user_attentions;</span><br><span class="line">String[] attentions;</span><br><span class="line">Text k = <span class="keyword">new</span> Text();</span><br><span class="line">Text v = <span class="keyword">new</span> Text();</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">map</span><span class="params">(LongWritable key, Text value,</span></span></span><br><span class="line"><span class="function"><span class="params">Mapper&lt;LongWritable, Text, Text, Text&gt;.Context context)</span></span></span><br><span class="line"><span class="function"><span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line"></span><br><span class="line">user_attentions = value.toString().split(<span class="string">":"</span>);</span><br><span class="line">attentions = user_attentions[<span class="number">1</span>].trim().split(<span class="string">","</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> (String att : attentions) &#123;</span><br><span class="line">k.set(att);</span><br><span class="line">v.set(user_attentions[<span class="number">0</span>].trim());</span><br><span class="line">context.write(k, v);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> shixuanji</span></span><br><span class="line"><span class="comment"> * 将两两粉丝(普通用户)拼接起来, 格式a-f:c =&gt; a,b 都共同关注了 c</span></span><br><span class="line"><span class="comment"> * </span></span><br><span class="line"><span class="comment"> *  AF,I,O,K,G,D,C,H,B</span></span><br><span class="line"><span class="comment">BE,J,F,A</span></span><br><span class="line"><span class="comment">CB,E,K,A,H,G,F</span></span><br><span class="line"><span class="comment">DH,C,G,F,E,A,K,L</span></span><br><span class="line"><span class="comment">EA,B,L,G,M,F,D,H</span></span><br><span class="line"><span class="comment">FC,M,L,A,D,G</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">MyMapper_Step2</span> <span class="keyword">extends</span> <span class="title">Mapper</span>&lt;<span class="title">LongWritable</span>, <span class="title">Text</span>, <span class="title">Text</span>, <span class="title">Text</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">String[] attenion_users;</span><br><span class="line">String[] users;</span><br><span class="line">Text k = <span class="keyword">new</span> Text();</span><br><span class="line">Text v = <span class="keyword">new</span> Text();</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">map</span><span class="params">(LongWritable key, Text value,</span></span></span><br><span class="line"><span class="function"><span class="params">Mapper&lt;LongWritable, Text, Text, Text&gt;.Context context)</span></span></span><br><span class="line"><span class="function"><span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line">attenion_users = value.toString().split(<span class="string">"\t"</span>);</span><br><span class="line">users = attenion_users[<span class="number">1</span>].trim().split(<span class="string">","</span>);</span><br><span class="line"><span class="keyword">for</span> (String u1 : users) &#123;</span><br><span class="line"><span class="keyword">for</span> (String u2 : users) &#123;</span><br><span class="line"><span class="keyword">if</span> (u1.compareTo(u2) &lt; <span class="number">0</span>) &#123;</span><br><span class="line">String users = u1 + <span class="string">"-"</span> + u2;</span><br><span class="line">k.set(users);</span><br><span class="line">v.set(attenion_users[<span class="number">0</span>].trim());</span><br><span class="line">context.write(k, v);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> shixuanji</span></span><br><span class="line"><span class="comment"> *需要统计的是, 某人拥有的全部粉丝</span></span><br><span class="line"><span class="comment"> *  key: 传过来的 key</span></span><br><span class="line"><span class="comment"> *  value:  用,分割 </span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">MyReducer_Step1</span> <span class="keyword">extends</span> <span class="title">Reducer</span>&lt;<span class="title">Text</span>, <span class="title">Text</span>, <span class="title">Text</span>, <span class="title">Text</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">Text k = <span class="keyword">new</span> Text();</span><br><span class="line">Text v = <span class="keyword">new</span> Text();</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">reduce</span><span class="params">(Text key, Iterable&lt;Text&gt; values,</span></span></span><br><span class="line"><span class="function"><span class="params">Reducer&lt;Text, Text, Text, Text&gt;.Context context)</span></span></span><br><span class="line"><span class="function"><span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 注意: 这里 sb 不能写在外面,会不断的拼接</span></span><br><span class="line">StringBuilder sb = <span class="keyword">new</span> StringBuilder();</span><br><span class="line"><span class="keyword">for</span> (Text v : values) &#123;</span><br><span class="line">sb.append(v.toString()).append(<span class="string">","</span>);</span><br><span class="line">&#125;</span><br><span class="line">k.set(key);</span><br><span class="line">v.set(sb.substring(<span class="number">0</span>, sb.length() - <span class="number">1</span>));</span><br><span class="line">context.write(k, v);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> shixuanji</span></span><br><span class="line"><span class="comment"> * 拿到的数据: a-b c</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">MyReducer_Step2</span> <span class="keyword">extends</span> <span class="title">Reducer</span>&lt;<span class="title">Text</span>, <span class="title">Text</span>, <span class="title">Text</span>, <span class="title">Text</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">Text k = <span class="keyword">new</span> Text();</span><br><span class="line">Text v = <span class="keyword">new</span> Text();</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">reduce</span><span class="params">(Text key, Iterable&lt;Text&gt; values,</span></span></span><br><span class="line"><span class="function"><span class="params">Reducer&lt;Text, Text, Text, Text&gt;.Context context)</span></span></span><br><span class="line"><span class="function"><span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line">StringBuilder sb = <span class="keyword">new</span> StringBuilder();</span><br><span class="line"><span class="keyword">for</span> (Text attention : values) &#123;</span><br><span class="line">sb.append(attention.toString()).append(<span class="string">","</span>);</span><br><span class="line">&#125;</span><br><span class="line">k.set(key);</span><br><span class="line">v.set(sb.substring(<span class="number">0</span>, sb.length() - <span class="number">1</span>));</span><br><span class="line">context.write(k, v);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">// job1的输出</span></span><br><span class="line">AF,I,O,K,G,D,C,H,B</span><br><span class="line">BE,J,F,A</span><br><span class="line">CB,E,K,A,H,G,F</span><br><span class="line">DH,C,G,F,E,A,K,L</span><br><span class="line">EA,B,L,G,M,F,D,H</span><br><span class="line">FC,M,L,A,D,G</span><br><span class="line">GM</span><br><span class="line">HO</span><br><span class="line">IO,C</span><br><span class="line">JO</span><br><span class="line">KO,B</span><br><span class="line">LD,E</span><br><span class="line">ME,F</span><br><span class="line">OA,H,I,J,F</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">// job2的输出</span></span><br><span class="line">A-BE,C</span><br><span class="line">A-CD,F</span><br><span class="line">A-DF,E</span><br><span class="line">A-EC,D,B</span><br><span class="line">A-FO,B,E,D,C</span><br><span class="line">A-GE,F,D,C</span><br><span class="line">A-HO,E,D,C</span><br><span class="line">A-IO</span><br><span class="line">A-JB,O</span><br><span class="line">A-KD,C</span><br><span class="line">A-LD,F,E</span><br><span class="line">A-ME,F</span><br><span class="line">B-CA</span><br><span class="line">B-DE,A</span><br><span class="line">B-EC</span><br><span class="line">B-FA,E,C</span><br><span class="line">B-GC,A,E</span><br><span class="line">B-HA,E,C</span><br><span class="line">B-IA</span><br><span class="line">B-KC,A</span><br><span class="line">B-LE</span><br><span class="line">B-ME</span><br><span class="line">B-OA,K</span><br><span class="line">C-DA,F</span><br><span class="line">C-ED</span><br><span class="line">C-FD,A</span><br><span class="line">C-GF,A,D</span><br><span class="line">C-HD,A</span><br><span class="line">C-IA</span><br><span class="line">C-KA,D</span><br><span class="line">C-LF,D</span><br><span class="line">C-MF</span><br><span class="line">C-OI,A</span><br><span class="line">D-EL</span><br><span class="line">D-FE,A</span><br><span class="line">D-GA,F,E</span><br><span class="line">D-HE,A</span><br><span class="line">D-IA</span><br><span class="line">D-KA</span><br><span class="line">D-LF,E</span><br><span class="line">D-MF,E</span><br><span class="line">D-OA</span><br><span class="line">E-FC,B,M,D</span><br><span class="line">E-GC,D</span><br><span class="line">E-HC,D</span><br><span class="line">E-JB</span><br><span class="line">E-KD,C</span><br><span class="line">E-LD</span><br><span class="line">F-GA,D,C,E</span><br><span class="line">F-HA,E,C,D,O</span><br><span class="line">F-IO,A</span><br><span class="line">F-JO,B</span><br><span class="line">F-KC,A,D</span><br><span class="line">F-LE,D</span><br><span class="line">F-ME</span><br><span class="line">F-OA</span><br><span class="line">G-HA,C,D,E</span><br><span class="line">G-IA</span><br><span class="line">G-KC,A,D</span><br><span class="line">G-LD,E,F</span><br><span class="line">G-MF,E</span><br><span class="line">G-OA</span><br><span class="line">H-IO,A</span><br><span class="line">H-JO</span><br><span class="line">H-KA,D,C</span><br><span class="line">H-LE,D</span><br><span class="line">H-ME</span><br><span class="line">H-OA</span><br><span class="line">I-JO</span><br><span class="line">I-KA</span><br><span class="line">I-OA</span><br><span class="line">K-LD</span><br><span class="line">K-OA</span><br><span class="line">L-MF,E</span><br></pre></td></tr></table></figure><h2 id="求学生成绩"><a href="#求学生成绩" class="headerlink" title="求学生成绩"></a>求学生成绩</h2><h3 id="题目-1"><a href="#题目-1" class="headerlink" title="题目"></a>题目</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">computer,huangxiaoming,<span class="number">85</span>,<span class="number">86</span>,<span class="number">41</span>,<span class="number">75</span>,<span class="number">93</span>,<span class="number">42</span>,<span class="number">85</span></span><br><span class="line">computer,xuzheng,<span class="number">54</span>,<span class="number">52</span>,<span class="number">86</span>,<span class="number">91</span>,<span class="number">42</span></span><br><span class="line">computer,huangbo,<span class="number">85</span>,<span class="number">42</span>,<span class="number">96</span>,<span class="number">38</span></span><br><span class="line">english,zhaobenshan,<span class="number">54</span>,<span class="number">52</span>,<span class="number">86</span>,<span class="number">91</span>,<span class="number">42</span>,<span class="number">85</span>,<span class="number">75</span></span><br><span class="line">english,liuyifei,<span class="number">85</span>,<span class="number">41</span>,<span class="number">75</span>,<span class="number">21</span>,<span class="number">85</span>,<span class="number">96</span>,<span class="number">14</span></span><br><span class="line">algorithm,liuyifei,<span class="number">75</span>,<span class="number">85</span>,<span class="number">62</span>,<span class="number">48</span>,<span class="number">54</span>,<span class="number">96</span>,<span class="number">15</span></span><br><span class="line">computer,huangjiaju,<span class="number">85</span>,<span class="number">75</span>,<span class="number">86</span>,<span class="number">85</span>,<span class="number">85</span></span><br><span class="line">english,liuyifei,<span class="number">76</span>,<span class="number">95</span>,<span class="number">86</span>,<span class="number">74</span>,<span class="number">68</span>,<span class="number">74</span>,<span class="number">48</span></span><br><span class="line">english,huangdatou,<span class="number">48</span>,<span class="number">58</span>,<span class="number">67</span>,<span class="number">86</span>,<span class="number">15</span>,<span class="number">33</span>,<span class="number">85</span></span><br><span class="line">algorithm,huanglei,<span class="number">76</span>,<span class="number">95</span>,<span class="number">86</span>,<span class="number">74</span>,<span class="number">68</span>,<span class="number">74</span>,<span class="number">48</span></span><br><span class="line">algorithm,huangjiaju,<span class="number">85</span>,<span class="number">75</span>,<span class="number">86</span>,<span class="number">85</span>,<span class="number">85</span>,<span class="number">74</span>,<span class="number">86</span></span><br><span class="line">computer,huangdatou,<span class="number">48</span>,<span class="number">58</span>,<span class="number">67</span>,<span class="number">86</span>,<span class="number">15</span>,<span class="number">33</span>,<span class="number">85</span></span><br><span class="line">english,zhouqi,<span class="number">85</span>,<span class="number">86</span>,<span class="number">41</span>,<span class="number">75</span>,<span class="number">93</span>,<span class="number">42</span>,<span class="number">85</span>,<span class="number">75</span>,<span class="number">55</span>,<span class="number">47</span>,<span class="number">22</span></span><br><span class="line">english,huangbo,<span class="number">85</span>,<span class="number">42</span>,<span class="number">96</span>,<span class="number">38</span>,<span class="number">55</span>,<span class="number">47</span>,<span class="number">22</span></span><br><span class="line">algorithm,liutao,<span class="number">85</span>,<span class="number">75</span>,<span class="number">85</span>,<span class="number">99</span>,<span class="number">66</span></span><br><span class="line">computer,huangzitao,<span class="number">85</span>,<span class="number">86</span>,<span class="number">41</span>,<span class="number">75</span>,<span class="number">93</span>,<span class="number">42</span>,<span class="number">85</span></span><br><span class="line">math,wangbaoqiang,<span class="number">85</span>,<span class="number">86</span>,<span class="number">41</span>,<span class="number">75</span>,<span class="number">93</span>,<span class="number">42</span>,<span class="number">85</span></span><br><span class="line">computer,liujialing,<span class="number">85</span>,<span class="number">41</span>,<span class="number">75</span>,<span class="number">21</span>,<span class="number">85</span>,<span class="number">96</span>,<span class="number">14</span>,<span class="number">74</span>,<span class="number">86</span></span><br><span class="line">computer,liuyifei,<span class="number">75</span>,<span class="number">85</span>,<span class="number">62</span>,<span class="number">48</span>,<span class="number">54</span>,<span class="number">96</span>,<span class="number">15</span></span><br><span class="line">computer,liutao,<span class="number">85</span>,<span class="number">75</span>,<span class="number">85</span>,<span class="number">99</span>,<span class="number">66</span>,<span class="number">88</span>,<span class="number">75</span>,<span class="number">91</span></span><br><span class="line">computer,huanglei,<span class="number">76</span>,<span class="number">95</span>,<span class="number">86</span>,<span class="number">74</span>,<span class="number">68</span>,<span class="number">74</span>,<span class="number">48</span></span><br><span class="line">english,liujialing,<span class="number">75</span>,<span class="number">85</span>,<span class="number">62</span>,<span class="number">48</span>,<span class="number">54</span>,<span class="number">96</span>,<span class="number">15</span></span><br><span class="line">math,huanglei,<span class="number">76</span>,<span class="number">95</span>,<span class="number">86</span>,<span class="number">74</span>,<span class="number">68</span>,<span class="number">74</span>,<span class="number">48</span></span><br><span class="line">math,huangjiaju,<span class="number">85</span>,<span class="number">75</span>,<span class="number">86</span>,<span class="number">85</span>,<span class="number">85</span>,<span class="number">74</span>,<span class="number">86</span></span><br><span class="line">math,liutao,<span class="number">48</span>,<span class="number">58</span>,<span class="number">67</span>,<span class="number">86</span>,<span class="number">15</span>,<span class="number">33</span>,<span class="number">85</span></span><br><span class="line">english,huanglei,<span class="number">85</span>,<span class="number">75</span>,<span class="number">85</span>,<span class="number">99</span>,<span class="number">66</span>,<span class="number">88</span>,<span class="number">75</span>,<span class="number">91</span></span><br><span class="line">math,xuzheng,<span class="number">54</span>,<span class="number">52</span>,<span class="number">86</span>,<span class="number">91</span>,<span class="number">42</span>,<span class="number">85</span>,<span class="number">75</span></span><br><span class="line">math,huangxiaoming,<span class="number">85</span>,<span class="number">75</span>,<span class="number">85</span>,<span class="number">99</span>,<span class="number">66</span>,<span class="number">88</span>,<span class="number">75</span>,<span class="number">91</span></span><br><span class="line">math,liujialing,<span class="number">85</span>,<span class="number">86</span>,<span class="number">41</span>,<span class="number">75</span>,<span class="number">93</span>,<span class="number">42</span>,<span class="number">85</span>,<span class="number">75</span></span><br><span class="line">english,huangxiaoming,<span class="number">85</span>,<span class="number">86</span>,<span class="number">41</span>,<span class="number">75</span>,<span class="number">93</span>,<span class="number">42</span>,<span class="number">85</span></span><br><span class="line">algorithm,huangdatou,<span class="number">48</span>,<span class="number">58</span>,<span class="number">67</span>,<span class="number">86</span>,<span class="number">15</span>,<span class="number">33</span>,<span class="number">85</span></span><br><span class="line">algorithm,huangzitao,<span class="number">85</span>,<span class="number">86</span>,<span class="number">41</span>,<span class="number">75</span>,<span class="number">93</span>,<span class="number">42</span>,<span class="number">85</span>,<span class="number">75</span></span><br></pre></td></tr></table></figure><blockquote><p>一、数据解释</p><p>数据字段个数不固定：<br>第一个是课程名称，总共四个课程，computer，math，english，algorithm，<br>第二个是学生姓名，后面是每次考试的分数</p><p>二、统计需求：<br>1、统计每门课程的参加考试人数和课程平均分</p><p>2、统计每门课程参考学生的平均分，并且按课程存入不同的结果文件，要求一门课程一个结果文件</p><p>3、求出每门课程参考学生成绩最高平均分的学生的信息：课程，姓名和平均分</p></blockquote><h3 id="答案"><a href="#答案" class="headerlink" title="答案"></a>答案</h3><h4 id="第1小题"><a href="#第1小题" class="headerlink" title="第1小题"></a>第1小题</h4><p><strong>统计每门课程的参考人数和课程平均分</strong></p><p><strong>涉及知识点: 去重， 自定义类</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//  ScoreBean </span></span><br><span class="line"><span class="keyword">package</span> com.rox.mapreduce.mr3._02_分组组件;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.DataInput;</span><br><span class="line"><span class="keyword">import</span> java.io.DataOutput;</span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.WritableComparable;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> lombok.AllArgsConstructor;</span><br><span class="line"><span class="keyword">import</span> lombok.Getter;</span><br><span class="line"><span class="keyword">import</span> lombok.NoArgsConstructor;</span><br><span class="line"><span class="keyword">import</span> lombok.Setter;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Getter</span></span><br><span class="line"><span class="meta">@Setter</span></span><br><span class="line"><span class="meta">@AllArgsConstructor</span></span><br><span class="line"><span class="meta">@NoArgsConstructor</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ScoreBean</span> <span class="keyword">implements</span> <span class="title">WritableComparable</span>&lt;<span class="title">ScoreBean</span>&gt; </span>&#123;</span><br><span class="line"><span class="keyword">private</span> String courseName;</span><br><span class="line"><span class="keyword">private</span> String stuName; </span><br><span class="line"><span class="keyword">private</span> Double score;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">write</span><span class="params">(DataOutput out)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">out.writeUTF(courseName);</span><br><span class="line">out.writeUTF(stuName);</span><br><span class="line">out.writeDouble(score);</span><br><span class="line">&#125;</span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">readFields</span><span class="params">(DataInput in)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line"><span class="keyword">this</span>.courseName = in.readUTF();</span><br><span class="line"><span class="keyword">this</span>.stuName = in.readUTF();</span><br><span class="line"><span class="keyword">this</span>.score = in.readDouble();</span><br><span class="line">&#125;</span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 如果是相同课程, 按照分数降序排列的</span></span><br><span class="line"><span class="comment"> * 如果是不同课程, 按照课程名称升序排列</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">compareTo</span><span class="params">(ScoreBean o)</span> </span>&#123;</span><br><span class="line"><span class="comment">// 测试一下只写按分数降序排序</span></span><br><span class="line"><span class="comment">//return o.getScore().compareTo(this.getScore());</span></span><br><span class="line"></span><br><span class="line"><span class="comment">/*// 首先分组(只在相同的组内进行比较)</span></span><br><span class="line"><span class="comment">int nameRes = this.getCourseName().compareTo(o.getCourseName());</span></span><br><span class="line"><span class="comment">if (nameRes == 0) &#123;</span></span><br><span class="line"><span class="comment">// 课程相同的时候才进行降序排序</span></span><br><span class="line"><span class="comment">int scoreRes = </span></span><br><span class="line"><span class="comment">return scoreRes;</span></span><br><span class="line"><span class="comment">&#125;</span></span><br><span class="line"><span class="comment">return nameRes;*/</span></span><br><span class="line"><span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> String <span class="title">toString1</span><span class="params">()</span> </span>&#123;</span><br><span class="line"><span class="keyword">return</span> stuName + <span class="string">"\t"</span> + score;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> String <span class="title">toString</span><span class="params">()</span> </span>&#123;</span><br><span class="line"><span class="keyword">return</span> courseName + <span class="string">"\t"</span> + stuName</span><br><span class="line">+ <span class="string">"\t"</span> + score;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">ScoreBean</span><span class="params">(String stuName, Double score)</span> </span>&#123;</span><br><span class="line"><span class="keyword">super</span>();</span><br><span class="line"><span class="keyword">this</span>.stuName = stuName;</span><br><span class="line"><span class="keyword">this</span>.score = score;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//  ScorePlusDemo1 </span></span><br><span class="line"><span class="keyword">package</span> com.rox.mapreduce.mr3._02_分组组件;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.util.HashSet;</span><br><span class="line"><span class="keyword">import</span> java.util.Set;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.FileSystem;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.LongWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Job;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Mapper;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Reducer;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ScorePlusDemo1</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException, ClassNotFoundException, InterruptedException </span>&#123;</span><br><span class="line">Configuration conf = <span class="keyword">new</span> Configuration();</span><br><span class="line">conf.set(<span class="string">"fs.defaultFS"</span>, <span class="string">"hdfs://cs1:9000"</span>);</span><br><span class="line">System.setProperty(<span class="string">"HADOOP_USER_NAME"</span>, <span class="string">"ap"</span>);</span><br><span class="line"></span><br><span class="line">Job job = Job.getInstance(conf);</span><br><span class="line">job.setJarByClass(ScorePlusDemo1.class);</span><br><span class="line"></span><br><span class="line">job.setMapperClass(MyMapper.class);</span><br><span class="line">job.setReducerClass(MyReducer.class);</span><br><span class="line"></span><br><span class="line">job.setMapOutputKeyClass(Text.class);</span><br><span class="line">job.setMapOutputValueClass(ScoreBean.class);</span><br><span class="line"></span><br><span class="line">job.setOutputKeyClass(Text.class);</span><br><span class="line">job.setOutputValueClass(Text.class);</span><br><span class="line"></span><br><span class="line">String inP = <span class="string">"/in/newScoreIn"</span>;</span><br><span class="line">String outP = <span class="string">"/out/ans1"</span>;</span><br><span class="line">FileInputFormat.setInputPaths(job, <span class="keyword">new</span> Path(inP));</span><br><span class="line">FileOutputFormat.setOutputPath(job, <span class="keyword">new</span> Path(outP));</span><br><span class="line"></span><br><span class="line">        Path mypath = <span class="keyword">new</span> Path(outP);</span><br><span class="line">        FileSystem hdfs = mypath.getFileSystem(conf);</span><br><span class="line">        <span class="keyword">if</span> (hdfs.isDirectory(mypath)) &#123;</span><br><span class="line">            hdfs.delete(mypath, <span class="keyword">true</span>);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">Boolean waitForComp = job.waitForCompletion(<span class="keyword">true</span>);</span><br><span class="line">System.exit(waitForComp?<span class="number">0</span>:<span class="number">1</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">MyMapper</span> <span class="keyword">extends</span> <span class="title">Mapper</span>&lt;<span class="title">LongWritable</span>, <span class="title">Text</span>, <span class="title">Text</span>, <span class="title">ScoreBean</span>&gt;  </span>&#123;</span><br><span class="line">Text k = <span class="keyword">new</span> Text();</span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">map</span><span class="params">(LongWritable key, Text value, Context context)</span></span></span><br><span class="line"><span class="function"><span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line"><span class="comment">// 1.截取</span></span><br><span class="line">String[] datas = value.toString().trim().split(<span class="string">","</span>);</span><br><span class="line">String courseName = datas[<span class="number">0</span>].trim();</span><br><span class="line">String stuName = datas[<span class="number">1</span>].trim();</span><br><span class="line"><span class="keyword">int</span> sum = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">2</span>; i&lt;datas.length; i++) &#123;</span><br><span class="line">sum += Integer.parseInt(datas[i]);</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">double</span> avgScore = sum/(datas.length-<span class="number">2</span>);</span><br><span class="line">ScoreBean sb = <span class="keyword">new</span> ScoreBean(courseName, stuName, avgScore);</span><br><span class="line">k.set(courseName);</span><br><span class="line">context.write(k, sb);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">MyReducer</span> <span class="keyword">extends</span> <span class="title">Reducer</span>&lt;<span class="title">Text</span>, <span class="title">ScoreBean</span>, <span class="title">Text</span>, <span class="title">Text</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">Text v = <span class="keyword">new</span> Text();</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">reduce</span><span class="params">(Text key, Iterable&lt;ScoreBean&gt; values,</span></span></span><br><span class="line"><span class="function"><span class="params">Reducer&lt;Text, ScoreBean, Text, Text&gt;.Context context)</span></span></span><br><span class="line"><span class="function"><span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line"></span><br><span class="line">Set&lt;String&gt; stuNames = <span class="keyword">new</span> HashSet&lt;&gt;();</span><br><span class="line"><span class="keyword">int</span> count = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">int</span> sum = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">for</span> (ScoreBean sb : values) &#123;</span><br><span class="line">stuNames.add(sb.getStuName());</span><br><span class="line">count ++;</span><br><span class="line">sum += sb.getScore();</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">int</span> size = stuNames.size();</span><br><span class="line">String val = size + <span class="string">"\t"</span> + (<span class="keyword">double</span>)sum/count;</span><br><span class="line">v.set(val);</span><br><span class="line">context.write(key, v);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 执行结果 </span></span><br><span class="line">algorithm<span class="number">6</span><span class="number">71.33333333333333</span></span><br><span class="line">computer<span class="number">10</span><span class="number">69.6</span></span><br><span class="line">english<span class="number">8</span><span class="number">66.0</span></span><br><span class="line">math<span class="number">7</span><span class="number">72.57142857142857</span></span><br></pre></td></tr></table></figure><h4 id="第2小题"><a href="#第2小题" class="headerlink" title="第2小题"></a>第2小题</h4><p><strong>统计每门课程参考学生的平均分，并且按课程存入不同的结果文件，要求一门课程一个结果文件</strong></p><p><strong>涉及知识点： 分区, 字符串组合key， Partitioner</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.rox.mapreduce.mr3._02_分组组件;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.util.HashMap;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.FileSystem;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.DoubleWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.LongWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Job;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Mapper;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Partitioner;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Reducer;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> shixuanji</span></span><br><span class="line"><span class="comment"> * 注意: 此题因为数据中有2条 course 和 stuName相同的数据(english liuyifei), 所以必须再在reduce中继续去重一下, 再计算一下平均分</span></span><br><span class="line"><span class="comment"> * </span></span><br><span class="line"><span class="comment"> * 否则, 可以不用写reduce, 因为Mapper中已经把逻辑处理完了,可以直接输出</span></span><br><span class="line"><span class="comment"> </span></span><br><span class="line"><span class="comment"> * 最终输出: </span></span><br><span class="line"><span class="comment"> * computer liuyifei 43</span></span><br><span class="line"><span class="comment"> * computer huanglei 63</span></span><br><span class="line"><span class="comment"> * math liutao   64</span></span><br><span class="line"><span class="comment"> * ...</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ScorePlusDemo2</span> </span>&#123;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException, ClassNotFoundException, InterruptedException </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 指定HDFS相关参数</span></span><br><span class="line">Configuration conf = <span class="keyword">new</span> Configuration();</span><br><span class="line">conf.set(<span class="string">"fs.defaultFS"</span>, <span class="string">"hdfs://cs1:9000"</span>);</span><br><span class="line">System.setProperty(<span class="string">"HADOOP_USER_NAME"</span>, <span class="string">"ap"</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">//  创建/配置 Job</span></span><br><span class="line">Job job = Job.getInstance(conf);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 设置Jar包类型</span></span><br><span class="line">job.setJarByClass(ScorePlusDemo2.class);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 设置Map Reduce执行类</span></span><br><span class="line">job.setMapperClass(MyMapper.class);</span><br><span class="line">job.setReducerClass(MyReducer.class);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 设置Map输出类</span></span><br><span class="line">job.setMapOutputKeyClass(Text.class);</span><br><span class="line">job.setMapOutputValueClass(DoubleWritable.class);</span><br><span class="line"></span><br><span class="line"><span class="comment">// Reduce输出类</span></span><br><span class="line">job.setOutputKeyClass(Text.class);</span><br><span class="line">job.setOutputValueClass(DoubleWritable.class);</span><br><span class="line"></span><br><span class="line"><span class="comment">//  设置分区 </span></span><br><span class="line">job.setPartitionerClass(MyPartition.class);</span><br><span class="line">job.setNumReduceTasks(<span class="number">4</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 设置输入 输出路径</span></span><br><span class="line">String inP = <span class="string">"/in/newScoreIn"</span>;</span><br><span class="line">String outP = <span class="string">"/out/scorePlus2"</span>;</span><br><span class="line">FileInputFormat.setInputPaths(job, <span class="keyword">new</span> Path(inP));</span><br><span class="line">FileOutputFormat.setOutputPath(job, <span class="keyword">new</span> Path(outP));</span><br><span class="line"></span><br><span class="line"><span class="comment">// 设置如果存在路径就删除</span></span><br><span class="line">        Path mypath = <span class="keyword">new</span> Path(outP);</span><br><span class="line">        FileSystem hdfs = mypath.getFileSystem(conf);</span><br><span class="line">        <span class="keyword">if</span> (hdfs.isDirectory(mypath)) &#123;</span><br><span class="line">            hdfs.delete(mypath, <span class="keyword">true</span>);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//  执行job</span></span><br><span class="line">        <span class="keyword">boolean</span> waitForCompletion = job.waitForCompletion(<span class="keyword">true</span>);</span><br><span class="line">        System.exit(waitForCompletion?<span class="number">0</span>:-<span class="number">1</span>);</span><br><span class="line">&#125;</span><br><span class="line">    </span><br><span class="line">===============================================================</span><br><span class="line"></span><br><span class="line"><span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">MyMapper</span> <span class="keyword">extends</span> <span class="title">Mapper</span>&lt;<span class="title">LongWritable</span>, <span class="title">Text</span>, <span class="title">Text</span>, <span class="title">DoubleWritable</span>&gt; </span>&#123;</span><br><span class="line"><span class="comment">// 把 课程+学生 作为 key</span></span><br><span class="line"></span><br><span class="line">Text k = <span class="keyword">new</span> Text();  <span class="comment">//只有输出String类型的, 才需要在这里设置Text</span></span><br><span class="line">DoubleWritable v = <span class="keyword">new</span> DoubleWritable();</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">map</span><span class="params">(LongWritable key, Text value, Context context)</span></span></span><br><span class="line"><span class="function"><span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line"></span><br><span class="line">String[] datas = value.toString().trim().split(<span class="string">","</span>);</span><br><span class="line">String kStr = datas[<span class="number">0</span>].trim() + <span class="string">"\t"</span> + datas[<span class="number">1</span>].trim();</span><br><span class="line"><span class="keyword">int</span> sum = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">2</span>; i &lt; datas.length; i++) &#123;</span><br><span class="line">sum += Integer.parseInt(datas[i]);</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">double</span> avg = sum / (datas.length - <span class="number">2</span>);</span><br><span class="line">k.set(kStr);</span><br><span class="line">v.set(avg);</span><br><span class="line">context.write(k, v);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">===============================================================</span><br><span class="line">    </span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> shixuanji</span></span><br><span class="line"><span class="comment"> * 注意: 此题因为数据中有2条 course 和 stuName相同的数据, 所以必须再在reduce中</span></span><br><span class="line"><span class="comment"> * 继续去重一下, 再计算一下平均分</span></span><br><span class="line"><span class="comment"> * </span></span><br><span class="line"><span class="comment"> * 否则, 可以不用写reduce, 因为Mapper中已经把逻辑处理完了,可以直接输出</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">MyReducer</span> <span class="keyword">extends</span> <span class="title">Reducer</span>&lt;<span class="title">Text</span>, <span class="title">DoubleWritable</span>, <span class="title">Text</span>, <span class="title">DoubleWritable</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">DoubleWritable v = <span class="keyword">new</span> DoubleWritable();</span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">reduce</span><span class="params">(Text key, Iterable&lt;DoubleWritable&gt; values,</span></span></span><br><span class="line"><span class="function"><span class="params">Reducer&lt;Text, DoubleWritable, Text, DoubleWritable&gt;.Context context)</span></span></span><br><span class="line"><span class="function"><span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 考虑到有 课程, 学生名相同, 后面的数据不同的情况, 这里再做一个平均求和</span></span><br><span class="line"><span class="comment"> * 可以验证打印下</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">int</span> count = <span class="number">0</span>;</span><br><span class="line">Double sum = <span class="number">0.0</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> (DoubleWritable avg : values) &#123;</span><br><span class="line"><span class="keyword">if</span> (count &gt; <span class="number">0</span>) &#123;</span><br><span class="line"><span class="comment">// 有key完全相同的情况才会进到这里</span></span><br><span class="line">System.out.println(<span class="string">"这是第"</span> +count +<span class="string">"次, 说明课程和姓名有相同的两条数据\n课程姓名是: "</span>+key.toString());</span><br><span class="line">&#125;</span><br><span class="line">sum += avg.get();</span><br><span class="line">count ++;</span><br><span class="line">&#125;</span><br><span class="line">Double finAvg = sum/count;</span><br><span class="line">v.set(finAvg);</span><br><span class="line">context.write(key, v);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">===============================================================</span><br><span class="line">===============================================================</span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> shixuanji</span></span><br><span class="line"><span class="comment"> * 继承 Partitioner, 实现自定义分区</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyPartition</span> <span class="keyword">extends</span> <span class="title">Partitioner</span>&lt;<span class="title">Text</span>, <span class="title">DoubleWritable</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> HashMap&lt;String, Integer&gt; courseMap = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line"><span class="keyword">static</span> &#123;</span><br><span class="line">courseMap.put(<span class="string">"algorithm"</span>, <span class="number">0</span>);</span><br><span class="line">courseMap.put(<span class="string">"computer"</span>, <span class="number">1</span>);</span><br><span class="line">courseMap.put(<span class="string">"english"</span>, <span class="number">2</span>);</span><br><span class="line">courseMap.put(<span class="string">"math"</span>, <span class="number">3</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">getPartition</span><span class="params">(Text key, DoubleWritable value, <span class="keyword">int</span> numPartitions)</span> </span>&#123;</span><br><span class="line"><span class="comment">// 取出Map输出的key中的前半部分--courseName</span></span><br><span class="line">Integer code = courseMap.get(key.toString().trim().split(<span class="string">"\t"</span>)[<span class="number">0</span>]);</span><br><span class="line"><span class="keyword">if</span> (code != <span class="keyword">null</span>) &#123;</span><br><span class="line"><span class="keyword">return</span> code;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> <span class="number">5</span>;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">===============================================================</span><br><span class="line"> ===============================================================</span><br><span class="line">    </span><br><span class="line"> 执行结果 </span><br><span class="line">algorithmhuangdatou<span class="number">56.0</span></span><br><span class="line">algorithmhuangjiaju<span class="number">82.0</span></span><br><span class="line">algorithmhuanglei<span class="number">74.0</span></span><br><span class="line">algorithmhuangzitao<span class="number">72.0</span></span><br><span class="line">algorithmliutao<span class="number">82.0</span></span><br><span class="line">algorithmliuyifei<span class="number">62.0</span></span><br><span class="line">----------</span><br><span class="line">computerhuangbo<span class="number">65.0</span></span><br><span class="line">computerhuangdatou<span class="number">56.0</span></span><br><span class="line">computerhuangjiaju<span class="number">83.0</span></span><br><span class="line">computerhuanglei<span class="number">74.0</span></span><br><span class="line">computerhuangxiaoming<span class="number">72.0</span></span><br><span class="line">computerhuangzitao<span class="number">72.0</span></span><br><span class="line">computerliujialing<span class="number">64.0</span></span><br><span class="line">computerliutao<span class="number">83.0</span></span><br><span class="line">computerliuyifei<span class="number">62.0</span></span><br><span class="line">computerxuzheng<span class="number">65.0</span></span><br><span class="line">---------</span><br><span class="line">englishhuangbo<span class="number">55.0</span></span><br><span class="line">englishhuangdatou<span class="number">56.0</span></span><br><span class="line">englishhuanglei<span class="number">83.0</span></span><br><span class="line">englishhuangxiaoming<span class="number">72.0</span></span><br><span class="line">englishliujialing<span class="number">62.0</span></span><br><span class="line">englishliuyifei<span class="number">66.5</span></span><br><span class="line">englishzhaobenshan<span class="number">69.0</span></span><br><span class="line">englishzhouqi<span class="number">64.0</span></span><br><span class="line">------------</span><br><span class="line">mathhuangjiaju<span class="number">82.0</span></span><br><span class="line">mathhuanglei<span class="number">74.0</span></span><br><span class="line">mathhuangxiaoming<span class="number">83.0</span></span><br><span class="line">mathliujialing<span class="number">72.0</span></span><br><span class="line">mathliutao<span class="number">56.0</span></span><br><span class="line">mathwangbaoqiang<span class="number">72.0</span></span><br><span class="line">mathxuzheng<span class="number">69.0</span></span><br></pre></td></tr></table></figure><h4 id="第3小题"><a href="#第3小题" class="headerlink" title="第3小题"></a>第3小题</h4><p>求出 <strong><em>每门课程</em></strong><sup>①</sup>参与考试的学生成绩 <strong><em>最高<sup>②</sup></em></strong>  <strong><em>平均分<sup>③</sup></em></strong> 的学生的信息：<u>课程，姓名和平均分</u></p><p><strong>涉及知识点： 先分组，再排序</strong></p><div id="sequence-0"></div><div id="sequence-1"></div><p><script src="https://cdnjs.cloudflare.com/ajax/libs/webfont/1.6.27/webfontloader.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/snap.svg/0.4.1/snap.svg-min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/underscore.js/1.8.3/underscore-min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/js-sequence-diagrams/1.0.6/sequence-diagram-min.js"></script><textarea id="sequence-0-code" style="display: none">Mapper->Reduce: k:courseName, v:ScoreBean(分组，sort).Reduce->Output: k:ScoreBean, v:NullWritable.</textarea><textarea id="sequence-0-options" style="display: none">{"theme":"simple","scale":1,"line-width":2,"line-length":50,"text-margin":10,"font-size":12}</textarea><script>  var code = document.getElementById("sequence-0-code").value;  var options = JSON.parse(decodeURIComponent(document.getElementById("sequence-0-options").value));  var diagram = Diagram.parse(code);  diagram.drawSVG("sequence-0", options);</script><textarea id="sequence-1-code" style="display: none">s->fs:fd->fd: s->fd: 为辅导费反倒是</textarea><textarea id="sequence-1-options" style="display: none">{"theme":"simple","scale":1,"line-width":2,"line-length":50,"text-margin":10,"font-size":12}</textarea><script>  var code = document.getElementById("sequence-1-code").value;  var options = JSON.parse(decodeURIComponent(document.getElementById("sequence-1-options").value));  var diagram = Diagram.parse(code);  diagram.drawSVG("sequence-1", options);</script></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;求微博共同粉丝&quot;&gt;&lt;a href=&quot;#求微博共同粉丝&quot; class=&quot;headerlink&quot; title=&quot;求微博共同粉丝&quot;&gt;&lt;/a&gt;求微博共同粉丝&lt;/h2&gt;&lt;h3 id=&quot;题目&quot;&gt;&lt;a href=&quot;#题目&quot; class=&quot;headerlink&quot; title=&quot;题
      
    
    </summary>
    
      <category term="Hadoop" scheme="https://airpoet.github.io/categories/Hadoop/"/>
    
      <category term="学习笔记" scheme="https://airpoet.github.io/categories/Hadoop/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="原创" scheme="https://airpoet.github.io/tags/%E5%8E%9F%E5%88%9B/"/>
    
      <category term="技术" scheme="https://airpoet.github.io/tags/%E6%8A%80%E6%9C%AF/"/>
    
      <category term="Hadoop" scheme="https://airpoet.github.io/tags/Hadoop/"/>
    
      <category term="MapReduce" scheme="https://airpoet.github.io/tags/MapReduce/"/>
    
  </entry>
  
  <entry>
    <title>MapReduce笔记-3</title>
    <link href="https://airpoet.github.io/2018/06/08/Hadoop/Study/MapReduce%E7%AC%94%E8%AE%B0-3/"/>
    <id>https://airpoet.github.io/2018/06/08/Hadoop/Study/MapReduce笔记-3/</id>
    <published>2018-06-08T01:23:27.815Z</published>
    <updated>2018-06-09T07:09:04.617Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-多-Job-串联"><a href="#1-多-Job-串联" class="headerlink" title="1.多 Job 串联"></a>1.多 Job 串联</h2><h3 id="1-概念"><a href="#1-概念" class="headerlink" title="1.概念"></a>1.概念</h3><p>当程序中有多个 Job， 并且多个 job 之间相互依赖， a ， job 需要依赖另一个b，job 的执行结果时候， 此时需要使用多 job 串联</p><h3 id="2-涉及到昨天的微博求共同粉丝题目"><a href="#2-涉及到昨天的微博求共同粉丝题目" class="headerlink" title="2. 涉及到昨天的微博求共同粉丝题目"></a>2. 涉及到昨天的微博求共同粉丝题目</h3><blockquote><p>A:B,C,D,F,E,O<br>B:A,C,E,K<br>C:F,A,D,I<br>D:A,E,F,L<br>E:B,C,D,M,L<br>F:A,B,C,D,E,O,M<br>G:A,C,D,E,F<br>H:A,C,D,E,O<br>I:A,O<br>J:B,O<br>K:A,C,D<br>L:D,E,F<br>M:E,F,G<br>O:A,H,I,J,K</p><p>以上是数据：<br>A:B,C,D,F,E,O<br>表示：A用户 关注B,C,D,E,F,O</p><p>求所有两两用户之间的共同关注对象</p></blockquote><ol><li><p><strong>第一个 MapReduce 程序</strong></p><ul><li>思路</li></ul><p><img src="http://p6i5vzkfk.bkt.clouddn.com/study/2018-06-08-013547.png" alt="image-20180608093547127"></p></li></ol><ul><li><p>对象可以创建在 map 方法外面， 每当启动一个 maptask 任务才会执行一个 mapper ， 这样就不会重复创建对象， <strong>mapper 类</strong></p><p><img src="http://p6i5vzkfk.bkt.clouddn.com/study/2018-06-08-014513.png" alt="image-20180608094512645"></p><p><img src="http://p6i5vzkfk.bkt.clouddn.com/study/2018-06-08-031859.png" alt="image-20180608111859010"></p></li><li><p><strong>reduce 类</strong></p><p><img src="http://p6i5vzkfk.bkt.clouddn.com/study/2018-06-08-015227.jpg?" alt=""></p></li></ul><ol start="2"><li><p><strong>第二个 MapReduce 程序：</strong> </p><p><img src="http://p6i5vzkfk.bkt.clouddn.com/study/2018-06-08-015838.png" alt="image-20180608095838184"></p><ul><li><strong>map 类</strong></li></ul><p><img src="http://p6i5vzkfk.bkt.clouddn.com/study/2018-06-08-020429.png" alt="image-20180608100429646"></p><p><img src="http://p6i5vzkfk.bkt.clouddn.com/study/2018-06-08-020313.png" alt="image-20180608100312428"></p><p><img src="http://p6i5vzkfk.bkt.clouddn.com/study/2018-06-08-020501.png" alt="image-20180608100501665"></p></li></ol><ul><li><p><strong>reduce 类</strong></p><p><img src="http://p6i5vzkfk.bkt.clouddn.com/study/2018-06-08-020829.jpg?rr" alt=""></p></li></ul><ol><li><p><strong>多 Job 串联</strong></p><ul><li><p>基本的写到一起， job1， job2</p></li><li><p>用<code>JobControl</code>对象管理多 job， 会将多个 job 当做一个组中的 job 提交， 参数指的是组名， 随意起</p></li><li><p>原生的 job 要转为可控制的 job</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 创建 JobControl 组</span></span><br><span class="line">JobControl jc = <span class="keyword">new</span> JobControl(<span class="string">"common_friend"</span>);</span><br><span class="line"><span class="comment">// job 拿好配置， 加入 ControlledJob 管理, 变成可控制的 job</span></span><br><span class="line">ControlledJob ajob = <span class="keyword">new</span> ControlledJob(job1.getConfiguration());</span><br><span class="line">ControlledJob bjob = <span class="keyword">new</span> ControlledJob(job2.getConfiguration());</span><br><span class="line"><span class="comment">// 添加依赖关系</span></span><br><span class="line">bjob.addDependingJob(ajob);  </span><br><span class="line"><span class="comment">//  添加 job进 JC</span></span><br><span class="line">jc.addJob(ajob);</span><br><span class="line">jc.addJob(bjob);</span><br><span class="line"><span class="comment">// 启动线程</span></span><br><span class="line">Thread jobControlTread = <span class="keyword">new</span> Thread(jc);</span><br><span class="line">jobControlTread.start();</span><br><span class="line"><span class="comment">// 在线程完成之后关闭</span></span><br><span class="line"><span class="keyword">while</span>(!jc.allFinished()) &#123;</span><br><span class="line">Thread.sleep(<span class="number">500</span>);</span><br><span class="line">&#125;</span><br><span class="line">jobControl.stop();</span><br></pre></td></tr></table></figure></li></ul></li></ol><hr><h2 id="2-分组组件"><a href="#2-分组组件" class="headerlink" title="2. 分组组件"></a>2. 分组组件</h2><p><strong>map–分组–reduce</strong>  </p><p>reduce 接收到的数据是按照 map 输出的 key 进行分组的, 分组的时候按照 key 相同的时候为一组,  默认都实现了 <code>WritableComparable</code>接口， 其中的 compareTo（）方法返回为0的时候 默认为一组， 返回不为0， 则分到不同组</p><p><br></p><p><strong>自定义分组使用场景：</strong> 默认的数据分组不能满足需求</p><blockquote><p>一、数据解释</p><p>数据字段个数不固定：<br>第一个是课程名称，总共四个课程，computer，math，english，algorithm，<br>第二个是学生姓名，后面是每次考试的分数</p><p>二、统计需求：<br>1、统计每门课程的参考人数和课程平均分</p><p>2、统计每门课程参考学生的平均分，并且按课程存入不同的结果文件，要求一门课程一个结果文件</p><p>3、求出每门课程参考学生成绩最高平均分的学生的信息：课程，姓名和平均分</p></blockquote><p><strong>第三题： 要求就是分组求最大值， 两件事情： 分组， 排序（shuffle）</strong></p><p>排序输出的 key ： 分数</p><p>Map 输出的 key： 科目</p><p>如果是科目，怎么求最大值？</p><p><strong>最佳方案</strong>： <strong>map 的 key</strong>： 科目 + 分数</p><blockquote><p>排序： 分数</p><p>分组： 科目</p></blockquote><p>这样， 相同科目&amp;分数会到一组， 此时就不能使用默认的， 此时就只能自定义分组规则</p><p><br></p><h5 id="分组的结论：-？？"><a href="#分组的结论：-？？" class="headerlink" title="分组的结论： ？？"></a>分组的结论： ？？</h5><p><img src="http://p6i5vzkfk.bkt.clouddn.com/study/2018-06-08-061014.png" alt="image-20180608141013590"></p><p><img src="http://p6i5vzkfk.bkt.clouddn.com/study/2018-06-08-061154.png" alt="image-20180608141153954"></p><p><img src="http://p6i5vzkfk.bkt.clouddn.com/study/2018-06-08-061312.png" alt="image-20180608141312277"></p><h4 id="分析："><a href="#分析：" class="headerlink" title="分析："></a>分析：</h4><p>MapReduce 中：</p><p><strong>Map 端</strong></p><ul><li>key： 拆分课程、 分数， <strong>封装为对象（自定义排序）， 作为 key 发送</strong></li><li>value： 姓名</li></ul><p><strong>Reduce 端</strong></p><ul><li>已经分好组（自定义）， 排好序的</li><li>如果按照自定义的分组来： <pre><code>- 相同课程为一组， 并且这一组数据按照分数排好了序（倒序）</code></pre></li></ul><h4 id="代码："><a href="#代码：" class="headerlink" title="代码："></a>代码：</h4><p> ScoreBean</p><p><img src="http://p6i5vzkfk.bkt.clouddn.com/study/2018-06-08-030741.png" alt="image-20180608110741068"></p><p>// 这里实现 <code>WritableComparable</code></p><p><img src="http://p6i5vzkfk.bkt.clouddn.com/study/2018-06-08-033821.png" alt="image-20180608113821115"></p><p><img src="http://p6i5vzkfk.bkt.clouddn.com/study/2018-06-08-060515.png" alt="image-20180608140514714"></p><hr><p> MyGroup（自定义分组类） </p><p>自定义接口需要<strong>继承</strong> <code>WritableComparator</code>类，重写下面方法</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">compare</span><span class="params">(WritableComparable a, WritableComparable b)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> a.compareTo(b);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img src="http://p6i5vzkfk.bkt.clouddn.com/study/2018-06-08-032738.png" alt="image-20180608112738092"></p><blockquote><p>注意, 这里是个坑， 调用无参构造时， 要传入 true 才会创建</p></blockquote><p><img src="http://p6i5vzkfk.bkt.clouddn.com/study/2018-06-08-034602.png" alt="image-20180608114601732"></p><hr><p> ScoreDouble(主类) </p><p>=========Map==========</p><p><img src="http://p6i5vzkfk.bkt.clouddn.com/study/2018-06-08-031625.png" alt="image-20180608111624675"></p><p>=========Reduce==========</p><p><img src="http://p6i5vzkfk.bkt.clouddn.com/study/2018-06-08-033416.png" alt="image-20180608113416441"></p><p>=========Main===========</p><p><img src="http://p6i5vzkfk.bkt.clouddn.com/study/2018-06-08-033458.png" alt="image-20180608113458292"></p><p><img src="http://p6i5vzkfk.bkt.clouddn.com/study/2018-06-08-034007.png" alt="image-20180608114006747"></p><hr><h5 id="遇到问题"><a href="#遇到问题" class="headerlink" title="遇到问题"></a>遇到问题</h5><p><strong>应该是先分组， 再排序</strong></p><p>默认是先排序， 在分组， 可以尝试</p><ul><li>可以先按课程排序</li><li>再按分数排序</li><li>但是要的是这种结果<ul><li><img src="http://p6i5vzkfk.bkt.clouddn.com/study/2018-06-08-060255.jpg?fgh=re" alt=""></li></ul></li></ul><h2 id="3-Reduce-中的2个坑"><a href="#3-Reduce-中的2个坑" class="headerlink" title="3. Reduce 中的2个坑"></a>3. Reduce 中的2个坑</h2><h3 id="坑1"><a href="#坑1" class="headerlink" title="坑1"></a>坑1</h3><p><strong>Iterable\<text>只能循环遍历一次</text></strong></p><p>迭代器每次循环遍历完成， 指针都会移动到最后一个</p><p>系统类型，没事</p><p><img src="http://p6i5vzkfk.bkt.clouddn.com/study/2018-06-08-061946.png" alt="image-20180608141946102"></p><p>自定义类型 ？ </p><h3 id="坑2"><a href="#坑2" class="headerlink" title="坑2"></a>坑2</h3><p><strong>迭代器中所有对象公用同一个地址</strong></p><hr><h2 id="4-Reduce-端的-Join"><a href="#4-Reduce-端的-Join" class="headerlink" title="4. Reduce 端的 Join"></a>4. Reduce 端的 Join</h2><p>思路： </p><p><strong>核心： 关联条件</strong></p><ul><li>想要在 reduce 端完成 join， 要在 reduce 端可以同时接收到两个表中的数据</li><li>要保证在 Map 端进行读文件的时候， 读到2个表的数据， 并且需要对2个表的数据进行区分</li><li>将2个表放在同一个目录下</li></ul><h4 id="Map-端"><a href="#Map-端" class="headerlink" title="Map 端"></a>Map 端</h4><ul><li>读取两个表中的数据， 进行切分、发送</li><li>key ： 公共字段–关联字段–<code>pid</code></li><li>value： 剩下的字段， 需要标记， 标记数据的来源</li></ul><p><strong>–&gt;代码</strong></p><ul><li>重写 <code>setup</code>， 在 Map 开始之前， 拿到文件的 filename， 图暂缺</li></ul><p><img src="http://p6i5vzkfk.bkt.clouddn.com/study/2018-06-08-064240.png" alt="image-20180608144239477"></p><ul><li>根据 filename 设置 k， v， 打标签</li></ul><p><img src="http://p6i5vzkfk.bkt.clouddn.com/study/2018-06-08-065349.png" alt="image-20180608145349367"></p><h4 id="Reduce-端"><a href="#Reduce-端" class="headerlink" title="Reduce 端"></a>Reduce 端</h4><ul><li>接收过来， 判断是来自于哪个表的数据， 进行拼接</li></ul><p><strong>–&gt;代码</strong></p><p><img src="http://p6i5vzkfk.bkt.clouddn.com/study/2018-06-08-070047.png" alt="image-20180608150046953"></p><p><img src="http://p6i5vzkfk.bkt.clouddn.com/study/2018-06-08-070316.png" alt="image-20180608150315294"></p><p><img src="http://p6i5vzkfk.bkt.clouddn.com/study/2018-06-08-070719.png" alt="image-20180608150719001"></p><h3 id="缺陷"><a href="#缺陷" class="headerlink" title="缺陷"></a>缺陷</h3><p><strong>1. ReduceTask 的并行度问题：</strong></p><ul><li>建议0.95*datanode 的个数</li><li>并行度不高， 性能不高</li></ul><p><strong>2. 容器性能</strong></p><ul><li>list 等， 不提倡， reduce 接收的数据， 可能会很大</li></ul><p><strong>3. ReduceTask 容易产生数据倾斜</strong></p><ul><li>假设我们设置多个 ReduceTask， 根据分区规则， 默认 hash</li><li>以 key关联条件分，  ReduceTask数据倾斜， 每个 ReduceTask 分工不均， 非常影响性能，没有合理的利用集群资源</li><li>在真实的生产中一定要尽量的避免数据倾斜</li><li>最好的做法：将分区设计的足够完美，难度比较大</li><li>因此，ReduceTask 一般不会完成 John工作</li><li><strong>放在 Map 端完成就不会有这个问题了</strong></li></ul><hr><h5 id="补充：Mapper-中的源码分析"><a href="#补充：Mapper-中的源码分析" class="headerlink" title="补充：Mapper 中的源码分析"></a>补充：Mapper 中的源码分析</h5><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">(Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line">    <span class="comment">// 在 maptask 执行之前调用一次， 一个 maptask 只会调用一次。setup 中通常会帮 map 中初始化一些变量和资源， 比如数据库的连接等。</span></span><br><span class="line">    <span class="comment">// 主要目的：减少资源的初始化次数而提升程序的性能</span></span><br><span class="line">    setup(context);</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      <span class="comment">// 获取文件是否还有下一行， 一行只调用一次</span></span><br><span class="line">      <span class="keyword">while</span> (context.nextKeyValue()) &#123;</span><br><span class="line">        map(context.getCurrentKey(), context.getCurrentValue(), context);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">       <span class="comment">// maptask 任务执行完成之后会调用一次，一个 maptask 只会调用一次</span></span><br><span class="line">       <span class="comment">// 帮 map 处理一些善后工作， 比如：资源的关闭</span></span><br><span class="line">      cleanup(context);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><hr><h2 id="5-Map-端的-Join"><a href="#5-Map-端的-Join" class="headerlink" title="5. Map 端的 Join"></a>5. Map 端的 Join</h2><p><img src="http://p6i5vzkfk.bkt.clouddn.com/study/2018-06-08-075049.png" alt="image-20180608155048562"></p><p>为了提升 Map 端 Join 性能， 我们的策略是， <strong>将小表的数据加载到每个运行的 MapTask 的内存中</strong>。</p><p>如果小表被加载到了内存中， 我们<strong>每次在 Map 端只需要读取大表，当读取到大表的每一行数据，可以直接和内存中的小表进行关联。</strong></p><p>这个时候，<strong>只需要 Map 就可以完成 Join 操作了</strong>。</p><p><br></p><h3 id="1-如何将小表加入到内存中？"><a href="#1-如何将小表加入到内存中？" class="headerlink" title="1. 如何将小表加入到内存中？"></a>1. 如何将小表加入到内存中？</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 将指定路径文件加载到缓存中</span></span><br><span class="line">job.addCacheFile(<span class="keyword">new</span> URI(<span class="string">"/xxx"</span>));</span><br></pre></td></tr></table></figure><h3 id="2-Map-端怎样读取缓存中的数据"><a href="#2-Map-端怎样读取缓存中的数据" class="headerlink" title="2. Map 端怎样读取缓存中的数据"></a>2. Map 端怎样读取缓存中的数据</h3><p>想要在 Java 中使用缓存中的数据，缓存中的数据必须封装到 Java 的容器中</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 获取缓存文件</span></span><br><span class="line">context.getLocalCacheFiles()[<span class="number">0</span>]</span><br></pre></td></tr></table></figure><h3 id="3-代码"><a href="#3-代码" class="headerlink" title="3. 代码"></a>3. 代码</h3><p><strong>setup</strong>：从缓存读取一文件（多对一的一）到 HashMap</p><p><img src="/var/folders/6l/blvdbwd53hqglz0f09n3sd5c0000gn/T/abnerworks.Typora/image-20180608160128707.png" alt="image-20180608160128707"></p><p><img src="http://p6i5vzkfk.bkt.clouddn.com/study/2018-06-08-080613.png" alt="image-20180608160613685"></p><p><img src="http://p6i5vzkfk.bkt.clouddn.com/study/2018-06-08-080844.png" alt="image-20180608160843766"></p><p><strong>Mapper</strong></p><p><img src="http://p6i5vzkfk.bkt.clouddn.com/study/2018-06-08-081128.png" alt="image-20180608161128128"></p><p><img src="http://p6i5vzkfk.bkt.clouddn.com/study/2018-06-08-081321.png" alt="image-20180608161321395"></p><p><strong>main 方法中注意点</strong></p><p><img src="http://p6i5vzkfk.bkt.clouddn.com/study/2018-06-08-081451.jpg?ff=ytt" alt="ddg"></p><p><strong>注意点：这种方式只能通过 Jar 包上传的方式，直接用 Eclipse 会找不到缓存</strong> </p><p><img src="http://p6i5vzkfk.bkt.clouddn.com/study/2018-06-08-082315.png" alt="image-20180608162315252"></p><hr><h2 id="6-对比"><a href="#6-对比" class="headerlink" title="6. 对比"></a>6. 对比</h2><p><strong>MapJoin 的方式： 大 &amp; 小表</strong></p><p>因为有一个表需要加载到内存中，注定加载到内存中的表不能过大（hive 中默认是256M）</p><p><strong>大表 &amp; 大表 如何设计</strong></p><ul><li>ReduceJoin ： 解决数据倾斜的问题，合理设计分区。 —很难做到</li><li>将其中一个<strong>大表进行切分</strong>，切分成小表， <strong>最终执行 大表 &amp; 小表</strong></li></ul><h4 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h4><ul><li><p>并行度高，不存在数据倾斜的问题，运行效率高</p></li><li><p><strong>优先选择MapJoin</strong></p></li></ul><hr><h2 id="7-排序算法"><a href="#7-排序算法" class="headerlink" title="7. 排序算法"></a>7. 排序算法</h2><h3 id="1-快速排序"><a href="#1-快速排序" class="headerlink" title="1. 快速排序"></a>1. 快速排序</h3><p><strong>边界值始终是不变的。</strong></p><p><img src="http://p6i5vzkfk.bkt.clouddn.com/study/2018-06-08-083614.png" alt="image-20180608163614370"></p><p><img src="http://p6i5vzkfk.bkt.clouddn.com/study/2018-06-08-083842.png" alt="image-20180608163841417"></p><p><img src="http://p6i5vzkfk.bkt.clouddn.com/study/2018-06-08-084004.png" alt="image-20180608164004311"></p><p><img src="http://p6i5vzkfk.bkt.clouddn.com/study/2018-06-08-084128.png" alt="image-20180608164127167"></p><p><img src="http://p6i5vzkfk.bkt.clouddn.com/study/2018-06-08-084319.png" alt="image-20180608164318335"></p><h3 id="2-归并排序"><a href="#2-归并排序" class="headerlink" title="2. 归并排序"></a>2. 归并排序</h3><p>一般情况针对<strong>有序的</strong>，<strong>多个</strong>， <strong>小</strong>数据集</p><blockquote><p>应用场景：想到了多个Reduce 任务产生的多个文件的合并</p></blockquote><h4 id="1-归并排序前传：-合并多个数组"><a href="#1-归并排序前传：-合并多个数组" class="headerlink" title="1. 归并排序前传： 合并多个数组"></a>1. 归并排序前传： 合并多个数组</h4><p><img src="http://p6i5vzkfk.bkt.clouddn.com/study/2018-06-08-085031.png" alt="image-20180608165031396"></p><h4 id="2-归并排序-之-一个大数据集"><a href="#2-归并排序-之-一个大数据集" class="headerlink" title="2. 归并排序 之 一个大数据集"></a>2. 归并排序 之 一个大数据集</h4><h5 id="—归———"><a href="#—归———" class="headerlink" title="—归———-"></a>—归———-</h5><p><strong>切分成单个的数据集</strong></p><p><img src="http://p6i5vzkfk.bkt.clouddn.com/study/2018-06-08-085652.png" alt="image-20180608165651868"></p><p><img src="http://p6i5vzkfk.bkt.clouddn.com/study/2018-06-08-085727.png" alt="image-20180608165727484"></p><h5 id="—-并———"><a href="#—-并———" class="headerlink" title="—-并———"></a>—-并———</h5><ol><li>两两相并， 并成新的数组， 小的先放入数组， 再放大的</li><li>新的数组再不断执行 上述的 <strong>合并多个数组</strong></li></ol><hr><h2 id="8-Shuffle-过程"><a href="#8-Shuffle-过程" class="headerlink" title="8. Shuffle 过程"></a>8. Shuffle 过程</h2><p>。。。</p><hr><h2 id="9、作业"><a href="#9、作业" class="headerlink" title="9、作业"></a>9、作业</h2><h4 id="题1："><a href="#题1：" class="headerlink" title="题1："></a><strong>题1：</strong></h4><p><img src="http://p6i5vzkfk.bkt.clouddn.com/study/2018-06-08-090449.png" alt="image-20180608170449235"></p><h4 id="题2："><a href="#题2：" class="headerlink" title="题2："></a><strong>题2：</strong></h4><p><img src="http://p6i5vzkfk.bkt.clouddn.com/study/2018-06-08-090748.png" alt="image-20180608170748485"></p><h4 id="题3："><a href="#题3：" class="headerlink" title="题3："></a>题3：</h4><p>写最后3个题</p><p><img src="http://p6i5vzkfk.bkt.clouddn.com/study/2018-06-08-091115.png" alt="image-20180608171115135"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;1-多-Job-串联&quot;&gt;&lt;a href=&quot;#1-多-Job-串联&quot; class=&quot;headerlink&quot; title=&quot;1.多 Job 串联&quot;&gt;&lt;/a&gt;1.多 Job 串联&lt;/h2&gt;&lt;h3 id=&quot;1-概念&quot;&gt;&lt;a href=&quot;#1-概念&quot; class=&quot;head
      
    
    </summary>
    
      <category term="Hadoop" scheme="https://airpoet.github.io/categories/Hadoop/"/>
    
      <category term="学习笔记" scheme="https://airpoet.github.io/categories/Hadoop/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="原创" scheme="https://airpoet.github.io/tags/%E5%8E%9F%E5%88%9B/"/>
    
      <category term="技术" scheme="https://airpoet.github.io/tags/%E6%8A%80%E6%9C%AF/"/>
    
      <category term="Hadoop" scheme="https://airpoet.github.io/tags/Hadoop/"/>
    
      <category term="MapReduce" scheme="https://airpoet.github.io/tags/MapReduce/"/>
    
  </entry>
  
  <entry>
    <title>MapReduce笔记-2 三大组件-Partitioner分区,sort排序,Combiner局部分区</title>
    <link href="https://airpoet.github.io/2018/06/07/Hadoop/Study/MapReduce%E7%AC%94%E8%AE%B0-2/"/>
    <id>https://airpoet.github.io/2018/06/07/Hadoop/Study/MapReduce笔记-2/</id>
    <published>2018-06-07T03:27:55.684Z</published>
    <updated>2018-06-09T11:54:15.219Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-Combiner-组件"><a href="#1-Combiner-组件" class="headerlink" title="1.  Combiner 组件"></a>1.  Combiner 组件</h2><h3 id="1-产生缘由："><a href="#1-产生缘由：" class="headerlink" title="1. 产生缘由："></a>1. 产生缘由：</h3><p>Combiner 是 MapReduce 程序中 Mapper 和 Reducer 之外的一种组件，它的作用是在 maptask 之后给 maptask 的结果进行局部汇总，以减轻 reducetask 的计算负载，减少网络传输</p><p><strong>Combiner 组件的作用：</strong></p><ul><li>减少 reduce 端的数据量</li><li>减少 shuffle 过程的数据量</li><li>在 map 端做了一次合并，提高分布式计算程序的整体性能</li></ul><p><strong>Combiner 组件帮 reduce 分担压力， 因此其业务逻辑和 reduce 中的业务逻辑相似</strong></p><h3 id="2-自定义-Combiner-组件："><a href="#2-自定义-Combiner-组件：" class="headerlink" title="2.自定义 Combiner 组件："></a>2.自定义 Combiner 组件：</h3><p>默认情况下没有 Combiner 组件，Combiner 作用时间点 — map–combiner–reduce</p><ol><li><p>继承 Reduce 类</p><ul><li>public class  MyCombiner extends Reducer&lt;前两个： map 的输出， 后两个： reduce 的输入&gt;{}</li><li>我们在写 MapReduce 程序的时候， map 的输出就是 reduce 的输入</li><li>也就是说， 这个 MyCombiner() 的前两个泛型和后两个泛型的类型一致</li></ul></li><li><p>重写 reduce 方法</p><ul><li><p><strong>Combiner 本质上相当于 在 map 端进行了一次 reduce 操作， 通常情况下直接使用 reducer 的类作为 Combiner 的类，不再单独写 Combiner 代码逻辑</strong></p></li><li><p><strong>在 Job 中加上<code>job.setCombinerClass(WorldcountReduce.class)</code>， 就会调用 Combiner</strong></p></li></ul></li></ol><ol start="3"><li><p><strong>Combiner 使用原则</strong></p><ul><li>有或没有都<strong>不能影响业务逻辑</strong>，都<strong>不能影响最终结果</strong>。比如累加，最大值等，求平均值就不能用。</li></ul></li></ol><hr><h2 id="2、MapReduce-中的序列化"><a href="#2、MapReduce-中的序列化" class="headerlink" title="2、MapReduce 中的序列化"></a>2、MapReduce 中的序列化</h2><h3 id="2-1、概述"><a href="#2-1、概述" class="headerlink" title="2.1、概述"></a>2.1、概述</h3><p><strong>Java</strong> 的<strong>序列化</strong>是一个<strong>重量级序列化框架（Serializable）</strong>，一个对象被序列化后，会附带很多额 外的信息（各种校验信息，header，继承体系等），<strong>不便于在网络中高效传输</strong>；</p><p><strong>Hadoop 自己开发了一套序列化机制</strong>（参与序列化的对象的类都要<strong>实现 Writable 接口</strong>），精简，高效</p><h4 id="Java-基本类型-amp-Hadoop-类型对照表"><a href="#Java-基本类型-amp-Hadoop-类型对照表" class="headerlink" title="Java 基本类型 &amp; Hadoop 类型对照表"></a>Java 基本类型 &amp; Hadoop 类型对照表</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Java &amp; Hadoop类型参照</span></span><br><span class="line">hadoop数据类型      &lt;------------&gt;  java数据类型:  </span><br><span class="line">布尔型：  </span><br><span class="line">BooleanWritable     &lt;------------&gt;  <span class="keyword">boolean</span>  </span><br><span class="line">整型：  </span><br><span class="line">ByteWritable        &lt;------------&gt;  <span class="keyword">byte</span>  </span><br><span class="line">ShortWritable       &lt;------------&gt;  <span class="keyword">short</span>  </span><br><span class="line">IntWritable         &lt;------------&gt;  <span class="keyword">int</span>  </span><br><span class="line">LongWritable        &lt;------------&gt;  <span class="keyword">long</span>  </span><br><span class="line">浮点型：  </span><br><span class="line">FloatWritable       &lt;------------&gt;  <span class="keyword">float</span>  </span><br><span class="line">DoubleWritable      &lt;------------&gt;  <span class="keyword">double</span>  </span><br><span class="line">字符串（文本）：  </span><br><span class="line">Text                &lt;------------&gt;  String  </span><br><span class="line">数组：  </span><br><span class="line">ArrayWritable       &lt;------------&gt;  Array  </span><br><span class="line">map集合：  </span><br><span class="line">MapWritable         &lt;------------&gt;  map</span><br></pre></td></tr></table></figure><h3 id="2-2、自定义对象实现-MapReduce-框架的序列化"><a href="#2-2、自定义对象实现-MapReduce-框架的序列化" class="headerlink" title="2.2、自定义对象实现 MapReduce 框架的序列化"></a>2.2、自定义对象实现 MapReduce 框架的序列化</h3><p><strong>要实现<code>WritableComparable</code>接口</strong>，因为 MapReduce 框架中的 shuffle 过程一定会对 key 进行排序</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//序列化方法</span></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">write</span><span class="params">(DataOutput out)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">    out.writeUTF(phone);</span><br><span class="line">    out.writeLong(upfFlow);</span><br><span class="line">    out.writeLong(downFlow);</span><br><span class="line">    out.writeLong(sumFlow);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//反序列化方法</span></span><br><span class="line"><span class="comment">//注意： 字段的反序列化顺序与序列化时的顺序保持一致,並且类型也一致</span></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">readFields</span><span class="params">(DataInput in)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line"><span class="keyword">this</span>.phone = in.readUTF();</span><br><span class="line"><span class="keyword">this</span>.upfFlow = in.readLong();</span><br><span class="line"><span class="keyword">this</span>.downFlow = in.readLong();</span><br><span class="line"><span class="keyword">this</span>.sumFlow = in.readLong();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><hr><h2 id="3-MapReduce中的Sort-–TODO。。"><a href="#3-MapReduce中的Sort-–TODO。。" class="headerlink" title="3. MapReduce中的Sort –TODO。。"></a>3. MapReduce中的Sort –TODO。。</h2><p>MapTask –&gt; ReduceTask 之间， 框架<strong>默认</strong>添加了排序</p><p>排序的规则是<strong>按照Map 端输出的 key 的字典顺序进行排序</strong></p><h5 id="1、-如果没有重写-WritableComparable-时"><a href="#1、-如果没有重写-WritableComparable-时" class="headerlink" title="1、 如果没有重写 WritableComparable 时"></a>1、 如果没有重写 WritableComparable 时</h5><p> 按单词统计中词频出现的此处进行排序， 按照出现的次数， 从低到高</p><p>如果想要对词频进行排序， 那么词频应该放在 map 输出 key 的位置</p><p><strong>代码实现</strong>：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"> Map </span><br><span class="line"><span class="comment">//词频为 key， 其它为 value</span></span><br><span class="line"></span><br><span class="line"> Reduce </span><br><span class="line"><span class="comment">// 将 map 输入的结果反转(k,v 换位置), 输出最终结果</span></span><br><span class="line"><span class="comment">// 最后输出还是按照左边词, 右边次数</span></span><br><span class="line"><span class="comment">// ps： 如果倒序排的时候, map 的时候发的时候 加上-,  reduce 发的时候, 再加上-, 转成 IntWritable</span></span><br></pre></td></tr></table></figure><h5 id="2、自定义排序要实现WritableComparable接口"><a href="#2、自定义排序要实现WritableComparable接口" class="headerlink" title="2、自定义排序要实现WritableComparable接口"></a>2、<strong>自定义排序要实现<code>WritableComparable</code>接口</strong></h5><ul><li><strong>自定义的类必须放在 key 的位置</strong></li><li><strong>实现<code>WritableComparable</code>接口</strong>， 重写 <code>compareTo()</code>方法</li><li>待扩展…</li></ul><blockquote><p> 作业： <strong>增强需求： 按照总流量排序， 总流量相同时， 按照手机号码排序</strong></p></blockquote><hr><h2 id="4、MapReduce-中的数据分发组件-Partitioner（分区）"><a href="#4、MapReduce-中的数据分发组件-Partitioner（分区）" class="headerlink" title="4、MapReduce 中的数据分发组件 Partitioner（分区）"></a>4、MapReduce 中的数据分发组件 <code>Partitioner（分区）</code></h2><p><strong>需求：</strong> 根据归属地<strong>输出</strong>流量统计数据<strong>结果到不同文件</strong>，以便于在查询统计结果时可以定位到 省级范围进行</p><p><strong>思路</strong>：MapReduce 中会将 map 输出的 kv 对，按照相同 key 分组，然后分发给不同的 reducetask</p><p><strong>执行时机</strong>: <strong>在Map输出 kv 对之后, 所携带的 k,v 参数，跟 Map 输出相同</strong></p><p><br></p><h4 id="MapReduce-默认的分发规则为："><a href="#MapReduce-默认的分发规则为：" class="headerlink" title="MapReduce 默认的分发规则为："></a><strong>MapReduce 默认的分发规则为</strong>：</h4><p><strong>根据 <code>key</code> 的 <code>hashcode%reducetask</code> 数来分发</strong>，所以：<strong>如果要按照我们自 己的需求进行分组，则需要改写数据分发（分区）组件 Partitioner</strong></p><p><br></p><h4 id="Partition重点总结："><a href="#Partition重点总结：" class="headerlink" title="Partition重点总结："></a>Partition重点总结：</h4><ul><li><p><strong>Partition 的 key value, 就是Mapper输出的key value</strong></p><p><code>public abstract int getPartition(KEY key, VALUE value, int numPartitions);</code></p><p><strong>输入是Map的结果对&lt;key, value&gt;和Reducer的数目，输出则是分配的Reducer（整数编号）</strong>。<strong>就是指定Mappr输出的键值对到哪一个reducer上去</strong>。系统缺省的Partitioner是HashPartitioner，它以key的Hash值对Reducer的数目取模，得到对应的Reducer。<strong>这样保证如果有相同的key值，肯定被分配到同一个reducre上。如果有N个reducer，编号就为0,1,2,3……(N-1)</strong>。</p></li><li><p>MapReduce 中会将 map 输出的 kv 对，按照相同 key 分组，然后分发给不同的 reducetask 默认的分发规则为:根据 key 的 hashcode%reducetask 数来分发，所以:如果要按照我们自 己的需求进行分组，则需要改写数据分发(分组)组件 Partitioner, 自定义一个 CustomPartitioner 继承抽象类:Partitioner</p></li><li><strong>因此， Partitioner 的执行时机， 是在Map输出 kv 对之后</strong></li></ul><h5 id="Partitioner-实现过程"><a href="#Partitioner-实现过程" class="headerlink" title="Partitioner 实现过程"></a><strong>Partitioner 实现过程</strong></h5><ol><li>先分析一下具体的业务逻辑，确定大概有多少个分区</li><li>首先书写一个类，它要<strong>继承 <code>org.apache.hadoop.mapreduce.Partitioner</code>这个抽象类</strong></li><li><strong>重写<code>public int getPartition</code>这个方法，根据具体逻辑，读数据库或者配置返回相同的数字</strong></li><li><strong>在<code>main</code>方法中设置<code>Partioner</code>的类，<code>job.setPartitionerClass(DataPartitioner.class)</code>;</strong></li><li><strong>设置<code>Reducer</code>的数量，<code>job.setNumReduceTasks(6)</code>;</strong></li></ol><h4 id="典型的-Partitioner-代码实现"><a href="#典型的-Partitioner-代码实现" class="headerlink" title="典型的 Partitioner 代码实现"></a>典型的 Partitioner 代码实现</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.util.HashMap;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Partitioner;</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ProvincePartitioner</span> <span class="keyword">extends</span> <span class="title">Partitioner</span>&lt;<span class="title">Text</span>, <span class="title">FlowBean</span>&gt; </span>&#123;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> HashMap&lt;String, Integer&gt; provincMap = <span class="keyword">new</span> HashMap&lt;String, Integer&gt;();</span><br><span class="line"><span class="keyword">static</span> &#123;</span><br><span class="line">provincMap.put(<span class="string">"138"</span>, <span class="number">0</span>);</span><br><span class="line">provincMap.put(<span class="string">"139"</span>, <span class="number">1</span>);</span><br><span class="line">provincMap.put(<span class="string">"136"</span>, <span class="number">2</span>);</span><br><span class="line">provincMap.put(<span class="string">"137"</span>, <span class="number">3</span>);</span><br><span class="line">provincMap.put(<span class="string">"135"</span>, <span class="number">4</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">getPartition</span><span class="params">(Text key, FlowBean value, <span class="keyword">int</span> numPartitions)</span> </span>&#123;</span><br><span class="line">Integer code = provincMap.get(key.toString().substring(<span class="number">0</span>, <span class="number">3</span>));</span><br><span class="line"><span class="keyword">if</span> (code != <span class="keyword">null</span>) &#123;</span><br><span class="line"><span class="keyword">return</span> code;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> <span class="number">5</span>;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><hr><h2 id="5、全局计数器"><a href="#5、全局计数器" class="headerlink" title="5、全局计数器"></a>5、全局计数器</h2><h3 id="1-框架内置计数器："><a href="#1-框架内置计数器：" class="headerlink" title="1.  框架内置计数器："></a>1.  框架内置计数器：</h3><ul><li>Hadoop内置的计数器，主要用来记录作业的执行情况</li><li>内置计数器包括 <strong>MapReduce框架计数器</strong>（Map-Reduce Framework）<ul><li><strong>文件系统计数器（FielSystemCounters）</strong></li><li><strong>作业计数器（Job Counters）</strong></li><li><strong>文件输入格式计数器（File Output Format Counters）</strong></li><li><strong>文件输出格式计数器（File Input Format Counters)</strong></li></ul></li><li>计数器由相关的task进行维护，定期传递给tasktracker，再由tasktracker传给jobtracker；</li><li>最终的作业计数器实际上是有jobtracker维护，所以计数器可以被全局汇总，同时也不必在整个网络中传递</li><li>只有当一个作业执行成功后，最终的计数器的值才是完整可靠的；</li></ul><h3 id="2-自定义的计数器"><a href="#2-自定义的计数器" class="headerlink" title="2. 自定义的计数器"></a>2. 自定义的计数器</h3><h5 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h5><ul><li>用来统计运行过程中的进度和状态， 类似于 job 运行的一个报告、日志</li><li>要将数据处理过程中遇到的不合规数据行进行全局计数，类似这 种需求可以借助 MapReduce 框架中提供的全局计数器来实现</li><li><strong>计数器的值可以在mapper或reducer中增加</strong></li></ul><p><strong>使用方式</strong></p><ol><li><p>定义枚举类</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">enum</span> Temperature&#123;  </span><br><span class="line">MISSING,  </span><br><span class="line">TOTAL  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>在map或者reduce中使用计数器 </p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 1.自定义计数器</span></span><br><span class="line">Counter counter = context.getCounter(Temperature.TOTAL);  </span><br><span class="line"><span class="comment">// 2.为计数器赋初始值</span></span><br><span class="line">counter.setValue(<span class="keyword">long</span> value);</span><br><span class="line"><span class="comment">// 3.计数器工作</span></span><br><span class="line">counter.increment(<span class="keyword">long</span> incr);</span><br></pre></td></tr></table></figure></li><li><p>获取计数器</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Counters counters=job.getCounters(); </span><br><span class="line">Counter counter=counters.findCounter(LOG_PROCESSOR_COUNTER.BAD_RECORDS_LONG);<span class="comment">// 查找枚举计数器，假如Enum的变量为BAD_RECORDS_LONG </span></span><br><span class="line"><span class="keyword">long</span> value=counter.getValue();<span class="comment">//获取计数值</span></span><br></pre></td></tr></table></figure></li></ol><h4 id="计数器使用完整代码"><a href="#计数器使用完整代码" class="headerlink" title="计数器使用完整代码"></a>计数器使用完整代码</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/** </span></span><br><span class="line"><span class="comment">* <span class="doctag">@Description</span> 假如一个文件，规范的格式是3个字段，“\t”作为分隔符，其中有2条异常数据，一条数据是只有2个字段，一条数据是有4个字段</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MyCounter</span> </span>&#123;</span><br><span class="line">    <span class="comment">// \t键</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> String TAB_SEPARATOR = <span class="string">"\t"</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">MyCounterMap</span> <span class="keyword">extends</span></span></span><br><span class="line"><span class="class">            <span class="title">Mapper</span>&lt;<span class="title">LongWritable</span>, <span class="title">Text</span>, <span class="title">Text</span>, <span class="title">Text</span>&gt; </span>&#123;</span><br><span class="line">        <span class="comment">// 定义枚举对象</span></span><br><span class="line">        <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">enum</span> LOG_PROCESSOR_COUNTER &#123;</span><br><span class="line">            BAD_RECORDS_LONG, BAD_RECORDS_SHORT</span><br><span class="line">        &#125;;</span><br><span class="line">        </span><br><span class="line">        <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">map</span><span class="params">(LongWritable key, Text value, Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line">            String arr_value[] = value.toString().split(TAB_SEPARATOR);</span><br><span class="line">            <span class="keyword">if</span> (arr_value.length &gt; <span class="number">3</span>) &#123;</span><br><span class="line">                <span class="comment">/* 自定义计数器 */</span></span><br><span class="line">                context.getCounter(<span class="string">"ErrorCounter"</span>, <span class="string">"toolong"</span>).increment(<span class="number">1</span>);</span><br><span class="line">                <span class="comment">/* 枚举计数器 */</span></span><br><span class="line">                context.getCounter(LOG_PROCESSOR_COUNTER.BAD_RECORDS_LONG).increment(<span class="number">1</span>);</span><br><span class="line">            &#125; <span class="keyword">else</span> <span class="keyword">if</span> (arr_value.length &lt; <span class="number">3</span>) &#123;</span><br><span class="line">                <span class="comment">// 自定义计数器</span></span><br><span class="line">                context.getCounter(<span class="string">"ErrorCounter"</span>, <span class="string">"tooshort"</span>).increment(<span class="number">1</span>);</span><br><span class="line">                <span class="comment">// 枚举计数器</span></span><br><span class="line">                context.getCounter(LOG_PROCESSOR_COUNTER.BAD_RECORDS_SHORT).increment(<span class="number">1</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@SuppressWarnings</span>(<span class="string">"deprecation"</span>)</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException, InterruptedException, ClassNotFoundException </span>&#123;</span><br><span class="line">        String[] args0 = &#123; </span><br><span class="line">                <span class="string">"hdfs://hadoop2:9000/buaa/counter/counter.txt"</span>,</span><br><span class="line">                <span class="string">"hdfs://hadoop2:9000/buaa/counter/out/"</span> </span><br><span class="line">            &#125;;</span><br><span class="line">        <span class="comment">// 读取配置文件</span></span><br><span class="line">        Configuration conf = <span class="keyword">new</span> Configuration();</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 如果输出目录存在，则删除</span></span><br><span class="line">        Path mypath = <span class="keyword">new</span> Path(args0[<span class="number">1</span>]);</span><br><span class="line">        FileSystem hdfs = mypath.getFileSystem(conf);</span><br><span class="line">        <span class="keyword">if</span> (hdfs.isDirectory(mypath)) &#123;</span><br><span class="line">            hdfs.delete(mypath, <span class="keyword">true</span>);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 新建一个任务</span></span><br><span class="line">        Job job = <span class="keyword">new</span> Job(conf, <span class="string">"MyCounter"</span>);</span><br><span class="line">        <span class="comment">// 主类</span></span><br><span class="line">        job.setJarByClass(MyCounter.class);</span><br><span class="line">        <span class="comment">// Mapper</span></span><br><span class="line">        job.setMapperClass(MyCounterMap.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 输入目录</span></span><br><span class="line">        FileInputFormat.addInputPath(job, <span class="keyword">new</span> Path(args0[<span class="number">0</span>]));</span><br><span class="line">        <span class="comment">// 输出目录</span></span><br><span class="line">        FileOutputFormat.setOutputPath(job, <span class="keyword">new</span> Path(args0[<span class="number">1</span>]));</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 提交任务，并退出</span></span><br><span class="line">        System.exit(job.waitForCompletion(<span class="keyword">true</span>) ? <span class="number">0</span> : <span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>注意点：在没有 ReduceTask 的时候，  <code>job.setNumReduceTasks(0);</code></strong></p><p><a href="https://blog.csdn.net/qq_35732963/article/details/53358033" target="_blank" rel="noopener">关于计数器，详情可参考</a></p><hr>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;1-Combiner-组件&quot;&gt;&lt;a href=&quot;#1-Combiner-组件&quot; class=&quot;headerlink&quot; title=&quot;1.  Combiner 组件&quot;&gt;&lt;/a&gt;1.  Combiner 组件&lt;/h2&gt;&lt;h3 id=&quot;1-产生缘由：&quot;&gt;&lt;a href=
      
    
    </summary>
    
      <category term="Hadoop" scheme="https://airpoet.github.io/categories/Hadoop/"/>
    
      <category term="学习笔记" scheme="https://airpoet.github.io/categories/Hadoop/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="原创" scheme="https://airpoet.github.io/tags/%E5%8E%9F%E5%88%9B/"/>
    
      <category term="技术" scheme="https://airpoet.github.io/tags/%E6%8A%80%E6%9C%AF/"/>
    
      <category term="Hadoop" scheme="https://airpoet.github.io/tags/Hadoop/"/>
    
      <category term="MapReduce" scheme="https://airpoet.github.io/tags/MapReduce/"/>
    
  </entry>
  
  <entry>
    <title>MapReduce笔记-1  WordCount, MapReduce运行机制</title>
    <link href="https://airpoet.github.io/2018/06/06/Hadoop/Study/MapReduce%E7%AC%94%E8%AE%B0-1/"/>
    <id>https://airpoet.github.io/2018/06/06/Hadoop/Study/MapReduce笔记-1/</id>
    <published>2018-06-06T09:41:22.111Z</published>
    <updated>2018-06-08T11:58:53.510Z</updated>
    
    <content type="html"><![CDATA[<p>参考链接:</p><p><a href="https://mubu.com/doc/254d__SRSn" target="_blank" rel="noopener">hdfs 笔记</a> </p><p><a href="https://mubu.com/doc/1BuHQkjk0G" target="_blank" rel="noopener">mapreduce 笔记</a></p><h1 id="1、MapReduce-入门"><a href="#1、MapReduce-入门" class="headerlink" title="1、MapReduce 入门"></a>1、MapReduce 入门</h1><h3 id="1-1、MapReduce概念"><a href="#1-1、MapReduce概念" class="headerlink" title="1.1、MapReduce概念"></a>1.1、MapReduce概念</h3><p><strong>hadoop 的四大组件：</strong></p><ul><li><strong>HDFS</strong>：分布式存储系统</li><li><strong>MapReduce</strong>：分布式计算系统</li><li><strong>YARN</strong>：hadoop 的资源调度系统</li><li><strong>Common</strong>：以上三大组件的底层支撑组件，主要提供基础工具包和 RPC 框架等</li></ul><p>MapReduce 是一个分布式运算程序的编程框架，是用户开发“<strong>基于 Hadoop 的数据分析应用</strong>” 的核心框架</p><p>MapReduce <strong>核心功能</strong> ：<strong>将用户编写的业务逻辑代码</strong>和<strong>自带默认组件</strong>整合成一个完整的<strong>分布 式运算程序</strong>，<strong>并发运行</strong>在一个 Hadoop <strong>集群</strong>上</p><h3 id="1-2、为什么需要-MapReduce？"><a href="#1-2、为什么需要-MapReduce？" class="headerlink" title="1.2、为什么需要 MapReduce？"></a>1.2、为什么需要 MapReduce？</h3><p>引入 MapReduce 框架后，<strong>开发人员</strong>可以将绝大部分工作<strong>集中在业务逻辑</strong>的开发上，而将 <strong>分布式计算中的复杂性交由框架来处理</strong></p><p>Hadoop 当中的 <strong>MapReduce</strong> <strong>分布式程序运算框架</strong>的<strong>整体结构</strong>如下：</p><blockquote><p><strong>MRAppMaster</strong>：MapReduce Application Master，分配任务，协调任务的运行</p><p><strong>MapTask</strong>：阶段并发任，负责 mapper 阶段的任务处理</p><p>YARNChild</p><p><strong>ReduceTask</strong>：阶段汇总任务，负责 reducer 阶段的任务处理</p><p>YARNChild</p></blockquote><h3 id="1-3、MapReduce-的编写规范"><a href="#1-3、MapReduce-的编写规范" class="headerlink" title="1.3、MapReduce 的编写规范"></a>1.3、MapReduce 的编写规范</h3><p>MapReduce 程序编写规范：</p><ol><li>用户编写的程序分成<strong>三个部分</strong>：<strong>Mapper，Reducer，Driver</strong>(提交运行 MR 程序的客户端)</li><li>Mapper 的输入数据是 KV 对的形式（KV 的类型可自定义）</li><li>Mapper 的输出数据是 KV 对的形式（KV 的类型可自定义）</li><li>Mapper 中的业务逻辑写在 map()方法中</li><li>map()方法（maptask 进程）对每一个&lt;K,V&gt;调用一次</li><li>Reducer 的输入数据类型对应 Mapper 的输出数据类型，也是 KV 对的形式</li><li>Reducer 的业务逻辑写在 reduce()方法中</li><li>Reducetask 进程对每一组相同 k 的&lt;K,V&gt;组调用一次 reduce()方法</li><li>用户自定义的 Mapper 和 Reducer 都要继承各自的父类</li><li>整个程序需要一个 Drvier 来进行提交，提交的是一个描述了各种必要信息的 job 对象</li></ol><h3 id="1-4、WordCount-程序"><a href="#1-4、WordCount-程序" class="headerlink" title="1.4、WordCount 程序"></a>1.4、WordCount 程序</h3><h4 id="1、业务逻辑"><a href="#1、业务逻辑" class="headerlink" title="1、业务逻辑"></a>1、业务逻辑</h4><ol><li><p>maptask阶段处理每个数据分块的单词统计分析，思路是每遇到一个单词则把其转换成一个 key-value对，比如单词  hello，就转换成&lt;’hello’,1&gt;发送给 reducetask去汇总</p></li><li><p>reducetask阶段将接受  maptask的结果，来做汇总计数</p></li></ol><h4 id="2、具体代码实现"><a href="#2、具体代码实现" class="headerlink" title="2、具体代码实现"></a>2、具体代码实现</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line"> Map </span><br><span class="line"><span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">WordCountMapper</span> <span class="keyword">extends</span> <span class="title">Mapper</span>&lt;<span class="title">LongWritable</span>, <span class="title">Text</span>, <span class="title">Text</span>, <span class="title">IntWritable</span>&gt; </span>&#123;</span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">map</span><span class="params">(LongWritable key, Text value, Context context)</span></span></span><br><span class="line"><span class="function"><span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line"><span class="comment">// 计算任务代码：切割单词，输出每个单词计 1 的 key-value 对</span></span><br><span class="line">String[] words = value.toString().split(<span class="string">" "</span>);</span><br><span class="line"><span class="keyword">for</span> (String word : words) &#123;</span><br><span class="line">context.write(<span class="keyword">new</span> Text(word), <span class="keyword">new</span> IntWritable(<span class="number">1</span>));</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"> Reduce </span><br><span class="line"><span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">WordCountReducer</span> <span class="keyword">extends</span> <span class="title">Reducer</span>&lt;<span class="title">Text</span>, <span class="title">IntWritable</span>, <span class="title">Text</span>, <span class="title">IntWritable</span>&gt; </span>&#123;</span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">reduce</span><span class="params">(Text key, Iterable&lt;IntWritable&gt; values,</span></span></span><br><span class="line"><span class="function"><span class="params">Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line"><span class="comment">// 汇总计算代码：对每个 key 相同的一组 key-value 做汇总统计</span></span><br><span class="line"><span class="keyword">int</span> sum = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">for</span> (IntWritable v : values) &#123;</span><br><span class="line">sum += v.get();</span><br><span class="line">&#125;</span><br><span class="line">context.write(key, <span class="keyword">new</span> IntWritable(sum));</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"> main </span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line"><span class="comment">// 指定 hdfs 相关的参数</span></span><br><span class="line">Configuration conf = <span class="keyword">new</span> Configuration();</span><br><span class="line">conf.set(<span class="string">"fs.defaultFS"</span>, <span class="string">"hdfs://hadoop02:9000"</span>);</span><br><span class="line">System.setProperty(<span class="string">"HADOOP_USER_NAME"</span>, <span class="string">"hadoop"</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 新建一个 job 任务</span></span><br><span class="line">Job job = Job.getInstance(conf);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 设置 jar 包所在路径</span></span><br><span class="line">job.setJarByClass(WordCountMR.class);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 指定 mapper 类和 reducer 类</span></span><br><span class="line">job.setMapperClass(WordCountMapper.class);</span><br><span class="line">job.setReducerClass(WordCountReducer.class);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 指定 maptask 的输出类型</span></span><br><span class="line">job.setMapOutputKeyClass(Text.class);</span><br><span class="line">job.setMapOutputValueClass(IntWritable.class);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 指定 reducetask 的输出类型</span></span><br><span class="line">job.setOutputKeyClass(Text.class);</span><br><span class="line">job.setOutputValueClass(IntWritable.class);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 指定该 mapreduce 程序数据的输入和输出路径</span></span><br><span class="line">Path inputPath = <span class="keyword">new</span> Path(<span class="string">"/wordcount/input"</span>);</span><br><span class="line">Path outputPath = <span class="keyword">new</span> Path(<span class="string">"/wordcount/output"</span>);</span><br><span class="line">FileInputFormat.setInputPaths(job, inputPath);</span><br><span class="line">FileOutputFormat.setOutputPath(job, outputPath);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 最后提交任务</span></span><br><span class="line"><span class="keyword">boolean</span> waitForCompletion = job.waitForCompletion(<span class="keyword">true</span>);</span><br><span class="line">System.exit(waitForCompletion?<span class="number">0</span>:<span class="number">1</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="2、MapReduce-程序的核心运行机制"><a href="#2、MapReduce-程序的核心运行机制" class="headerlink" title="2、MapReduce 程序的核心运行机制"></a>2、MapReduce 程序的核心运行机制</h1><h3 id="2-1、概述"><a href="#2-1、概述" class="headerlink" title="2.1、概述"></a>2.1、概述</h3><p>一个完整的 MapReduce 程序在分布式运行时有两类实例进程：</p><ol><li>MRAppMaster：负责整个程序的过程调度及状态协调</li><li>Yarnchild：负责 map 阶段的整个数据处理流程</li><li>Yarnchild：负责 reduce 阶段的整个数据处理流程</li></ol><p>以上两个阶段 MapTask 和 ReduceTask 的进程都是 YarnChild ， 并不是说这 MapTask 和 ReduceTask 就跑在同一个 YarnChild 进行里</p><h3 id="2-2、MapReduce-程序的运行流程"><a href="#2-2、MapReduce-程序的运行流程" class="headerlink" title="2.2、MapReduce 程序的运行流程"></a>2.2、MapReduce 程序的运行流程</h3><ol><li>一个 mr 程序启动的时候，最先启动的是 MRAppMaster，MRAppMaster 启动后根据本次 job 的描述信息，计算出需要的 maptask 实例数量，然后向集群申请机器启动相应数量的 maptask 进程</li><li>maptask 进程启动之后，根据给定的数据切片(哪个文件的哪个偏移量范围)范围进行数 据处理，主体流程为：<ul><li>利用客户指定的 InputFormat 来获取 RecordReader 读取数据，形成输入 KV 对</li><li>将输入 KV 对传递给客户定义的 map()方法，做逻辑运算，并将 map()方法输出的 KV 对收 集到缓存</li><li>将缓存中的 KV 对按照 K 分区排序后不断溢写到磁盘文件</li></ul></li><li>MRAppMaster 监控到所有 maptask 进程任务完成之后（真实情况是，某些 maptask 进 程处理完成后，就会开始启动 reducetask 去已完成的 maptask 处 fetch 数据），会根据客户指 定的参数启动相应数量的 reducetask 进程，并告知 reducetask 进程要处理的数据范围（数据 分区）</li><li>Reducetask 进程启动之后，根据 MRAppMaster 告知的待处理数据所在位置，从若干台 maptask 运行所在机器上获取到若干个 maptask 输出结果文件，并在本地进行重新<strong>归并排序</strong>， 然后按照相同 key 的 KV 为一个组，调用客户定义的 reduce()方法进行逻辑运算，并收集运 算输出的结果 KV，然后调用客户指定的 OutputFormat 将结果数据输出到外部存储</li></ol><h3 id="2-3、MapTask-并行度决定机制"><a href="#2-3、MapTask-并行度决定机制" class="headerlink" title="2.3、MapTask 并行度决定机制"></a>2.3、MapTask 并行度决定机制</h3><p><strong>将待处理数据执行逻辑切片（即按照一个特定切片大小，将待处理数据划分成逻辑上的多 个 split），然后每一个 split 分配一个 mapTask 并行实例处理</strong>。</p><p>这段逻辑及形成的切片规划描述文件，是由 FileInputFormat 实现类的 getSplits()方法完成的。 该方法返回的是 List<inputsplit>，InputSplit 封装了每一个逻辑切片的信息，包括长度和位置 信息，而 getSplits()方法返回一组 InputSplit。</inputsplit></p><h3 id="2-4、切片机制"><a href="#2-4、切片机制" class="headerlink" title="2.4、切片机制"></a>2.4、切片机制</h3><h4 id="FileInputFormat-中默认的切片机制"><a href="#FileInputFormat-中默认的切片机制" class="headerlink" title="FileInputFormat 中默认的切片机制"></a><strong>FileInputFormat 中默认的切片机制</strong></h4><ol><li>简单地按照文件的内容长度进行切片</li><li>切片大小，默认等于 block 大小</li><li>切片时不考虑数据集整体，而是逐个针对每一个文件单独切片</li></ol><blockquote><p>比如待处理数据有两个文件：</p><p>File1.txt    200M </p><p>File2.txt    100M </p><p>经过 getSplits()方法处理之后，形成的切片信息是：</p><p>File1.txt-split1    0-128M</p><p>File1.txt-split2    129M-200M</p><p>File2.txt-split1    0-100M</p></blockquote><h4 id="FileInputFormat-中切片的大小的参数配置"><a href="#FileInputFormat-中切片的大小的参数配置" class="headerlink" title="FileInputFormat 中切片的大小的参数配置"></a>FileInputFormat 中切片的大小的参数配置</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 通过分析源码，在 FileInputFormat 中，计算切片大小的逻辑：</span></span><br><span class="line"><span class="keyword">long</span> splitSize = computeSplitSize(blockSize, minSize, maxSize)，翻译一下就是求这三个值的中 间值</span><br><span class="line"></span><br><span class="line"><span class="comment">// 切片主要由这几个值来运算决定：</span></span><br><span class="line">blocksize：默认是 <span class="number">128</span>M，可通过 dfs.blocksize 修改</span><br><span class="line">minSize：默认是 <span class="number">1</span>，可通过 mapreduce.input.fileinputformat.split.minsize 修改</span><br><span class="line">maxsize：默认是 Long.MaxValue，可通过 mapreduce.input.fileinputformat.split.maxsize 修改</span><br><span class="line"></span><br><span class="line"><span class="comment">//因此，如果 maxsize 调的比 blocksize 小，则切片会小于 blocksize;  如果 minsize 调的比 blocksize 大，则切片会大于 blocksize</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 但是，不论怎么调参数，都不能让多个小文件“划入”一个 split</span></span><br></pre></td></tr></table></figure><h3 id="2-5、MapTask-并行度经验之谈"><a href="#2-5、MapTask-并行度经验之谈" class="headerlink" title="2.5、MapTask 并行度经验之谈"></a>2.5、MapTask 并行度经验之谈</h3><p>如果硬件配置为 2*12core + 64G，恰当的 map 并行度是大约每个节点 20-100 个 map，最好 每个 map 的执行时间至少一分钟。</p><ol><li>如果 job 的每个 map 或者 reduce task 的运行时间都只有 30-40 秒钟，那么就减少该 job 的 map 或者 reduce 数，每一个 task(map|reduce)的 setup 和加入到调度器中进行调度，这个 中间的过程可能都要花费几秒钟，所以如果每个 task 都非常快就跑完了，就会在 task 的开 始和结束的时候浪费太多的时间。</li></ol><p><strong>配置 task 的 JVM 重用</strong>可以改善该问题：</p><ul><li><strong>mapred.job.reuse.jvm.num.tasks</strong>，默认是 1，表示一个 JVM 上最多可以顺序执行的 task 数目（属于同一个 Job）是 1。也就是说一个 task 启一个 JVM。</li><li>这个值可以在 <strong>mapred-site.xml</strong> 中进行更改，当设置成多个，就意味着这多个 task 运行在同一个 JVM 上，但不是同时执行， 是排队顺序执行</li></ul><ol start="2"><li>如果 input 的<strong>文件非常的大</strong>，比如 1TB，<strong>可以考虑</strong>将 hdfs 上的每个 <strong>blocksize 设大</strong>，比如 设成 256MB 或者 512MB</li></ol><h3 id="2-6、ReduceTask-并行度决定机制"><a href="#2-6、ReduceTask-并行度决定机制" class="headerlink" title="2.6、ReduceTask 并行度决定机制"></a>2.6、ReduceTask 并行度决定机制</h3><p><strong>reducetask</strong> 的并行度同样影响整个 job 的执行并发度和执行效率，但与 maptask 的并发数由 切片数决定不同，Reducetask 数量的决定是可以直接手动设置：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 设置 ReduceTask 的并行度</span></span><br><span class="line">job.setNumReduceTasks(<span class="number">4</span>);</span><br></pre></td></tr></table></figure><p>默认值是 1，</p><p>手动设置为 4，表示运行 4 个 reduceTask，</p><p>设置为 0，表示不运行 reduceTask 任务，也就是没有 reducer 阶段，只有 mapper 阶段</p><p><br></p><p>如果<strong>数据分布不均匀</strong>，就有<strong>可能在 reduce 阶段产生数据倾斜</strong></p><p>注意：reducetask 数量并不是任意设置，还要<strong>考虑业务逻辑需求</strong>，有些情况下，需要计算<strong>全局汇总结果</strong>，就<strong>只能有 1 个 reducetask</strong></p><p>尽量不要运行太多的 reducetask。对大多数 job 来说，最好 rduce 的个数最多和集群中的 reduce 持平，或者比集群的 reduce slots 小。这个对于小集群而言，尤其重要。</p><p><strong>最好的ReduceTask 个数是：datanode 个数 *  0.75~0.95 左右</strong></p><hr><h1 id="3-昨日复习"><a href="#3-昨日复习" class="headerlink" title="3. 昨日复习"></a>3. 昨日复习</h1><p>1.MapReduce 的 wc 编程</p><ul><li>手写代码<ul><li>Mapper</li><li>Reducer</li><li>Driver</li></ul></li></ul><p>2.MapTask 的并行度</p><ul><li>在程序执行的时候运行的 maptask 的总个数</li></ul><p>3.ReduceTask的并行度问题</p><ul><li>ReduceTask 的并行度设置依赖于自己传入的参数</li><li>一般经验： ReduceTask 的个数应该 = datanode 的阶段数 * （0.75~0.95）</li><li>ReduceTask 在设置的时候的并行度有一定的瓶颈</li><li>分区： 决定 ReduceTask 中的数据怎么分配的<ul><li>默认分区方式</li><li>自定义分区</li></ul></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;参考链接:&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://mubu.com/doc/254d__SRSn&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;hdfs 笔记&lt;/a&gt; &lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://mubu.com/doc/1
      
    
    </summary>
    
      <category term="Hadoop" scheme="https://airpoet.github.io/categories/Hadoop/"/>
    
      <category term="学习笔记" scheme="https://airpoet.github.io/categories/Hadoop/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="原创" scheme="https://airpoet.github.io/tags/%E5%8E%9F%E5%88%9B/"/>
    
      <category term="技术" scheme="https://airpoet.github.io/tags/%E6%8A%80%E6%9C%AF/"/>
    
      <category term="Hadoop" scheme="https://airpoet.github.io/tags/Hadoop/"/>
    
      <category term="MapReduce" scheme="https://airpoet.github.io/tags/MapReduce/"/>
    
  </entry>
  
  <entry>
    <title>▍Do Not Go Gentle into That Good Night</title>
    <link href="https://airpoet.github.io/2018/06/04/Poetry/%E2%96%8D%E3%80%8A%E4%B8%8D%E8%A6%81%E6%B8%A9%E5%92%8C%E7%9A%84%E8%B5%B0%E8%BF%9B%E9%82%A3%E4%B8%AA%E8%89%AF%E5%A4%9C%E3%80%8B--%E8%BF%AA%E5%85%B0%E6%89%98%E9%A9%AC%E6%96%AF/"/>
    <id>https://airpoet.github.io/2018/06/04/Poetry/▍《不要温和的走进那个良夜》--迪兰托马斯/</id>
    <published>2018-06-03T16:38:57.809Z</published>
    <updated>2018-06-09T17:19:23.133Z</updated>
    
    <content type="html"><![CDATA[<blockquote class="blockquote-center"><p><img src="http://p6i5vzkfk.bkt.clouddn.com/study/2018-06-03-521528043568_.pic.jpg" alt=""></p><p> <br></p><p>Do not go gentle into that good night,</p><p>Old age should burn and rave at close of the day;</p><p>Rage, rage against the dying of the light.</p><p><br></p><p>Though wise men at their end know dark is right,</p><p>Because their words had forked no lightning they</p><p>Do not go gentle into that good night.</p><p> <br></p><p>Good men, the last wave by, crying how bright</p><p>Their frail deeds might have danced in a green bay,</p><p>Rage, rage against the dying of the light.</p><p><br></p><p>Wild men, who caught and sang the sun in flight,</p><p>And learn, too late, they grieved it on its way,</p><p>Do not go gentle into that good night.</p><p><br></p><p>Grave men, near death, who see with blinding sight</p><p>Blind eyes could blaze like meteors and be gay,</p><p>Rage, rage against the dying of the light.</p><p><br></p><p>And you, my father, there on the sad height,</p><p>Curse, bless, me now with your fierce tears, I pray.</p><p>Do not go gentle into that good night.</p><p>Rage, rage against the dying of the light.</p><p><br></p><hr><p>  <br></p><p>《不要温和地走进那个良夜》 -巫宁坤译本</p><p>​    <br></p><p>不要温和地走进那个良夜，</p><p>老年应当在日暮时燃烧咆哮；</p><p>怒斥，怒斥光明的消逝。</p><p>  <br></p><p>虽然智慧的人临终时懂得黑暗有理，</p><p>因为他们的话没有进发出闪电，他们</p><p>也并不温和地走进那个良夜。</p><p><br>  </p><p>善良的人，当最后一浪过去，高呼他们脆弱的善行</p><p>可能曾会多么光辉地在绿色的海湾里舞蹈，</p><p>怒斥，怒斥光明的消逝。</p><p>狂暴的人抓住并歌唱过翱翔的太阳，</p><p>懂得，但为时太晚，他们使太阳在途中悲伤，</p><p>也并不温和地走进那个良夜。</p><p>  <br></p><p>严肃的人，接近死亡，用炫目的视觉看出</p><p>失明的跟睛可以像流星一样闪耀欢欣，</p><p>怒斥，恕斥光明的消逝。</p><p>  <br></p><p>您啊，我的父亲，在那悲哀的高处。</p><p>现在用您的热泪诅咒我，祝福我吧。我求您</p><p>不要温和地走进那个良夜。</p><p>怒斥，怒斥光明的消逝</p><p><br></p><hr><p>《不要温顺地走入那长夜》 -和菜头译本</p><p><br></p><p>白日将尽，暮年仍应燃烧咆哮</p><p>狂怒吧，狂怒吧！</p><p>对抗着光明渐逝</p><p><br></p><p>虽然智者深知</p><p>人之将死，黑暗自有其时</p><p>只因他们所言未曾裂天如电</p><p>他们不要温顺地走入那长夜</p><p><br></p><p>随着最后一浪，善人在哭喊</p><p>哭喊那脆弱的善行</p><p>它本应何其欢快</p><p>在绿色峡湾里起舞</p><p>狂怒吧，狂怒吧！</p><p>对抗着光明渐逝。</p><p><br></p><p>狂人曾抓住飞驰的太阳</p><p>放声歌唱</p><p>太晚，他们才感到其中的伤感</p><p>不要温顺地走进那长夜</p><p><br></p><p>严肃的人行将死去时</p><p>用那渐渐失神的目光去看</p><p>盲瞳却如流星璀璨，欢欣溢满</p><p>狂怒吧，狂怒吧！</p><p>对抗着光明渐逝</p><p><br></p><p>还有你啊，我的父亲，远在悲伤的高地</p><p>我恳请你现在</p><p>就让你诅咒，你的祝福</p><p>随着热泪落下</p><p>不要温顺地走进那长夜</p><p>狂怒吧，狂怒吧！</p><p>对抗这光明渐逝</p><p><br></p><hr><p>​       《 绝不向黑夜请安》  -高晓松译本</p><p>绝不向黑夜请安</p><p>老朽请于白日尽头涅槃</p><p>咆哮于光之消散</p><p><br></p><p>先哲虽败于幽暗</p><p>诗歌终不能将苍穹点燃</p><p>绝不向黑夜请安</p><p><br></p><p>贤者舞蹈于碧湾</p><p>为惊涛淹没的善行哭喊</p><p>咆哮于光之消散</p><p><br></p><p>狂者如夸父逐日</p><p>高歌中顿觉迟来的伤感</p><p>绝不向黑夜请安</p><p><br></p><p>逝者于临终迷幻</p><p>盲瞳怒放出流星的灿烂</p><p>咆哮于光之消散</p><p><br></p><p>那么您，我垂垂将死的父亲</p><p>请掬最后一捧热泪降临</p><p>请诅咒，请保佑</p><p>我祈愿，绝不向</p><p>黑夜请安，咆哮</p><p>于光之消散</p><p><br> </p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote class=&quot;blockquote-center&quot;&gt;&lt;p&gt;&lt;img src=&quot;http://p6i5vzkfk.bkt.clouddn.com/study/2018-06-03-521528043568_.pic.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt; 
      
    
    </summary>
    
      <category term="文艺" scheme="https://airpoet.github.io/categories/%E6%96%87%E8%89%BA/"/>
    
      <category term="诗歌" scheme="https://airpoet.github.io/categories/%E6%96%87%E8%89%BA/%E8%AF%97%E6%AD%8C/"/>
    
    
      <category term="诗歌" scheme="https://airpoet.github.io/tags/%E8%AF%97%E6%AD%8C/"/>
    
  </entry>
  
  <entry>
    <title>Hadoop学习笔记-3 HDFS 原理剖析</title>
    <link href="https://airpoet.github.io/2018/06/03/Hadoop/Study/Hadoop%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-3-HDFS%E5%8E%9F%E7%90%86%E5%89%96%E6%9E%90/"/>
    <id>https://airpoet.github.io/2018/06/03/Hadoop/Study/Hadoop学习笔记-3-HDFS原理剖析/</id>
    <published>2018-06-03T09:12:34.396Z</published>
    <updated>2018-06-08T09:31:27.200Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-HDFS体系结构"><a href="#1-HDFS体系结构" class="headerlink" title="1.  HDFS体系结构"></a>1.  HDFS体系结构</h2><p>主从。。。</p><p><br></p><h2 id="2-NameNode"><a href="#2-NameNode" class="headerlink" title="2.NameNode"></a>2.NameNode</h2><h3 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h3><ul><li><p>[x] 是整个文件系统的管理节点。它维护着整个文件系统的文件目录树，文件/目录的元信息和每个文件对应的数据块列表。接收用户的操作请求。 </p></li><li><p>[x] <strong>在<code>hdfs-site.xml</code>中的<code>dfs.namenode.name.dir</code>属性</strong> </p></li><li><p>[x] 文件包括： </p><ul><li><p>[x] 文件包括:</p><p><strong>①fsimage</strong>:元数据镜像文件。存储某一时段<code>NameNode</code>内存元数据信息。</p><p><strong>②edits</strong>:操作日志文件。</p><p><strong>③fstime</strong>:保存最近一次<code>checkpoint</code>的时间</p><p><strong>以上这些文件是保存在linux的文件系统中。</strong></p></li></ul></li></ul><h3 id="查看-fsimage-和-edits的内容"><a href="#查看-fsimage-和-edits的内容" class="headerlink" title="查看 fsimage 和 edits的内容"></a>查看 <code>fsimage</code> 和 <code>edits</code>的内容</h3><ol><li><p>查看 <code>NameNode中</code> <code>fsimage</code> 的内容 </p><ul><li><p>查看 <strong>fsimage镜像文件</strong>内容<code>Usage: bin/hdfs oiv [OPTIONS] -i INPUTFILE -o  OUTPUTFILE</code></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 可以知道数据存在那个哪个 fsimage 镜像中</span></span><br><span class="line">------------------------------------</span><br><span class="line"><span class="comment"># 使用离线的查看器 输出到网页查看</span></span><br><span class="line">oiv -i hadoopdata/namenode/current/fsimage_0000000000000000250 -o 0000000000000000250</span><br><span class="line"></span><br><span class="line"><span class="comment"># 出现这样的提示</span></span><br><span class="line">INFO offlineImageViewer.WebImageViewer: WebImageViewer started. Listening on /127.0.0.1:5978. Press Ctrl+C to stop the viewer.</span><br><span class="line"></span><br><span class="line"><span class="comment"># 另起一个窗口查看</span></span><br><span class="line">hadoop fs -ls -R webhdfs://127.0.0.1:5978</span><br><span class="line">------------------------------------</span><br><span class="line"></span><br><span class="line"><span class="comment"># 也可以导出到 xml 文件</span></span><br><span class="line">bin/hdfs oiv -p XML -i  tmp/dfs/name/current/fsimage_0000000000000000055 -o fsimage.xml</span><br></pre></td></tr></table></figure></li></ul></li></ol><ol start="2"><li><p>查看<code>edits</code>文件， 也可以导出到 xml</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看edtis内容</span></span><br><span class="line">bin/hdfs oev -i tmp/dfs/name/current/edits_0000000000000000057-0000000000000000186   -o edits.xml</span><br></pre></td></tr></table></figure></li></ol><p><br></p><h2 id="3-Datanode"><a href="#3-Datanode" class="headerlink" title="3.  Datanode"></a>3.  Datanode</h2><p><strong>提供真实文件数据的存储服务</strong></p><ul><li><p><strong>Datanode 节点的数据切块存储位置</strong></p><ul><li><p><code>~/hadoopdata/datanode/current/BP-1070660005-192.168.170.131-1527865615372/current/finalized/subdir0/subdir0</code></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[ap@cs2]~/hadoopdata/datanode/current/BP-1070660005-192.168.170.131-1527865615372/current/finalized/subdir0/subdir0% ll</span><br><span class="line">总用量 213340</span><br><span class="line">-rw-r--r-- 1 ap ap 134217728 6月   2 13:35 blk_1073741842</span><br><span class="line">-rw-r--r-- 1 ap ap   1048583 6月   2 13:35 blk_1073741842_1018.meta</span><br><span class="line">-rw-r--r-- 1 ap ap  82527955 6月   2 13:35 blk_1073741843</span><br><span class="line">-rw-r--r-- 1 ap ap    644759 6月   2 13:35 blk_1073741843_1019.meta</span><br><span class="line">-rw-r--r-- 1 ap ap        13 6月   3 02:12 blk_1073741850</span><br><span class="line">-rw-r--r-- 1 ap ap        11 6月   3 02:12 blk_1073741850_1028.meta</span><br></pre></td></tr></table></figure></li></ul></li></ul><ul><li><p>文件块（block）：最基本的存储单位。对于文件内容而言，一个文件的长度大小是size，那么从文件的０偏移开始，按照固定的大小，顺序对文件进行划分并编号，划分好的每一个块称一个Block。HDFS默认Block大小是128MB，以一个256MB文件，共有256/128=2个Block.</p></li><li><p>不同于普通文件系统的是，<strong>HDFS中，如果一个文件小于一个数据块的大小，并不占用整个数据块存储空间, 按文件大小的实际容量存储</strong></p></li><li><p>Replication。多复本。默认是三个。</p><ul><li><code>hdfs-site.xml</code>的<code>dfs.replication</code>属性 </li><li>手动设置某个文件的副本数为3个<ul><li><code>bin/hdfs dfs -setrep 3 /a.txt</code></li></ul></li></ul></li></ul><h2 id="4-数据存储：-写文件解析"><a href="#4-数据存储：-写文件解析" class="headerlink" title="4.  数据存储： 写文件解析"></a>4.  数据存储： 写文件解析</h2><ul><li><p>[x] <strong>疑点</strong>： HDFS client上传数据到HDFS时，会<strong>首先在本地缓存数据</strong>，当<strong>数据达到一个block大小时，请求NameNode分配一个block。</strong>NameNode会把block所在的DataNode的地址告诉HDFS client。HDFS client会直接和DataNode通信，把数据写到DataNode节点一个block文件中。 </p><blockquote><p>问题： 如果一直写的数据都没有达到一个 block 大小， 那怎么存储？？</p></blockquote></li></ul><p><img src="http://p6i5vzkfk.bkt.clouddn.com/study/2018-06-03-125641.png" alt="image-20180603205640605"></p><p><img src="http://p6i5vzkfk.bkt.clouddn.com/study/2018-06-03-125412.png" alt="image-20180603205412264"></p><h3 id="写文件的过程："><a href="#写文件的过程：" class="headerlink" title="写文件的过程："></a>写文件的过程：</h3><ol><li>首先调用FileSystem对象的open方法，其实是一个DistributedFileSystem的实例</li><li>DistributedFileSystem通过rpc获得文件的第一批个block的locations，同一block按照重复数会返回多个locations，这些locations按照hadoop拓扑结构排序，距离客户端近的排在前面.</li><li>前两步会返回一个FSDataInputStream对象，该对象会被封装成DFSInputStream对象，DFSInputStream可以方便的管理datanode和namenode数据流。客户端调用read方法，DFSInputStream最会找出离客户端最近的datanode并连接。</li><li>数据从datanode源源不断的流向客户端。</li><li>如果第一块的数据读完了，就会关闭指向第一块的datanode连接，接着读取下一块。这些操作对客户端来说是透明的，客户端的角度看来只是读一个持续不断的流。</li><li>如果第一批block都读完了，DFSInputStream就会去namenode拿下一批blocks的location，然后继续读，如果所有的块都读完，这时就会关闭掉所有的流。</li></ol><blockquote><p> 如果在读数据的时候，DFSInputStream和datanode的通讯发生异常，就会尝试正在读的block的排第二近的datanode,并且会记录哪个datanode发生错误，剩余的blocks读的时候就会直接跳过该datanode。DFSInputStream也会检查block数据校验和，如果发现一个坏的block,就会先报告到namenode节点，然后DFSInputStream在其他的datanode上读该block的镜像</p></blockquote><blockquote><p>该设计的方向就是客户端直接连接datanode来检索数据并且namenode来负责为每一个block提供最优的datanode，namenode仅仅处理block location的请求，这些信息都加载在namenode的内存中，hdfs通过datanode集群可以承受大量客户端的并发访问。</p></blockquote><p><br></p><h2 id="5-数据存储：-读文件解析"><a href="#5-数据存储：-读文件解析" class="headerlink" title="5.  数据存储： 读文件解析"></a>5.  数据存储： 读文件解析</h2><p><img src="http://p6i5vzkfk.bkt.clouddn.com/study/2018-06-03-125556.png" alt="image-20180603205556077"></p><p><img src="http://p6i5vzkfk.bkt.clouddn.com/study/2018-06-03-125203.png" alt="image-20180603205203151"></p><h3 id="读文件的过程"><a href="#读文件的过程" class="headerlink" title="读文件的过程"></a>读文件的过程</h3><ol><li>首先调用FileSystem对象的open方法，其实是一个DistributedFileSystem的实例</li><li>DistributedFileSystem通过rpc获得文件的第一批个block的locations，同一block按照重复数会返回多个locations，这些locations按照hadoop拓扑结构排序，距离客户端近的排在前面.</li><li>前两步会返回一个FSDataInputStream对象，该对象会被封装成DFSInputStream对象，DFSInputStream可以方便的管理datanode和namenode数据流。客户端调用read方法，DFSInputStream最会找出离客户端最近的datanode并连接。</li><li>数据从datanode源源不断的流向客户端。</li><li>如果第一块的数据读完了，就会关闭指向第一块的datanode连接，接着读取下一块。这些操作对客户端来说是透明的，客户端的角度看来只是读一个持续不断的流。</li><li>如果第一批block都读完了，DFSInputStream就会去namenode拿下一批blocks的location，然后继续读，如果所有的块都读完，这时就会关闭掉所有的流。</li></ol><blockquote><p> 如果在读数据的时候，DFSInputStream和datanode的通讯发生异常，就会尝试正在读的block的排第二近的datanode,并且会记录哪个datanode发生错误，剩余的blocks读的时候就会直接跳过该datanode。DFSInputStream也会检查block数据校验和，如果发现一个坏的block,就会先报告到namenode节点，然后DFSInputStream在其他的datanode上读该block的镜像</p></blockquote><blockquote><p>该设计的方向就是客户端直接连接datanode来检索数据并且namenode来负责为每一个block提供最优的datanode，namenode仅仅处理block location的请求，这些信息都加载在namenode的内存中，hdfs通过datanode集群可以承受大量客户端的并发访问。</p></blockquote><p><br></p><h2 id="6-Hadoop-Archives-（HAR-files）"><a href="#6-Hadoop-Archives-（HAR-files）" class="headerlink" title="6.Hadoop Archives （HAR files）"></a>6.Hadoop Archives （HAR files）</h2><p><strong>Hadoop Archives (HAR files)</strong>是在0.18.0版本中引入的，它的出现就是为了<strong>缓解大量小文件消耗namenode内存</strong>的问题。HAR文件是<strong>通过在HDFS上构建一个层次化的文件系统</strong>来工作。一个HAR文件是<strong>通过hadoop的archive命令来创建</strong>，而这个命令<strong>实 际上也是运行了一个MapReduce任务来将小文件打包成HAR</strong>。对于client端来说，使用HAR文件没有任何影响。所有的原始文件都 （using har://URL）。但在HDFS端它内部的文件数减少了。</p><p>通过HAR来读取一个文件并不会比直接从HDFS中读取文件高效，而且实际上可能还会稍微低效一点，因为对每一个HAR文件的访问都需要完成两层 index文件的读取和文件本身数据的读取。并且尽管HAR文件可以被用来作为MapReduce job的input，但是并没有特殊的方法来使maps将HAR文件中打包的文件当作一个HDFS文件处理。</p><p><strong>打包出来的 har 文件在<code>xxx.har/part-0</code>  中， contentz-size 跟原来的文件总大小一样</strong></p><p><strong>创建文件</strong> <code>hadoop archive -archiveName xxx.har -p  /src  /dest</code><br><strong>查看内容</strong> <code>hadoop fs -lsr har:///dest/xxx.har</code> 可以原封不动的显示出来</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 打包成 har</span></span><br><span class="line">hadoop archive -archiveName test.har -p /user/<span class="built_in">test</span> /</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看har 文件</span></span><br><span class="line">[ap@cs1]~% hadoop fs -count /test.har/part-0</span><br><span class="line">           0(目录数)            1(文件数)         72(文件大小)    /test.har/part-0 (文件名)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看打包前文件</span></span><br><span class="line">[ap@cs1]~% hadoop fs -count /user/<span class="built_in">test</span></span><br><span class="line">           1            2                 72 /user/<span class="built_in">test</span></span><br><span class="line">           </span><br><span class="line"><span class="comment"># 查看 har 文件， 把打包前的原本文件都显示出来了</span></span><br><span class="line">[ap@cs1]~% hadoop fs -ls -R har:///test.har</span><br><span class="line">-rw-r--r--   3 ap supergroup         50 2018-06-03 04:24 har:///test.har/a.txt</span><br><span class="line">-rw-r--r--   3 ap supergroup         22 2018-06-03 04:24 har:///test.har/b.txt</span><br></pre></td></tr></table></figure><p><strong>注意点：</strong></p><ul><li><strong>存储层面：</strong>为了解决小文件过多导致的 Namenode 压力过大问题， 把很多小文件打包成一个 har 文件。<ul><li><strong>使用层面：</strong> 但是实际处理的时候， 还是会还原出原本的小文件进行处理， 不会把 har 文件当成一个 HDFS 文件处理。 </li><li><strong>HDFS</strong> 上不支持 tar， <strong>只支持 har打包</strong></li></ul></li></ul><h2 id="7-HDFS-的-HA"><a href="#7-HDFS-的-HA" class="headerlink" title="7.HDFS 的 HA"></a>7.HDFS 的 HA</h2>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;1-HDFS体系结构&quot;&gt;&lt;a href=&quot;#1-HDFS体系结构&quot; class=&quot;headerlink&quot; title=&quot;1.  HDFS体系结构&quot;&gt;&lt;/a&gt;1.  HDFS体系结构&lt;/h2&gt;&lt;p&gt;主从。。。&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&quot;2-Na
      
    
    </summary>
    
      <category term="Hadoop" scheme="https://airpoet.github.io/categories/Hadoop/"/>
    
      <category term="学习笔记" scheme="https://airpoet.github.io/categories/Hadoop/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="原创" scheme="https://airpoet.github.io/tags/%E5%8E%9F%E5%88%9B/"/>
    
      <category term="技术" scheme="https://airpoet.github.io/tags/%E6%8A%80%E6%9C%AF/"/>
    
      <category term="Hadoop" scheme="https://airpoet.github.io/tags/Hadoop/"/>
    
      <category term="HDFS" scheme="https://airpoet.github.io/tags/HDFS/"/>
    
  </entry>
  
  <entry>
    <title>▍回答</title>
    <link href="https://airpoet.github.io/2018/06/03/Poetry/%E5%9B%9E%E7%AD%94/"/>
    <id>https://airpoet.github.io/2018/06/03/Poetry/回答/</id>
    <published>2018-06-03T06:40:41.275Z</published>
    <updated>2018-06-09T17:12:20.524Z</updated>
    
    <content type="html"><![CDATA[<blockquote class="blockquote-center"><p><img src="http://p6i5vzkfk.bkt.clouddn.com/study/2018-06-03-511528043539_.pic.jpg" alt=""></p><p><br></p><p>卑鄙是卑鄙者的通行证，<br>高尚是高尚者的墓志铭，<br>看吧，在那镀金的天空中，<br>飘满了死者弯曲的倒影。</p><p><br></p><p>冰川纪过去了，<br>为什么到处都是冰凌？<br>好望角发现了，<br>为什么死海里千帆相竞？</p><p><br></p><p>我来到这个世界上，<br>只带着纸、绳索和身影，<br>为了在审判之前，<br>宣读那些被判决的声音。</p><p><br></p><p>告诉你吧，世界<br>我–不–相–信！<br>纵使你脚下有一千名挑战者，<br>那就把我算作第一千零一名。</p><p><br></p><p>我不相信天是蓝的，<br>我不相信雷的回声，<br>我不相信梦是假的，<br>我不相信死无报应。</p><p><br></p><p>如果海洋注定要决堤，<br>就让所有的苦水都注入我心中，<br>如果陆地注定要上升，<br>就让人类重新选择生存的峰顶。</p><p><br></p><p>新的转机和闪闪星斗，<br>正在缀满没有遮拦的天空。<br>那是五千年的象形文字，<br>那是未来人们凝视的眼睛。</p><p><br></p><p>作者 / 北岛</p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote class=&quot;blockquote-center&quot;&gt;&lt;p&gt;&lt;img src=&quot;http://p6i5vzkfk.bkt.clouddn.com/study/2018-06-03-511528043539_.pic.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;
      
    
    </summary>
    
      <category term="文艺" scheme="https://airpoet.github.io/categories/%E6%96%87%E8%89%BA/"/>
    
      <category term="诗歌" scheme="https://airpoet.github.io/categories/%E6%96%87%E8%89%BA/%E8%AF%97%E6%AD%8C/"/>
    
    
      <category term="诗歌" scheme="https://airpoet.github.io/tags/%E8%AF%97%E6%AD%8C/"/>
    
  </entry>
  
  <entry>
    <title>Hadoop学习笔记-2 HDFS基础入门</title>
    <link href="https://airpoet.github.io/2018/06/02/Hadoop/Study/Hadoop%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-2-HDFS%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/"/>
    <id>https://airpoet.github.io/2018/06/02/Hadoop/Study/Hadoop学习笔记-2-HDFS基础入门/</id>
    <published>2018-06-02T07:07:33.222Z</published>
    <updated>2018-06-09T12:39:31.554Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Hadoop的核心组件-之-HDFS"><a href="#Hadoop的核心组件-之-HDFS" class="headerlink" title="Hadoop的核心组件 之 HDFS"></a>Hadoop的核心组件 之 HDFS</h1><h2 id="HDFS"><a href="#HDFS" class="headerlink" title="HDFS"></a>HDFS</h2><h3 id="1-HDFS是什么"><a href="#1-HDFS是什么" class="headerlink" title="1. HDFS是什么:"></a>1. HDFS是什么:</h3><ul><li>分布式文件系统</li></ul><h3 id="2-HDFS-设计思想"><a href="#2-HDFS-设计思想" class="headerlink" title="2. HDFS 设计思想"></a>2. HDFS 设计思想</h3><ul><li>分而治之,  切分存储, 当一个文件过大的时候, 一个节点存储不了, 采用切分存储</li><li><strong>分块存储</strong>: 每一个块叫做 block<ul><li>如果一个8T的数据, 这个怎么分合适???<ul><li>设置分块的时候要<strong>考虑</strong>一个事情 : <strong>负载均衡</strong></li><li>块的大小不能太大, 太大会造成负载不均衡</li><li><strong>hadoop2.x</strong> 中默认的切分的<strong>块的大小</strong>是: <strong>128M</strong>, 1.x中默认的是64M</li><li>如果一个文件<strong>不足128M, 也会单独存一个快</strong>, <strong>快的大小就是存储数据的实际大小</strong></li></ul></li><li>这个分块存储思想中, 如果一个块的存储节点宕机了, 这个时候, 数据的安全性得不到保证了</li></ul></li><li>HDFS中默认块的存储采用<strong>备份机制</strong><ul><li><strong>默认的备份个数是3个</strong>(总共存的, 存到datanode上的, namenode不存),  之前自己配的是2个, 所有备份相同地位是相同的.</li><li>相同的数据块的备份一定存储在不同的节点上</li><li>如果节点总共2个,  <code>dfs.replication=3</code> 副本个数是3个,  实际存储2个, 另一个进行<strong>记账</strong>,  当集群节点个数大于3个时, 会复制这个副本, 最终达到3个</li><li>假设集群中的节点4个, 副本3个, 有一个副本的机器宕机了, 这个时候发现副本的个数 小于 设定的个数,  就会进行<strong>复制, 达到3个副本</strong>,</li><li>如果 <em>这个时候</em>, 刚才宕机的节点又恢复了, 这个时候集群副本个数为4了,  集群会等待一段时间, 如果发现还是4个, 就会<strong>删除</strong>一个副本, <strong>达到3个</strong>(<u>设定值</u>)</li><li>备份越多越好吗?<ul><li>理论上副本数越多, 数据安全性越高</li><li>但是副本数越多, 会占用过多的存储资源, 会造成集群的维护变得越困难<ul><li>100 个节点, 50个副本,  在这50个副本中, 随时都有可能宕机, hdfs就需要维护副本</li></ul></li><li>一般情况下, 3个就可以了</li><li>hadoop是基于廉价的pc机设计的, 会造成机器随时可能宕机</li></ul></li></ul></li><li>HDFS的<strong>目录结构</strong><ul><li>hdfs的目录结构与linux 操作系统类似,  以 <code>/</code>为跟节点,  我们将这个目录🌲称为<code>抽象目录树</code></li><li>因为<strong>hdfs的目录结构</strong>代表的是所有数据节点的<strong>抽象出来的目录</strong>,  不代表任何一个节点<ul><li>hdfs:  /hadoop.zip   500M  被分成4个块存储</li><li>hdfs中存储的数据块 是有编号的, blk_1,  blk_2, blk_3,  blk_4</li><li>/spark.zip  300M  3个块, blk_5  blk_6  blk_7</li><li>底层存储的时候, 每一个block都有一个唯一的id</li><li>hdfs的数据底层存储的时候吗, 还是存在真正的物理节点上.</li></ul></li></ul></li></ul><h3 id="2-HDFS-的整体结构"><a href="#2-HDFS-的整体结构" class="headerlink" title="2. HDFS 的整体结构"></a>2. HDFS 的整体结构</h3><p><strong>主从结构:  一个主节点,  多个从节点</strong></p><h4 id="namenode"><a href="#namenode" class="headerlink" title="namenode:"></a>namenode:</h4><ul><li>用于存储元数据, 包括: <ul><li>抽象目录树</li><li>存储数据和block的对应关系</li><li>block存储的位置</li></ul></li><li>处理客户端的读写请求<ul><li>读: 下载</li><li>写: 上传</li></ul></li></ul><h4 id="datanode"><a href="#datanode" class="headerlink" title="datanode"></a>datanode</h4><ul><li>负责真正的数据存储, 存储数据的block</li><li>真正处理读写</li></ul><h4 id="secondarynamenode"><a href="#secondarynamenode" class="headerlink" title="secondarynamenode:"></a>secondarynamenode:</h4><ul><li>冷备份节点: 助理<ul><li>当namenode宕机的时候,  secondarynamenode不能主动切换为 namenode, 但是 secondarynamenode中存储的数据与namenode相同.</li></ul></li><li>主要作用: <ul><li>namenode宕机的时候, 帮助namenode恢复</li><li>帮助namenode做一些事情, 分担namenode的压力</li></ul></li></ul><h3 id="3-HDFS优缺点"><a href="#3-HDFS优缺点" class="headerlink" title="3. HDFS优缺点:"></a>3. HDFS优缺点:</h3><ul><li><p>优点: </p><ol><li><p>可构建在廉价机器上, 成本低,  通过多副本提高可靠性, 提供了容错和恢复机制</p></li><li><p>高容错性</p><ul><li>容错性: 数据访问上, 一个节点数据丢失, 不影响整体的数据访问</li><li>数据自动保存多个副本, 副本丢失后, 自动恢复, 最终恢复到用户配置的副本个数</li></ul></li><li><p>适合批处理, 适合离线数据处理</p><ul><li>移动计算而非数据, 数据位置暴露给计算框架</li></ul></li><li><p>适合大数据处理</p><ul><li>GB,  TB 甚至 PB 级数据, 百万规模以上的文件数量, 10k+ 节点规模</li></ul></li><li><p>流式文件访问, 不支持数据修改, hdfs用于数据存储</p><ul><li>一次性写入, 多次读取, 保证数据一致性</li></ul></li></ol></li></ul><ul><li><p><strong>缺点:</strong> </p><ol><li>不支持低延迟的数据访问, 不支持 <strong>实时/近实时</strong> 数据访问, 因为涉及到多轮<code>RPC</code>调用<ol><li>向 NameNode 寻址..</li><li>拿到地址后， 向 DataNode 请求数据..</li></ol></li><li><strong>不擅长存储大量的小文件</strong>–kb级别的<ul><li>寻址时间可能大于读取数据的时间, 不划算<ul><li>进行数据访问的时候先找元数据</li><li>元数据是和block对应的, 1个block块对应一条元数据</li><li>1000w个1kb的文件, 存了1000w个块 — 1000w元数据</li><li>在进行数据访问的时候可能花了 1s 的时间, 总体上不划算</li></ul></li><li>这样会造成元数据存储量过大, 增加namenode的压力<ul><li>在hdfs中一般情况下, 一条元数据大小 150byte 左右</li><li>1000w条元数据 — 1000w * 150,  1.5G左右</li></ul></li></ul></li><li><strong>不支持文件内容修改</strong>, 仅<strong>仅支持</strong>文件<strong>末尾追加</strong> <code>append</code>， 一个文件同时只能有一个写者，<strong>不支持并发操作</strong></li></ol></li></ul><h3 id="4-HDFS-的-常用命令"><a href="#4-HDFS-的-常用命令" class="headerlink" title="==4. HDFS 的 常用命令:=="></a>==4. HDFS 的 常用命令:==</h3><p><strong>HDFS归根结底就是一个文件系统,  类似于 linux,  需要用命令来操作</strong></p><h4 id="1-hapdoop-fs-命令"><a href="#1-hapdoop-fs-命令" class="headerlink" title="1. hapdoop fs 命令"></a>1. <code>hapdoop fs</code> 命令</h4><blockquote><p><code>hadoop fs</code> /  <code>hdfs dfs</code> 效果是一样的</p><p>在hadoop中查看, 只有绝对路径的访问方式</p></blockquote><ol><li><p>查看帮助</p><ul><li><code>hadoop fs -help</code> 查看所有 <code>hadoop fs</code>的帮助</li><li><code>hadoop fs -help ls</code> 查看 <code>fs</code>下的 <code>ls</code>的帮助</li></ul></li><li><p><strong>列出根目录</strong>: <code>hadoop fs -ls /</code></p><ul><li><code>hadoop fs -ls -R /</code> 递归展示</li><li><code>hadoop fs -ls -R -h /</code>友好展示， 展示文件大小单位</li><li><strong>如果不指定目录， 会默认找当前用户xx对应的<code>/user/xx</code>的目录</strong></li></ul></li><li><p><strong>递归创建 -mkdir -p</strong>:  </p><ul><li><code>hadoop fs -mkdir -p /aa/bb/cc/dd</code></li><li>不加 -p  为普通创建</li></ul></li><li><p><strong>创建空文件<code>-touchz</code></strong></p><ul><li>类似于 Linux 下的 touch</li></ul></li><li><p><strong>上传  put</strong>: <code>[-put [-f][-p] [-l] &lt;localsrc&gt; ... &lt;dst&gt;]</code></p><ul><li>上传一个: <code>hadoop fs -put hadoop-2.7.6.tar.gz /ss</code></li><li>上传多个: <code>hadoop fs -put aa.txt bb.txt /ss</code></li></ul></li><li><p><strong>下载 get</strong></p><ul><li><code>hadoop fs -get hdfs路径 本地路径</code></li></ul></li><li><p><strong>合并下载 getmerge</strong></p><ul><li><code>hadoop fs -getmerge /ss/aa.txt /ss/bb.txt /home/ap/cc.txt</code></li><li>会将最后一个路径之前8的当做需要合并的文件, 最后一个路径中指定的文件就是合并生成的文件</li></ul></li><li><p><strong>查看文件内容 cat</strong></p><ul><li><code>-cat</code> 查看文件内容</li><li><code>-text</code>也是类似</li></ul></li><li><p><strong>删除文件  rm</strong></p><ul><li><sub></sub>rm -rf (错误的)<sub></sub></li><li>rm -r(递归)  -f(强制)</li><li>文件<code>hadoop fs -rm -f /ss/aa.txt</code></li><li>文件夹 <code>hadoop fs -rm -f -r /aa</code></li></ul></li><li><p><strong>mv 修改名字, 移动</strong></p><ul><li><p>移动的文件<strong>从 hdfs 到 hdfs</strong></p></li><li><p><code>hadoop fs -mv  ..  ..</code></p></li></ul></li><li><p><strong>cp 复制</strong></p><ul><li><code>hadoop fs -cp /hdfsfile /hdfsfile</code>: 从 hdfs 复制到 hdfs<ul><li>参数 <strong>-p</strong>  ： 复制后<strong>保持文件的原本属性</strong>, 时间戳， 权限等<ul><li><code>Passing -p preserves status [topax] (timestamps, ownership, permission, ACLs, XAttr).</code></li></ul></li><li>参数 <strong>-f</strong>   :   已有同名文件的话， 直接<strong>覆盖</strong></li></ul></li></ul></li><li><p><strong>在末尾追加</strong>: <code></code>-appendToFile 本地文件  hdfs文件` </p><ul><li>将本地文件bb.txt 追加到 htfd的 /aa/aa.txt 上<ul><li><code>hadoop fs -appendToFile aa.txt /ss/bb.txt</code></li></ul></li><li>从命令行追加 , 但是不知道怎么结束， 先存疑？？<ul><li><code></code>hadoop fs -appendToFile - /a.txt`</li></ul></li><li>这个追加是在原始块的末尾追加的. 会改变集群上的文件</li><li>如果超过128M才会进行切分,  但这个命令<em>一般不会使用</em></li></ul></li><li><p><strong>查看文件，文件夹数量  count</strong></p><ul><li><code>DIR_COUNT FILE_COUNT CONTENT_SIZE FILE_NAME</code></li><li><p><code>8            3         176.5 K     /tmp</code></p></li><li><p><code>hadoop fs -count -h /tmp</code>:  -h 是友好展示</p></li><li><code>hdfs dfs -count -h /tmp</code>:  与上面效果一样</li><li><code>hdfs dfs -count -q -h /tmp</code>:  查看文件配额， 具体看 help</li></ul></li><li><p><strong><code>du</code>：</strong> <strong>展示文件大小</strong>， 如果参数是文件夹， 则展示文件夹下文件的大小</p><ul><li><code>hadoop fs -du -h  /tmp</code></li><li><code>hadoop fs -du -s -h  /tmp</code>: s 应该是  sum 的意思， 展示所有文件大小的总和</li></ul></li><li><p><strong>展示文件最后1kb内容</strong><code>-tail</code></p><ul><li><p>Show the last 1KB of the file.</p></li><li><p><code></code> hadoop fs -tail /dd.txt`</p></li><li><code>-f  Shows appended data as the file grows.</code></li><li>应用场景： <strong>监控日志</strong></li></ul></li><li><p><strong>修改文件权限 chmod</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1. 直接使用十进制数字修改 </span></span><br><span class="line">[ap@cs2]~/<span class="built_in">test</span>% hadoop fs -ls /</span><br><span class="line">drwxr-xr-x   - ap supergroup          0 2018-06-01 08:55 /aa</span><br><span class="line"><span class="comment"># -R：  /aa 目录下所有的文件递归修改权限</span></span><br><span class="line">[ap@cs2]~/<span class="built_in">test</span>% hadoop fs -chmod -R 777 /aa</span><br><span class="line">[ap@cs2]~/<span class="built_in">test</span>% hadoop fs -ls /</span><br><span class="line">drwxrwxrwx   - ap supergroup          0 2018-06-01 08:55 /aa</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. 针对用户组修改，注意，修改2个不同组权限， 用，隔开</span></span><br><span class="line">hadoop fs -chmod u+x,g+x /a.txt </span><br><span class="line"></span><br><span class="line"><span class="comment"># 3. 最常用的文件权限， 是  644(-rw-r--r--) 和 755(-rwxr-xr-x) </span></span><br><span class="line">文件创建默认就是644</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4. u+x 与 +x 的区别</span></span><br><span class="line">前者指定加在哪组用户上，  后者是所有组都加</span><br></pre></td></tr></table></figure></li><li><p><strong>修改用户权限 chown</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -chown -R 用户名:组名  hdfs目录/文件</span><br></pre></td></tr></table></figure></li></ol><hr><h4 id="2-hdfs-dfsadmin命令"><a href="#2-hdfs-dfsadmin命令" class="headerlink" title="2. hdfs dfsadmin命令"></a>2. <strong><code>hdfs dfsadmin</code>命令</strong></h4><p> 管理员对当前节点的一些操作</p><ul><li><strong><code>hdfs dfsadmin -report</code>  报告当前的一些状态</strong><ul><li>-live  活跃的   </li><li>-dead  死的</li><li>-decommissioning  退役的</li></ul></li><li>**<code>hdfs dfsadmin -safemode</code> 安全模式<ul><li>系统刚启动的时候， 会有30秒的安全模式开启状态， 过了30秒就关了</li><li>enter 进入</li><li>leave 离开</li><li>get  查看</li></ul></li><li><strong><code>hdfs dfsadmin</code> 设置配额</strong><ul><li><code>-setQuota</code> ： 配额是限定的文件&amp;文件夹的数量<ul><li>A quota of 1 would force the directory to remain empty.</li><li>空文件本身算一个文件</li><li><code>bin/hdfs dfsadmin -setQuota 10 lisi</code></li></ul></li><li><code>-clrQuota</code></li><li><code>-setSpaceQuota</code>： 空间配额限定的是大小<ul><li><code>bin/hdfs dfsadmin -setSpaceQuota 4k /lisi/</code></li></ul></li><li><code>-clrSpaceQuota</code></li><li><code>hdfs dfs -count -q -h /user</code>:  加上 -q 是查看配额</li></ul></li></ul><hr><h4 id="3-httpFS访问"><a href="#3-httpFS访问" class="headerlink" title="3.  httpFS访问"></a>3.  httpFS访问</h4><p>使用 REST 的形式， 可以在浏览器上直接访问集群， 可以在非 Linux 平台访问</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"># 编辑文件httpfs-env.sh</span><br><span class="line"># 打开此句注释, 使用内嵌的 tomcat</span><br><span class="line">export HTTPFS_HTTP_PORT=14000</span><br><span class="line"></span><br><span class="line"># 编辑文件core-site.xml</span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.proxyuser.root.hosts<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>*<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.proxyuser.root.groups<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>*<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">编辑文件hdfs-site.xml</span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.webhdfs.enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">           <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">重新启动namenode，执行 sbin/httpfs.sh start</span><br><span class="line"># 执行命令</span><br><span class="line">curl -i "http://cs1:14000/webhdfs/v1?user.name=root&amp;op=LISTSTATUS"</span><br></pre></td></tr></table></figure><p><a href="http://hadoop.apache.org/docs/r2.6.0/hadoop-project-dist/hadoop-hdfs/WebHDFS.html" target="_blank" rel="noopener">更多命令参考</a></p><hr><p><strong>相关知识点</strong></p><ul><li><p>这些命令<strong>在集群中的任何节点都可以做</strong>, hdfs文件系统中, 看到的目录结构只是一个抽象目录, 实际存储在集群中的节点上</p><ul><li>aa.txt ,  大小150M,   <code>hadoop fs -put aa.txt /</code></li><li>会在根目录下看到 /aa.txt,  但是 aa.txt 真实存储的时候, 会先进行分块, 分2块, 进行存储, 假设集群中5个存储节点,  这2个块存储在哪个节点,  由namenode进行分配</li><li>图形界面点进去, 可以看到存储的块</li></ul></li><li><p><strong>Linux的权限管理命令</strong>: </p><ol><li>修改 文件/文件夹 权限的 <code>chmod</code>: <ol><li>可读: r ,  =4        </li><li>可写: w,  =2</li><li>可执行: x,  =1<ol><li>最大权限是7</li><li>-rw-rw-r–</li><li>文件属性 d:目录  -:文件  l:链接</li><li>第一组: 本用户,  第二组: 本组用户,  第三组: 其它用户</li></ol></li></ol></li></ol><ul><li>chmod  711 </li><li>改一个文件夹下所有文件权限为711 <code>chmod -R 711 目录</code></li></ul><ol><li>修改文件所属用户和组 <code>chown</code><ul><li><code>chown -R root:root  ss/</code>把ss的文件夹全部改成root用户和root组</li></ul></li></ol></li></ul><hr><h3 id="5、Eclipse查看Hadoop文件信息"><a href="#5、Eclipse查看Hadoop文件信息" class="headerlink" title="5、Eclipse查看Hadoop文件信息"></a>5、Eclipse查看Hadoop文件信息</h3><p><a href="https://app.yinxiang.com/shard/s37/nl/7399077/9f4966ae-da19-48aa-960b-0a6081ab7ff2/" target="_blank" rel="noopener">详情可以查看</a></p><p><a href="https://app.yinxiang.com/shard/s37/nl/7399077/2668e8e5-f7a1-48e3-a5d5-a7fcf9076c1f/" target="_blank" rel="noopener">其中可能遇到的bug，参见</a></p><p>其中， Eclipse端无法直接删除文件的问题，似乎可以通过在<code>hdfs-site.xml</code> 中修改访问权限来实现， <strong>还未尝试</strong></p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.permissions<span class="tag">&lt;/<span class="name">name</span>&gt;</span> </span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span> </span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure><hr><h3 id="6-通过-Java-API的方式操作-HDFS"><a href="#6-通过-Java-API的方式操作-HDFS" class="headerlink" title="6. 通过 Java API的方式操作 HDFS"></a>6. 通过 Java API的方式操作 HDFS</h3>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Hadoop的核心组件-之-HDFS&quot;&gt;&lt;a href=&quot;#Hadoop的核心组件-之-HDFS&quot; class=&quot;headerlink&quot; title=&quot;Hadoop的核心组件 之 HDFS&quot;&gt;&lt;/a&gt;Hadoop的核心组件 之 HDFS&lt;/h1&gt;&lt;h2 id=&quot;H
      
    
    </summary>
    
      <category term="Hadoop" scheme="https://airpoet.github.io/categories/Hadoop/"/>
    
      <category term="学习笔记" scheme="https://airpoet.github.io/categories/Hadoop/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="原创" scheme="https://airpoet.github.io/tags/%E5%8E%9F%E5%88%9B/"/>
    
      <category term="技术" scheme="https://airpoet.github.io/tags/%E6%8A%80%E6%9C%AF/"/>
    
      <category term="Hadoop" scheme="https://airpoet.github.io/tags/Hadoop/"/>
    
      <category term="HDFS" scheme="https://airpoet.github.io/tags/HDFS/"/>
    
  </entry>
  
  <entry>
    <title>HashMap的实现原理</title>
    <link href="https://airpoet.github.io/2018/06/02/Java/HashMap%E7%9A%84%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/"/>
    <id>https://airpoet.github.io/2018/06/02/Java/HashMap的实现原理/</id>
    <published>2018-06-02T02:25:19.841Z</published>
    <updated>2018-06-02T03:22:52.059Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-什么是HashMap"><a href="#1-什么是HashMap" class="headerlink" title="1.什么是HashMap"></a>1.什么是HashMap</h1><p><img src="http://p6i5vzkfk.bkt.clouddn.com/study/2018-06-02-024247.jpg" alt=""></p><p><strong>Hash</strong>: 散列将一个任意的长度通过某种(hash函数)算法转换成一个固定值</p><p><strong>Map</strong>: 地图,  (x,y)存储</p><p>底层就是一个数组结构, 数组中的每一项又是一个链表, 当新建一个HashMap的时候, 就会初始化一个数组</p><p><strong>总结</strong>: 通过 hash 出来值, 然后通过值定位到某个 map, 然后value 存储到这个 map中, <strong>value只不过是 key 的附属.</strong></p><hr><h1 id="2-源码分析"><a href="#2-源码分析" class="headerlink" title="2.源码分析"></a>2.源码分析</h1><h3 id="先给出结论"><a href="#先给出结论" class="headerlink" title="先给出结论"></a>先给出结论</h3><h4 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构:"></a>数据结构:</h4><ul><li>底层是数组</li><li><code>Entry</code> 就是数组中的元素</li><li>每个<code>Map.Entry</code>其实就是一个<code>key-value</code>对,  它持有一个指向下一个元素的引用<code>Entry&lt;K,V&gt; next;</code>, 这就构成了链表</li></ul><h4 id="存取实现"><a href="#存取实现" class="headerlink" title="存取实现:"></a>存取实现:</h4><ul><li><strong>存储<code>put</code></strong> :<ul><li><strong>过程</strong><ul><li>先根据 <code>key</code> 的 <code>hashCode</code> 重新计算 <code>hash</code> 值, 根据 <code>hash</code> 值得到这个元素在数组中的位置(下标)</li><li>如果数组该位置上已经存放有其他元素了,  那么在这个位置上的元素将以链表的形式存放, 新加入的放在链头, 最先加入的放在链尾.  </li><li>如果数组该位置上没有元素, 就直接将该元素放到数组中的该位置上.</li></ul></li><li><strong>注意点</strong><ul><li>当系统决定存储 <code>HashMap</code> 中的 <code>key-value</code> 对时，完全没有考虑 <code>Entry</code> 中的 <code>value</code>，仅仅只是根据 <code>key</code>来计算并决定每个<code>Entry</code>的存储位置。当系统决定了 <code>key</code>的存储位置之后，<code>value</code>随之保存在那里即可。</li><li>对于于任意给定的对象，只要它的 <code>hashCode()</code>返回值相同，那么程序调用 <code>hash(int h)</code>方法所计算得到的<code>hash</code> 码值总是相同的。</li><li>本质上就是<strong>把 <code>hash</code> 值对数组长度取模运算</strong>， 这样一来，<strong>元素的分布相对来说是比较均匀的</strong></li><li>但是系统是用的<strong>位运算</strong>， 方法更巧妙， 消耗更小</li></ul></li></ul></li><li><strong>读取<code>get</code></strong><ul><li><strong>过程</strong><ul><li>首先计算 <code>key</code> 的 <code>hashCode</code>，找到数组中对应位置的某一元素，然后通过<code>key</code> 的 <code>equals</code> 方法在对应位置的链表中找到需要的元素。</li></ul></li></ul></li></ul><h4 id="存储实现总结"><a href="#存储实现总结" class="headerlink" title="存储实现总结:"></a>存储实现总结:</h4><ul><li><p><strong>HashMap</strong> 在底层将 <strong>key-value</strong> 当成一个<u>整体</u>进行处理，这个整体就是一个 <strong>Entry</strong> 对象。</p></li><li><p><strong>HashMap</strong> 底层采用一个 <strong>Entry[]</strong> 数组来保存所有的 <strong>key- value</strong> 对，当需要<strong><em>存储</em></strong>一个 <strong>Entry</strong> 对象时，会根据 <strong>hash</strong> 算法来<u>决定其在数组中的存储位置</u>，在根据 <strong>equals</strong> 方法<u>决定其在该数组位置上的链表中的存储位置</u>；</p></li><li>当需要<strong><em>取出</em></strong>一个 <strong>Entry</strong> 时，也会根据 <strong>hash</strong> 算法<u>找到其在数组中的存储位置</u>，再根据 <strong>equals</strong> 方法<u>从该位置上的链表中取出</u>该 <strong>Entry</strong>。</li></ul><hr><h1 id="3-HashMap-的性能参数"><a href="#3-HashMap-的性能参数" class="headerlink" title="3.  HashMap 的性能参数"></a>3.  HashMap 的性能参数</h1><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 桶表默认容量 16,  必须是 2 的倍数， 便于后面的 位运算</span></span><br><span class="line"><span class="comment"> * 控制hashcode 不超16范围, a.hashcode = xx % 16 (hashcode 取模 桶个数)</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> DEFAULT_INITIAL_CAPACITY = <span class="number">1</span> &lt;&lt; <span class="number">4</span>; <span class="comment">// aka 16</span></span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * MUST be a power of two &lt;= 1&lt;&lt;30.</span></span><br><span class="line"><span class="comment"> * 桶表最大 2^30</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> MAXIMUM_CAPACITY = <span class="number">1</span> &lt;&lt; <span class="number">30</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 扩容因子（负载因子）: 0.75</span></span><br><span class="line"><span class="comment"> * 扩容: 每次2倍</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">float</span> DEFAULT_LOAD_FACTOR = <span class="number">0.75f</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 链表: hash算法值相同的时候, 会把值相同的放在一个链表上, 链表上的元素个数</span></span><br><span class="line"><span class="comment"> * 超过8个时, 链表转化为二叉树, 提升查询效率</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> TREEIFY_THRESHOLD = <span class="number">8</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 小于6个， 又变回链表</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> UNTREEIFY_THRESHOLD = <span class="number">6</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * The smallest table capacity for which bins may be treeified.</span></span><br><span class="line"><span class="comment"> * (Otherwise the table is resized if too many nodes in a bin.)</span></span><br><span class="line"><span class="comment"> * Should be at least 4 * TREEIFY_THRESHOLD to avoid conflicts</span></span><br><span class="line"><span class="comment"> * between resizing and treeification thresholds.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> MIN_TREEIFY_CAPACITY = <span class="number">64</span>;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;1-什么是HashMap&quot;&gt;&lt;a href=&quot;#1-什么是HashMap&quot; class=&quot;headerlink&quot; title=&quot;1.什么是HashMap&quot;&gt;&lt;/a&gt;1.什么是HashMap&lt;/h1&gt;&lt;p&gt;&lt;img src=&quot;http://p6i5vzkfk.bkt
      
    
    </summary>
    
      <category term="Java" scheme="https://airpoet.github.io/categories/Java/"/>
    
      <category term="知识点" scheme="https://airpoet.github.io/categories/Java/%E7%9F%A5%E8%AF%86%E7%82%B9/"/>
    
    
      <category term="原创" scheme="https://airpoet.github.io/tags/%E5%8E%9F%E5%88%9B/"/>
    
      <category term="技术" scheme="https://airpoet.github.io/tags/%E6%8A%80%E6%9C%AF/"/>
    
      <category term="Java" scheme="https://airpoet.github.io/tags/Java/"/>
    
  </entry>
  
  <entry>
    <title>▍无题</title>
    <link href="https://airpoet.github.io/2018/06/02/Poetry/%E6%97%A0%E9%A2%98/"/>
    <id>https://airpoet.github.io/2018/06/02/Poetry/无题/</id>
    <published>2018-06-01T17:10:33.894Z</published>
    <updated>2018-06-09T17:12:12.202Z</updated>
    
    <content type="html"><![CDATA[<blockquote class="blockquote-center"><p><img src="http://p6i5vzkfk.bkt.clouddn.com/study/2018-06-03-501528043523_.pic.jpg" alt=""></p><p><br>在淮海中路看油画，要把天空调弱</p><p>让油菜花暗下去，看眉式清秀之人离开身体</p><p>穿过街巷中涂抹过的人群，悄悄投了水。  </p><p><br>在淮海中路1411号，春光遮蔽了暗疾</p><p>鸟鸣带来逼仄和飞行感，一个人的身体像麻绳</p><p>裸露在新鲜空气中，骨头开裂出花朵。  </p><p><br>眼底的云又白又黑，膝盖的青色愈爱愈深</p><p>穿过死后潭水的寂静，背部长出的鱼鳞</p><p>一年比一年薄，月亮一日比一日旧。  </p><p><br>与春风交换身体，与素不相识之人抱头痛哭</p><p>与我，许下再死一次的诺言，这么多年了</p><p>她说，我爱你依旧，胜过画中人。 </p><p> <br></p><p>作者 / 隐居的事</p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote class=&quot;blockquote-center&quot;&gt;&lt;p&gt;&lt;img src=&quot;http://p6i5vzkfk.bkt.clouddn.com/study/2018-06-03-501528043523_.pic.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;
      
    
    </summary>
    
      <category term="文艺" scheme="https://airpoet.github.io/categories/%E6%96%87%E8%89%BA/"/>
    
      <category term="诗歌" scheme="https://airpoet.github.io/categories/%E6%96%87%E8%89%BA/%E8%AF%97%E6%AD%8C/"/>
    
    
      <category term="诗歌" scheme="https://airpoet.github.io/tags/%E8%AF%97%E6%AD%8C/"/>
    
  </entry>
  
  <entry>
    <title>Hadoop相关书籍</title>
    <link href="https://airpoet.github.io/2018/06/02/Hadoop/Overview/Hadoop%E7%9B%B8%E5%85%B3%E4%B9%A6%E7%B1%8D/"/>
    <id>https://airpoet.github.io/2018/06/02/Hadoop/Overview/Hadoop相关书籍/</id>
    <published>2018-06-01T16:20:33.728Z</published>
    <updated>2018-06-01T16:57:11.289Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Hadoop框架体系相关书籍推荐"><a href="#Hadoop框架体系相关书籍推荐" class="headerlink" title="Hadoop框架体系相关书籍推荐"></a>Hadoop框架体系相关书籍推荐</h1><h2 id="1-Hadoop权威指南-第四版"><a href="#1-Hadoop权威指南-第四版" class="headerlink" title="1. [Hadoop权威指南] 第四版"></a>1. [Hadoop权威指南] 第四版</h2><blockquote><p> <strong>顾名思义, 很权威</strong>  </p></blockquote><p>🐘🐘🐘🐘🐘🐘🐘🐘🐘🐘🐘🐘🐘🐘🐘🐘🐘🐘🐘🐘🐘🐘🐘🐘🐘🐘🐘🐘🐘🐘🐘🐘🐘🐘🐘🐘🐘🐘🐘🐘🐘🐘</p><p><img src="http://p6i5vzkfk.bkt.clouddn.com/study/2018-06-01-162303.jpg" alt=""></p><p>🐘🐘🐘🐘🐘🐘🐘🐘🐘🐘🐘🐘🐘🐘🐘🐘🐘🐘🐘🐘🐘🐘🐘🐘🐘🐘🐘🐘🐘🐘🐘🐘🐘🐘🐘🐘🐘🐘🐘🐘🐘🐘</p><h2 id="2-HBase权威指南"><a href="#2-HBase权威指南" class="headerlink" title="2. [HBase权威指南]"></a>2. [HBase权威指南]</h2><blockquote><p> 祝你🐴到成功</p></blockquote><p>🐴🐴🐴🐴🐴🐴🐴🐴🐴🐴🐴🐴🐴🐴🐴🐴🐴🐴🐴🐴🐴🐴🐴🐴🐴🐴🐴🐴🐴🐴🐴🐴🐴🐴🐴🐴🐴🐴🐴🐴🐴</p><p><img src="http://p6i5vzkfk.bkt.clouddn.com/study/2018-06-01-163622.jpg" alt=""></p><p>🐴🐴🐴🐴🐴🐴🐴🐴🐴🐴🐴🐴🐴🐴🐴🐴🐴🐴🐴🐴🐴🐴🐴🐴🐴🐴🐴🐴🐴🐴🐴🐴🐴🐴🐴🐴🐴🐴🐴🐴🐴</p><h2 id="3-Hive编程指南"><a href="#3-Hive编程指南" class="headerlink" title="3. [Hive编程指南]"></a>3. [Hive编程指南]</h2><blockquote><p>小蜜蜂, 嗡嗡嗡.</p></blockquote><p>🐝🐝🐝🐝🐝🐝🐝🐝🐝🐝🐝🐝🐝🐝🐝🐝🐝🐝🐝🐝🐝🐝🐝🐝🐝🐝🐝🐝🐝🐝🐝🐝🐝🐝🐝🐝🐝🐝🐝🐝🐝</p><p><img src="http://p6i5vzkfk.bkt.clouddn.com/study/2018-06-01-163954.jpg" alt=""></p><p>🐝🐝🐝🐝🐝🐝🐝🐝🐝🐝🐝🐝🐝🐝🐝🐝🐝🐝🐝🐝🐝🐝🐝🐝🐝🐝🐝🐝🐝🐝🐝🐝🐝🐝🐝🐝🐝🐝🐝🐝🐝</p><h2 id="4-zookeeper分布式过程协同技术详解"><a href="#4-zookeeper分布式过程协同技术详解" class="headerlink" title="4. [zookeeper分布式过程协同技术详解]"></a>4. [zookeeper分布式过程协同技术详解]</h2><blockquote><p>这是个啥动物?? 🐱??</p></blockquote><p>🐱🐱🐱🐱🐱🐱🐱🐱🐱🐱🐱🐱🐱🐱🐱🐱🐱🐱🐱🐱🐱🐱🐱🐱🐱🐱🐱🐱🐱🐱🐱🐱🐱🐱🐱🐱🐱🐱🐱🐱🐱</p><p><img src="http://p6i5vzkfk.bkt.clouddn.com/study/2018-06-01-164208.jpg" alt=""></p><p>🐱🐱🐱🐱🐱🐱🐱🐱🐱🐱🐱🐱🐱🐱🐱🐱🐱🐱🐱🐱🐱🐱🐱🐱🐱🐱🐱🐱🐱🐱🐱🐱🐱🐱🐱🐱🐱🐱🐱🐱🐱</p><hr><h1 id="以上书籍下载地址"><a href="#以上书籍下载地址" class="headerlink" title="以上书籍下载地址"></a>以上书籍下载地址</h1><h5 id="有效期至-2018年06月08日"><a href="#有效期至-2018年06月08日" class="headerlink" title="有效期至 2018年06月08日"></a><strong>有效期至 2018年06月08日</strong></h5><p><a href="https://pan.baidu.com/s/1s8YK-Xbjpd738inPLSczRA" target="_blank" rel="noopener">百度网盘下载</a> </p><p>密码:  <code>tm0c</code></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Hadoop框架体系相关书籍推荐&quot;&gt;&lt;a href=&quot;#Hadoop框架体系相关书籍推荐&quot; class=&quot;headerlink&quot; title=&quot;Hadoop框架体系相关书籍推荐&quot;&gt;&lt;/a&gt;Hadoop框架体系相关书籍推荐&lt;/h1&gt;&lt;h2 id=&quot;1-Hadoop权
      
    
    </summary>
    
      <category term="Hadoop" scheme="https://airpoet.github.io/categories/Hadoop/"/>
    
      <category term="学习资源" scheme="https://airpoet.github.io/categories/Hadoop/%E5%AD%A6%E4%B9%A0%E8%B5%84%E6%BA%90/"/>
    
    
      <category term="原创" scheme="https://airpoet.github.io/tags/%E5%8E%9F%E5%88%9B/"/>
    
      <category term="技术" scheme="https://airpoet.github.io/tags/%E6%8A%80%E6%9C%AF/"/>
    
      <category term="Hadoop" scheme="https://airpoet.github.io/tags/Hadoop/"/>
    
      <category term="书籍" scheme="https://airpoet.github.io/tags/%E4%B9%A6%E7%B1%8D/"/>
    
  </entry>
  
  <entry>
    <title>Hadoop学习笔记-1 简介&amp;安装</title>
    <link href="https://airpoet.github.io/2018/05/31/Hadoop/Study/Hadoop%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-1-%E7%AE%80%E4%BB%8B&amp;%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"/>
    <id>https://airpoet.github.io/2018/05/31/Hadoop/Study/Hadoop学习笔记-1-简介&amp;环境搭建/</id>
    <published>2018-05-31T02:08:21.006Z</published>
    <updated>2018-06-09T01:53:11.658Z</updated>
    
    <content type="html"><![CDATA[<h1 id="引入"><a href="#引入" class="headerlink" title="引入"></a>引入</h1><h3 id="面试题"><a href="#面试题" class="headerlink" title="面试题"></a>面试题</h3><h4 id="1-有一个很大的-4T-的文件-文件中存储的是ip-每行存储一个-要求求出出现此处最多的那个ip"><a href="#1-有一个很大的-4T-的文件-文件中存储的是ip-每行存储一个-要求求出出现此处最多的那个ip" class="headerlink" title="1. 有一个很大的(4T)的文件,  文件中存储的是ip, 每行存储一个, 要求求出出现此处最多的那个ip"></a>1. 有一个很大的(4T)的文件,  文件中存储的是ip, 每行存储一个, 要求求出出现此处最多的那个ip</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">如果这个文件是小文件：</span><br><span class="line">io流+集合</span><br><span class="line">实现思路：</span><br><span class="line">创建一个流进行文件读取</span><br><span class="line">读取出来的数据存储到map集合中  key：ip    value:次数</span><br><span class="line">统计逻辑：</span><br><span class="line">判断读取的ip是否已经存在在map中</span><br><span class="line">存在：取出value+<span class="number">1</span></span><br><span class="line">不存在：将ip作为key   <span class="number">1</span>作为value</span><br><span class="line">怎么求ip出现次数最多的</span><br><span class="line">遍历map    遍历key，取出value找出最大值  value最大的key就是要找的ip</span><br><span class="line">我的文件足够大：大到一台机器装不下     </span><br><span class="line">数组   集合  变量------&gt;基于内存的</span><br><span class="line">怎么办？？？？？</span><br><span class="line">服务器的<span class="number">2</span>T</span><br><span class="line"><span class="number">1</span>.在最早的时候我们的思维模式就是纵向扩展，增加单个节点的性能    <span class="number">8</span>T</span><br><span class="line">摩尔定律：硬件性能<span class="number">18</span>-<span class="number">24</span>个月会提升一倍</span><br><span class="line"><span class="number">4</span>T------<span class="number">2</span>h</span><br><span class="line"><span class="number">4</span>T------<span class="number">1</span>h    前提是数据量不发生改变</span><br><span class="line">但是往往数据量的变化速度远远大于服务器性能的提升速度</span><br><span class="line">经过<span class="number">18</span>个月</span><br><span class="line">服务器性能提升了一倍</span><br><span class="line">数据量------提升了<span class="number">10</span>倍</span><br><span class="line"><span class="number">4</span>T------<span class="number">2</span>h</span><br><span class="line"><span class="number">40</span>t-----<span class="number">20</span>h   目前只需要<span class="number">10</span>h</span><br><span class="line">纵向扩展不可行？</span><br><span class="line">横向扩展：如果一台机器处理不了数据   使用多台机器</span><br><span class="line"><span class="number">4</span>T------<span class="number">2</span>h</span><br><span class="line"><span class="number">4</span>t----<span class="number">4</span>个机器----<span class="number">0.5</span>小时</span><br><span class="line">分而治之的思想：</span><br><span class="line">一个机器计算性能有限  这个时候可以使用多台机器共同计算  每台机器承担一部分计算量</span><br><span class="line">最终实现：</span><br><span class="line"><span class="number">1</span>.先将这个足够大的文件进行切分  切分成了多个小文件</span><br><span class="line"><span class="number">2</span>.将多个小文件分发给多个机器进行统计每个ip出现的次数   每个求出出现次数最多的ip</span><br><span class="line"><span class="number">3</span>.合并求出最终的最大值</span><br></pre></td></tr></table></figure><hr><h4 id="2-有两个很大的文件-两个文件中存储的都是url-求出两个文件中相同的url"><a href="#2-有两个很大的文件-两个文件中存储的都是url-求出两个文件中相同的url" class="headerlink" title="2. 有两个很大的文件, 两个文件中存储的都是url,  求出两个文件中相同的url"></a>2. 有两个很大的文件, 两个文件中存储的都是url,  求出两个文件中相同的url</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">如果文件是小文件：</span><br><span class="line">io流+集合（set）</span><br><span class="line">实现逻辑：</span><br><span class="line"><span class="number">1</span>.先创建两个文件读取流，用来读取两个文件</span><br><span class="line"><span class="number">2</span>.创建两个集合set1    set2</span><br><span class="line"><span class="number">3</span>.进行文件读取并分别set1   set2中</span><br><span class="line"><span class="number">4</span>.循环遍历其中一个set1，判断set1中取出的每个url是否在set2中  set2.contains(url)</span><br><span class="line">大文件的时候怎么办？</span><br><span class="line">我们也采用分而治之的思想：将两个大文件都进行切分，每个大文件都切成多个小文件</span><br><span class="line">一个大任务=<span class="number">4</span>*<span class="number">4</span>个小任务</span><br><span class="line">这样虽然可以达到目的但是效率太低？怎么办？</span><br><span class="line">排序，切分（规则同一）   最终将任务减少到<span class="number">4</span>个</span><br><span class="line">但是大文件排序仍然是一个非常消耗性能的事情，如果不需要排序就可做到这个效果尽量不要排序</span><br><span class="line">怎么办？</span><br><span class="line">hash算法的目的----》给每一个对象生成一个“唯一”的hash值<span class="number">0</span>-Integer_MAX</span><br><span class="line">是否可以运用hash算法解决这个问题</span><br><span class="line">url.hashCode()%分段的个数   两个文件分段规则一定相同吗？</span><br><span class="line">url.hashCode()肯定一样</span><br><span class="line">分段个数一定相同吗？可以不一样  如果不一样的话  必须成倍数关系</span><br><span class="line">最终的解决方案：</span><br><span class="line">分而治之+分段规则</span><br><span class="line">分段：分区</span><br></pre></td></tr></table></figure><hr><h4 id="3-有一个很小的文件-存储的都是url-每行一个-怎样快速判断给定的一个url是否在这个文件中"><a href="#3-有一个很小的文件-存储的都是url-每行一个-怎样快速判断给定的一个url是否在这个文件中" class="headerlink" title="3. 有一个很小的文件, 存储的都是url, 每行一个, 怎样快速判断给定的一个url是否在这个文件中"></a>3. 有一个很小的文件, 存储的都是url, 每行一个, 怎样快速判断给定的一个url是否在这个文件中</h4><p><strong>小文件</strong>:  IO + 集合(set)</p><ol><li>创建io 和 集合</li><li>进行文件读取放在 set集合中</li><li>set.contains(url) ==&gt;  true:存在,  false: 不存在</li></ol><p><strong>大文件:</strong>  </p><p>思路1:  用hashCode() 进行分区, 然后用要查找的 url 取模定位 </p><ul><li>但是这样定位到了还是要一个个找</li></ul><p><strong>思路2:</strong> </p><ul><li>数组的查询性能比较高, 数组可以通过下标</li><li><p><strong>基数排序</strong></p><ol><li>数组的索引代表的是数据的原始值, 数组中存储的值, 是原始值出现的次数</li><li>放到对应下标的位置,  值只存出现的次数</li><li>如果数组中对应的下表存储的值为0, 代表此下标的值没有出现过, 就不需要输出</li><li><strong>缺点:</strong> <ul><li>数据范围过大时, 数组长度不好创建</li><li>数组的类型不好确定</li><li>如果数据比较分散时, 会造成资源浪费</li></ul></li><li><u>练习: 写一个基数排序, 随机生成的20个数, 运用基数排序排序</u></li></ol></li></ul><ul><li><p>对于本题</p><ul><li>不需要统计次数, 存在标记为1, 不存在就是0</li><li>所以存的时候最好用boolean存,  用位数组 <code>bit[]</code></li><li>可以设计多个hash算法, 用来校验某一种hashCode相同的情况</li><li><strong>影响误判率3要素</strong>: hash算法个数 k - 数据量n - 数组长度 m</li><li><strong>布隆过滤器 </strong>公式: k = 0.7*(m/n), 此时的误判率最小</li></ul></li></ul><hr><h1 id="大数据基本介绍"><a href="#大数据基本介绍" class="headerlink" title="大数据基本介绍"></a>大数据基本介绍</h1><h3 id="数据"><a href="#数据" class="headerlink" title="数据"></a>数据</h3><ul><li>数据就是数值，也就是我们通过观察、实验或计算得出的结果。数据有很多种，最简单的就是数字。</li><li>数据也可以是文字、图像、声音等。数据可以用于科学研究、设计、查证等。</li></ul><h3 id="结构划分"><a href="#结构划分" class="headerlink" title="结构划分:"></a>结构划分:</h3><ul><li>结构化<ul><li>半结构化</li><li>非结构化</li></ul></li></ul><h3 id="大数据特点-4V"><a href="#大数据特点-4V" class="headerlink" title="大数据特点:  4V"></a>大数据特点:  4V</h3><ol><li><h5 id="数据量大"><a href="#数据量大" class="headerlink" title="数据量大"></a>数据量大</h5><blockquote><p>1 Byte =8 bit<br>1 KB = 1,024 Bytes = 8192 bit<br>1 MB = 1,024 KB = 1,048,576 Bytes<br>1 GB = 1,024 MB = 1,048,576 KB<br>1 TB = 1,024 GB = 1,048,576 MB   （普通用户数据级别）<br>1 PB = 1,024 TB = 1,048,576 GB（企业级数据级别）<br>1 EB = 1,024 PB = 1,048,576 TB<br>1 ZB = 1,024 EB = 1,048,576 PB（全球数据总量级别）</p></blockquote></li><li><p>数据增长速度快</p></li><li><p>数据种类多</p><ul><li>文字 图片  音频 视频..</li></ul></li><li>数据的价值密度低  整体价值高</li></ol><h3 id="数据来源"><a href="#数据来源" class="headerlink" title="数据来源"></a>数据来源</h3><ol><li>公司中的自己的业务数据  淘宝  京东</li><li>第三方</li><li>爬虫  爬数据</li></ol><h3 id="数据处理"><a href="#数据处理" class="headerlink" title="数据处理"></a>数据处理</h3><ol><li>缺失数据的处理<ul><li>考虑缺失数据是否影响整体的业务逻辑  不影响 删除</li><li>如果是和钱相关的数据    —-慎重   不能轻易删除  </li></ul></li><li>敏感数据<ul><li>脱敏处理 – 加密</li></ul></li></ol><h3 id="数据价值"><a href="#数据价值" class="headerlink" title="数据价值"></a>数据价值</h3><ul><li>人物画像<ul><li>根据根据用户数据给用户做一个全方位的分析画像   属性：  人脉  消费水平   性格特点<ul><li>….</li></ul></li></ul></li></ul><hr><h1 id="几个概念"><a href="#几个概念" class="headerlink" title="几个概念"></a>几个概念</h1><h3 id="集群"><a href="#集群" class="headerlink" title="集群:"></a>集群:</h3><ul><li>多个机器共同协作完成同一个任务, 每一个机器叫做节点,  多个机器共同组成的群体叫做集群</li><li>集群中的每个节点之间通过局域网或其他方式通讯</li></ul><h3 id="分布式"><a href="#分布式" class="headerlink" title="分布式:"></a>分布式:</h3><ul><li>分而治之 ,  一个任务呗分成多个子任务模块, 每个任务跑在不同的节点上</li><li>原来一个人干的事情, 现在大家分工劳动</li><li>分布式的文件系统 ,  分布式数据库,  分布式计算系统</li></ul><h3 id="负载均衡-Nginx"><a href="#负载均衡-Nginx" class="headerlink" title="负载均衡: Nginx"></a>负载均衡: Nginx</h3><ul><li>每个节点分配到的任务基本均衡</li><li>负载均衡是跟每个节点自身的配置等匹配的</li><li>不存在绝对的均衡</li></ul><hr><h1 id="Hadoop"><a href="#Hadoop" class="headerlink" title="Hadoop"></a>Hadoop</h1><h3 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h3><ul><li>一个分布式的开源框架</li><li>支持成千上万的节点, 每个节点依靠本地的计算和存储</li><li>在应用层面提供高可用性</li><li>将硬件错误看成一个常态</li></ul><h3 id="Hadoop的模块"><a href="#Hadoop的模块" class="headerlink" title="Hadoop的模块"></a>Hadoop的模块</h3><ul><li><strong>Common</strong> <ul><li>支持其他 Hadoop 模块的公共实用程序</li><li>封装: 工具类, RPC框架</li></ul></li><li><strong>HDFS</strong><ul><li>Hadoop的分布式文件系统, 负责海量数据的存储</li><li>将文件切分成指定大小的数据块并以多副本的存储形式存储在多个机器上</li><li>数据切分, 多副本, 容错等操作对用户是透明的</li><li><strong>架构</strong>: 主从架构 ( Java进程)<ul><li>主: namenode  一个</li><li>从: datenode   多个</li><li>助理: SecondaryNamenode 分担主进程的压力</li></ul></li></ul></li><li><strong>YARN</strong><ul><li>集群的资源调度框架,  负责集群的资源管理</li><li>架构: 主从架构<ul><li>主: ResourceManager  – 负责统筹资源</li><li>从: NodeManager</li></ul></li></ul></li><li><strong>MapReduce</strong><ul><li>分布式计算框架,  有计算任务的时候才会有响应的进程</li></ul></li></ul><h3 id="Hadoop的搭建"><a href="#Hadoop的搭建" class="headerlink" title="Hadoop的搭建"></a>Hadoop的搭建</h3><h4 id="搭建前的准备"><a href="#搭建前的准备" class="headerlink" title="搭建前的准备"></a>搭建前的准备</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line">搭建准备：</span><br><span class="line">1）ip配置</span><br><span class="line"></span><br><span class="line">2）主机名   vi /etc/sysconfig/network</span><br><span class="line"></span><br><span class="line">3）主机映射</span><br><span class="line"></span><br><span class="line">4）关闭防火墙和sellinux</span><br><span class="line">    service iptables stop</span><br><span class="line">    vi /etc/selinux/config</span><br><span class="line">    SELINUX=disabled</span><br><span class="line"></span><br><span class="line">5）将系统的启动级别改为3</span><br><span class="line">vi /etc/inittab</span><br><span class="line"></span><br><span class="line">6）创建普通用户，并为普通用户添加sudolers权限</span><br><span class="line">    创建用户：useradd 用户名</span><br><span class="line">    passwd 用户名</span><br><span class="line">    vi /etc/sudoers</span><br><span class="line">    hadoop  ALL=(ALL)       ALL</span><br><span class="line"></span><br><span class="line">7）配置免密登录</span><br><span class="line">   先切换到普通用户</span><br><span class="line">   1）生成秘钥</span><br><span class="line">   ssh-keygen</span><br><span class="line">   2)发送秘钥</span><br><span class="line">   ssh-copy-id hadoop(主机名)</span><br><span class="line">   验证：ssh hadoop</span><br><span class="line">   </span><br><span class="line">8）安装jdk</span><br><span class="line">    卸载jdk：</span><br><span class="line">    rpm -qa|grep jdk</span><br><span class="line">    rpm -e java-1.7.0-openjdk-1.7.0.99-2.6.5.1.el6.x86_64 --nodeps</span><br><span class="line"></span><br><span class="line">9）时间同步   伪分布式不需要   分布式需要，必须做</span><br><span class="line"></span><br><span class="line">10)选择安装版本：</span><br><span class="line">    不选太陈旧的版本也不选最新的版本</span><br><span class="line">    2.7.6</span><br><span class="line">    </span><br><span class="line">11)安装</span><br><span class="line">    一定切换用户    普通用户</span><br></pre></td></tr></table></figure><h4 id="方式1-伪分布式"><a href="#方式1-伪分布式" class="headerlink" title="方式1:  伪分布式"></a>方式1:  伪分布式</h4><p><strong>所有进程全部运行在同一个节点上</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line">1）上传</span><br><span class="line">2）解压</span><br><span class="line">3）修改配置文件</span><br><span class="line">配置文件的目录：HADOOP_HOME/etc/hadoop</span><br><span class="line">    需要修改6个配置文件：</span><br><span class="line">    1）hadoop-env.sh</span><br><span class="line">    <span class="built_in">export</span> JAVA_HOME=/home/hadoop/jdk1.8.0_73/</span><br><span class="line">    </span><br><span class="line">    2)core-site.xml</span><br><span class="line">    核心配置文件</span><br><span class="line">        &lt;property&gt;</span><br><span class="line">        &lt;name&gt;fs.defaultFS&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;hdfs://hadoop:9000&lt;/value&gt;</span><br><span class="line">        &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">    3)hdfs-site.xml</span><br><span class="line">        &lt;property&gt;</span><br><span class="line">        &lt;name&gt;dfs.replication&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;1&lt;/value&gt;</span><br><span class="line">        &lt;/property&gt;</span><br><span class="line">        </span><br><span class="line">     4)yarn-site.xml</span><br><span class="line">        &lt;property&gt;</span><br><span class="line">        &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;mapreduce_shuffle&lt;/value&gt;</span><br><span class="line">        &lt;/property&gt;</span><br><span class="line">     </span><br><span class="line">     5)mapred-site.xml</span><br><span class="line">     &lt;property&gt;</span><br><span class="line">         &lt;name&gt;mapreduce.framework.name&lt;/name&gt;</span><br><span class="line">       &lt;value&gt;yarn&lt;/value&gt;</span><br><span class="line">        &lt;/property&gt;</span><br><span class="line">   </span><br><span class="line">                                      </span><br><span class="line"> 6)slaves   配置的是从节点的信息</span><br><span class="line"> </span><br><span class="line"> 7)配置环境变量</span><br><span class="line"> <span class="built_in">export</span> JAVA_HOME=/home/hadoop/jdk1.8.0_73</span><br><span class="line"><span class="built_in">export</span> HADOOP_HOME=/home/hadoop/hadoop-2.7.6</span><br><span class="line"><span class="built_in">export</span>  PATH=<span class="variable">$PATH</span>:<span class="variable">$JAVA_HOME</span>/bin:<span class="variable">$HADOOP_HOME</span>/bin:<span class="variable">$HADOOP_HOME</span>/sbin</span><br><span class="line"><span class="built_in">source</span> /etc/rpofile</span><br><span class="line">验证  hadoop  version</span><br><span class="line"></span><br><span class="line">8)先进行格式化</span><br><span class="line">hadoop namenode -format</span><br><span class="line">9)启动</span><br><span class="line">        start-all.sh</span><br><span class="line">        不建议   建议以下命令：</span><br><span class="line">        start-dfs.sh</span><br><span class="line">        start-yarn.sh</span><br><span class="line"></span><br><span class="line">10）验证</span><br><span class="line">        jps   6个进程</span><br><span class="line">        3909 Jps</span><br><span class="line">        3736 ResourceManager</span><br><span class="line">        3401 DataNode</span><br><span class="line">        3306 NameNode</span><br><span class="line">        3836 NodeManager</span><br><span class="line">        3597 SecondaryNameNode</span><br><span class="line"></span><br><span class="line">页面：</span><br><span class="line">        hdfs：namenode的ip：50070</span><br><span class="line">        yarn:resourcemanager的ip：8088</span><br></pre></td></tr></table></figure><hr><h4 id="方式2-完全分布式"><a href="#方式2-完全分布式" class="headerlink" title="方式2:  完全分布式"></a>方式2:  完全分布式</h4><p><a href="https://app.yinxiang.com/shard/s37/nl/7399077/c3f4c3b9-249e-42cf-87e4-fb5db3bb37e2/" target="_blank" rel="noopener">参考文档</a></p><p><strong>各个节点的安装的普通用户名必须相同  密码也得相同, 每个节点都需要操作</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><span class="line">搭建准备：</span><br><span class="line"><span class="number">1</span>）ip配置</span><br><span class="line"><span class="number">2</span>）主机名   vi /etc/sysconfig/network</span><br><span class="line"><span class="number">3</span>）主机映射</span><br><span class="line"><span class="number">4</span>）关闭防火墙和sellinux</span><br><span class="line">service iptables stop</span><br><span class="line">vi /etc/selinux/config</span><br><span class="line">SELINUX=disabled</span><br><span class="line"><span class="number">5</span>）将系统的启动级别改为<span class="number">3</span></span><br><span class="line"></span><br><span class="line"><span class="number">6</span>）创建普通用户，并为普通用户添加sudolers权限</span><br><span class="line">创建用户：useradd 用户名</span><br><span class="line"> passwd 用户名</span><br><span class="line"> vi /etc/sudoers</span><br><span class="line"> hadoop  ALL=(ALL)       ALL</span><br><span class="line"><span class="number">7</span>）配置免密登录</span><br><span class="line">先切换到普通用户</span><br><span class="line">每台机器都需要执行下面的操作</span><br><span class="line">各个节点之间都做一下</span><br><span class="line">    a. 生成秘钥 ssh-keygen</span><br><span class="line">    b. 发送秘钥  ssh-copy-<span class="function">id <span class="title">hadoop</span><span class="params">(主机名)</span></span></span><br><span class="line"><span class="function">c. 验证：各个节点之间都需要做相互验证</span></span><br><span class="line"><span class="function">ssh hadoop01</span></span><br><span class="line"><span class="function">ssh hadoop02</span></span><br><span class="line"><span class="function">ssh hadoop03</span></span><br><span class="line"><span class="function">8）安装jdk</span></span><br><span class="line"><span class="function">卸载jdk：</span></span><br><span class="line"><span class="function">rpm -qa|grep jdk</span></span><br><span class="line"><span class="function">rpm -e java-1.7.0-openjdk-1.7.0.99-2.6.5.1.el6.x86_64 --nodeps</span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function">9）时间同步   伪分布式不需要   分布式需要，必须做</span></span><br><span class="line"><span class="function">1)不能联网的时候    手动指定   date -s 时间  或者手动搭建一个时间服务器</span></span><br><span class="line"><span class="function">2）能联网的时候    找一个公网中的公用的时间服务器  所有节点的时间和公网中的时间服务器保持一致</span></span><br><span class="line"><span class="function">ntpdate 公网的时间服务器地址</span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function">完全分布式必须要做  每个节点都需要执行</span></span><br><span class="line"><span class="function">10) 选择安装版本：</span></span><br><span class="line"><span class="function">不选太陈旧的版本也不选最新的版本</span></span><br><span class="line"><span class="function">2.7.6</span></span><br><span class="line"><span class="function">11) 安装</span></span><br><span class="line"><span class="function">一定切换用户    普通用户</span></span><br><span class="line"><span class="function">先在一个节点上执行所有的修改  在远程发送到其他节点</span></span><br><span class="line"><span class="function">                1）上传</span></span><br><span class="line"><span class="function">                2）解压d</span></span><br><span class="line"><span class="function">                3）配置环境变量</span></span><br><span class="line"><span class="function">                4）修改配置文件</span></span><br><span class="line"><span class="function">                    6个配置文件</span></span><br><span class="line"><span class="function">                    集群规划</span></span><br><span class="line"><span class="function">                    ....</span></span><br><span class="line"><span class="function">                    ....</span></span><br><span class="line"><span class="function">                    </span></span><br><span class="line"><span class="function">                5)远程发送</span></span><br><span class="line"><span class="function">                scp -r hadoop-2.7.6 hadoop02:$PWD</span></span><br><span class="line"><span class="function">                scp -r hadoop-2.7.6 hadoop03:$PWD</span></span><br><span class="line"><span class="function">                </span></span><br><span class="line"><span class="function">                scp -r /home/ap/apps/hadoop-2.7.6/etc/hadoop ap@cs1:/home/ap/apps/hadoop-2.7.6/etc</span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function">                远程发送/etc/pofile</span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function">                执行source /etc/pofile</span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function">                6）进行格式化     必须在namenode的节点（hdfs的主节点）</span></span><br><span class="line"><span class="function">                hadoop namenode -format</span></span><br><span class="line"><span class="function">            不配置目录默认/tmp  临时目录   可以随时回收的</span></span><br><span class="line"><span class="function">                7)启动</span></span><br><span class="line"><span class="function">                启动hdfs    start-dfs.sh  在任意节点都可以</span></span><br><span class="line"><span class="function">                启动yarn     start-yarn.sh   在yarn的主节点执行</span></span><br><span class="line"><span class="function">                jps命令查看</span></span><br><span class="line"><span class="function">                网页：</span></span><br><span class="line"><span class="function">                hdfs:     hadoop01:50070</span></span><br><span class="line"><span class="function">                yarn      hadoop03:8088</span></span><br><span class="line"><span class="function">                    </span></span><br><span class="line"><span class="function">                8) 去掉警告（在/etc/profile或者 .bash_profile 或者 .zshrc中添加）</span></span><br><span class="line"><span class="function">export HADOOP_HOME_WARN_SUPPRESS</span>=<span class="number">1</span></span><br><span class="line">                    </span><br><span class="line">                    </span><br><span class="line">测试yarn集群是否启动成功 (提交MapReduce例子程序试跑)</span><br><span class="line">ls apps/hadoop-<span class="number">2.7</span>.6/share/hadoop/mapreduce</span><br><span class="line">bin/hadoop jar hadoop-mapreduce-examples-<span class="number">2.6</span>.5.jar  pi <span class="number">5</span> <span class="number">5</span></span><br></pre></td></tr></table></figure><h3 id="可能遇到的错误"><a href="#可能遇到的错误" class="headerlink" title="可能遇到的错误"></a>可能遇到的错误</h3><h4 id="搭建过程中"><a href="#搭建过程中" class="headerlink" title="搭建过程中"></a>搭建过程中</h4><ol><li>主机找不到<ol><li>/etc/sysconfig/network     /etc/hosts</li><li>重启机器</li></ol></li><li>何时化的时候报错<ul><li>配置文件错误,  根据错误去相应文件进行调整, 修改完毕后, 重新格式化直到格式化成功</li></ul></li></ol><h4 id="启动过程中"><a href="#启动过程中" class="headerlink" title="启动过程中"></a>启动过程中</h4><h4 id="某些进程启动不了"><a href="#某些进程启动不了" class="headerlink" title="某些进程启动不了"></a>某些进程启动不了</h4><h5 id="措辞1-暴力"><a href="#措辞1-暴力" class="headerlink" title="措辞1: 暴力"></a>措辞1: 暴力</h5><ul><li>全部关闭集群重新启动<ul><li>stop-dfs.sh     在任意节点执行</li><li>stop-yarn.sh  在yarn的主节点启动</li><li>重新启动, 直接启动就可以了</li><li>start-dfs.sh</li><li>start-yarn.sh</li></ul></li></ul><h5 id="措施2-单独启动某些进程"><a href="#措施2-单独启动某些进程" class="headerlink" title="措施2: 单独启动某些进程"></a>措施2: 单独启动某些进程</h5><p>单独启动<code>hdfs</code>的相关进程</p><ul><li>hadoop-daemon.sh  start  hdfs 过程</li><li>hadoop-daemon.sh  start namenode</li><li>hadoop-daemon.sh start secondarynamenode</li></ul><p>单独启动<code>yarn</code>的相关命令</p><ul><li>yarn-daemon.sh start yarn 的相关过程</li><li>yarn-daemon.sh start resourcemanager</li></ul><h3 id="搭建过程中的注意事项"><a href="#搭建过程中的注意事项" class="headerlink" title="==搭建过程中的注意事项=="></a>==搭建过程中的注意事项==</h3><ol><li><p>集群的<strong>只能成功的格式化一次,</strong>  不成功的要一直到格式化成功, <strong>成功后就不能再次格式化</strong></p><ul><li><p><strong>格式化的过程中</strong>: 创建出来<strong>namenode</strong>存储的相关目录</p><ul><li><p>version文件: 记录仪集群的版本信息的,  每格式化一次, 就会产生一个新的版本信息</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">namespaceID=1163449973</span><br><span class="line">clusterID=CID-47f10077-2aef-4df6-a364-1a735515a100   <span class="comment">#记录集群的版本信息的</span></span><br><span class="line">cTime=0</span><br><span class="line">storageType=NAME_NODE</span><br><span class="line">blockpoolID=BP-1527239677-192.168.75.162-1527817150436</span><br><span class="line">layoutVersion=-63</span><br></pre></td></tr></table></figure></li></ul></li><li><p><strong>启动hdfs的时候</strong>:  生成<strong>datanode</strong>的相关数据信息</p><ul><li><p>version: 记录datanode 相关版本的信息</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">clusterID=CID-47f10077-2aef-4df6-a364-1a735515a100</span><br></pre></td></tr></table></figure></li></ul></li></ul></li></ol><ul><li>两个文件中的<code>clusterID</code>相同的时候, datanode 才会认为是同一个集群的</li></ul><ol start="2"><li><p><strong>想要重复格式化, 分3步走</strong></p><ol><li><p>停止所有服务</p></li><li><p>删除 namenode 的数据目录</p><blockquote><p><code>rm -rf /home/ap/data/hadoopdata/name</code></p></blockquote></li><li><p>删除 datanode 的数据目录</p><blockquote><p><code>rm -rf /home/ap/data/hadoopdata/data</code></p></blockquote></li><li><p>此时才可以重新格式化,  否则会造成 datanode 启动不了, 注意, 关闭防火墙, 关闭vpn</p></li><li><p>也可以一步到位</p><blockquote><p><code>rm -rf /home/ap/data</code> </p><p>再重新格式化</p></blockquote></li></ol></li></ol><ol start="3"><li><p>集群搭建过程中<strong>环境变量的配置</strong>(jdk. hadoop…)</p><ul><li>在Linux中修改环境变量的地方有3个<ul><li>/etc/profile  系统环境变量, 针对所有用户的</li><li>~/.bashrc     用户环境变量</li><li>~/.bash_profile  用户环境变量</li></ul></li><li>这3个配置文件的加载顺序<ul><li>/etc/profile  &gt; .bashrc  &gt;   .bash_profile</li></ul></li><li>生效: 最后一次加载的生效</li></ul></li></ol><ol start="4"><li><p><strong>时间同步</strong>问题</p><ul><li>只要是完全分布式的, 多个节点之间一定要做时间同步,</li><li>目的:<ul><li>要和 北京/上海 时间保持一致?    no</li><li>集群背部各个节点之间时间保持一致  yes</li></ul></li><li>why ? <ul><li>集群内部各个节点之间需要通信, 尤其是datanode 和 namenode之间, 他们之间的通信依靠<strong>心跳机制</strong>, 他们之间的心跳存在一个时间控制, 这个时间是 <strong>630s</strong>, 他们之前需要做时间同步</li></ul></li></ul></li></ol><hr><h1 id="集群的安装模式"><a href="#集群的安装模式" class="headerlink" title="集群的安装模式"></a>集群的安装模式</h1><h3 id="1-单机模式"><a href="#1-单机模式" class="headerlink" title="1. 单机模式"></a>1. 单机模式</h3><ul><li>直接解压的方式, 什么都不配置, 并且在一个节点上</li><li>没有分布式文件系统, 所有的文件都是来自本地, 只能对本地的文件进行读写</li><li>几乎没人用, 测试时偶尔会用</li></ul><h3 id="2-伪分布式"><a href="#2-伪分布式" class="headerlink" title="2. 伪分布式"></a>2. 伪分布式</h3><ul><li>可以看做跑在一个节点上的完全分布式</li><li>有分布式文件系统, 只不过这个文件系统只有一个节点</li></ul><h3 id="3-完全分布式"><a href="#3-完全分布式" class="headerlink" title="==3. 完全分布式=="></a>==3. 完全分布式==</h3><p><strong><a href="https://app.yinxiang.com/shard/s37/nl/7399077/c3f4c3b9-249e-42cf-87e4-fb5db3bb37e2/" target="_blank" rel="noopener">参考文档</a></strong> </p><p><strong>规划</strong></p><p><strong>目前疑点:</strong>  NodeManager是根据什么配置到每台机器上的??</p><p>根据表征, 可能是根据 slave文件</p><table><thead><tr><th>主机名 / IP</th><th>HDFS</th><th>YARN</th></tr></thead><tbody><tr><td>cts1 / 192.168.56.131</td><td>NameNode</td><td>空的</td></tr><tr><td>cts2 / 192.168.56.132</td><td>DataNode</td><td>NodeManager</td></tr><tr><td>cts3 / 192.168.56.133</td><td>DataNode + Secondary NameNode</td><td>NodeManager</td></tr><tr><td>cts4 / 192.168.56.134</td><td>DataNode</td><td>NodeManager +ResourceManager</td></tr></tbody></table><ul><li>hdfs 为例 : 在宏观看就是一个大的节点, 后台采用的硬件配置是三天机器的硬件配置之和, 但是对用户来讲完全感觉不到</li><li>在完全分布式中, 有主节点, 有从节点</li><li>主节点 namenode只有一个, 从节点有多个, 真实生产中, namenode会单独做一个节点</li><li>如果集群中namenode宕机,  整个集群还可以使用吗?  不可以<ul><li>namenode: 主要作用存储<strong>元数据</strong> (管理数据的数据, 存储的就是datanode存储数据的描述)</li><li>datanode: 负责集群中真正处理数据存存储的</li></ul></li><li>如果namenode 宕机, 集群无法使用, 这也是完全分布式的一大缺点, 存在单点故障问题</li><li>一般生产中不太使用,  学习, 测试, 节点个数比较少的时候, 有时候也会使用这种模式</li><li>节点数目越多, namenode宕机的可能性越大, 压力太大</li><li>助理secondarynamenode: 只是一个助理, 只是分担namenode的压力, 但是不能代替</li><li>架构:<ul><li>一主多从</li></ul></li></ul><h3 id="4-高可用"><a href="#4-高可用" class="headerlink" title="==4. 高可用=="></a>==4. 高可用==</h3><ul><li>概念: 集群可以持续对外提供服务,  做到 7*24 小时不间断</li><li>依赖于zookeeper,  搭建放在 zookeeper课程之后</li><li>集群架构: <ul><li>双主多从</li></ul></li><li>有<strong>2个 namenode</strong>, 但是在同一时间只能有一个是 活跃的 namenode, 我们把这个活跃的namenode 成为 active 的, 另外一个是处理热备份状态,  我们将这个节点叫 <code>standby</code>, 但是<strong>2个主节点</strong>存储的<strong>元数据</strong>是一模一样的, 当 <code>active namenode</code>宕机的时候, standby的namenode 可以立马切换为 active 的namenode, 对外提供服务, 就可以做到 <strong>集群持续对外提供服务</strong>的功能</li><li>如果过一段时间, 宕机的 namenode 又活过来了, 宕机的 namenode 只能是变成 standby 的</li><li><strong>缺陷</strong>: 在同一时间中, 集群中只有一个active 的 namenode,  也就是说 <strong>集群中有主节点能力的节点 只有一个</strong>, 如果集群中, 节点个数过多(1000) 的时候, 会造成namenode的崩溃, namenode存储的是元数据,  元数据过多的时候, 会造成namenode的崩溃(<strong>两个都崩溃</strong>),  没有真正的分担namenode 的压力</li><li><strong>实际生产多使用高可用</strong></li></ul><h3 id="5-联邦机制"><a href="#5-联邦机制" class="headerlink" title="5. 联邦机制"></a>5. 联邦机制</h3><ul><li>同一个集群中可以有多个主节点, 这些主节点的地位是一样的.</li><li><strong>同一时间, 可以有多个活跃的 namenode</strong></li><li>这些 namenode 共同使用集群中所有的 datanode, 每个namenode 只负责管理集群中的 datanode上的一部分数据</li><li>一般超大集群搭建的时候:  <strong>联邦 + 高可用</strong></li><li><strong>超大集群使用</strong></li><li>每个namenode进行数据管理靠的Block Pool ID相同 </li><li>不同的namenode管理的数据Block Pool ID  不同</li></ul><hr>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;引入&quot;&gt;&lt;a href=&quot;#引入&quot; class=&quot;headerlink&quot; title=&quot;引入&quot;&gt;&lt;/a&gt;引入&lt;/h1&gt;&lt;h3 id=&quot;面试题&quot;&gt;&lt;a href=&quot;#面试题&quot; class=&quot;headerlink&quot; title=&quot;面试题&quot;&gt;&lt;/a&gt;面试题&lt;/h3&gt;&lt;h
      
    
    </summary>
    
      <category term="Hadoop" scheme="https://airpoet.github.io/categories/Hadoop/"/>
    
      <category term="学习笔记" scheme="https://airpoet.github.io/categories/Hadoop/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="原创" scheme="https://airpoet.github.io/tags/%E5%8E%9F%E5%88%9B/"/>
    
      <category term="技术" scheme="https://airpoet.github.io/tags/%E6%8A%80%E6%9C%AF/"/>
    
      <category term="Hadoop" scheme="https://airpoet.github.io/tags/Hadoop/"/>
    
      <category term="HDFS" scheme="https://airpoet.github.io/tags/HDFS/"/>
    
  </entry>
  
  <entry>
    <title>Hadoop体系概览</title>
    <link href="https://airpoet.github.io/2018/05/31/Hadoop/Overview/Hadoop%E4%BD%93%E7%B3%BB%E6%A6%82%E8%A7%88/"/>
    <id>https://airpoet.github.io/2018/05/31/Hadoop/Overview/Hadoop体系概览/</id>
    <published>2018-05-30T16:46:03.290Z</published>
    <updated>2018-06-02T11:02:01.730Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Hadoop核心组件"><a href="#Hadoop核心组件" class="headerlink" title="Hadoop核心组件"></a>Hadoop核心组件</h1><h2 id="1-分布式文件系统HDFS"><a href="#1-分布式文件系统HDFS" class="headerlink" title="1. 分布式文件系统HDFS"></a>1. 分布式文件系统HDFS</h2><h3 id="1-1-基本概念"><a href="#1-1-基本概念" class="headerlink" title="1.1 基本概念"></a>1.1 基本概念</h3><ul><li>将文件切分成指定大小的数据块并以多副本的存储形式存储在多个机器上</li><li>数据切分, 多副本, 容错等操作对用户是透明的</li></ul><h3 id="1-2-图示"><a href="#1-2-图示" class="headerlink" title="1.2 图示"></a>1.2 图示</h3><p><img src="http://p6i5vzkfk.bkt.clouddn.com/study/2018-05-30-165029.png" alt="image-20180531005029275"></p><h3 id="1-3-HDFS架构"><a href="#1-3-HDFS架构" class="headerlink" title="1.3  HDFS架构"></a>1.3  HDFS架构</h3><ul><li><strong>Datanode 定期向 Namenode 发 Hearbeat</strong></li><li><strong>元数据信息： 多份备份</strong></li></ul><p><img src="http://p6i5vzkfk.bkt.clouddn.com/study/2018-06-02-064845.jpg" alt=""></p><h3 id="1-4-HDFS的-IO-操作"><a href="#1-4-HDFS的-IO-操作" class="headerlink" title="1.4 HDFS的 IO 操作"></a>1.4 HDFS的 IO 操作</h3><ul><li>上面的是<strong>读</strong><ul><li>客户端先向 NameNode 寻址</li><li>然后再找 DataNode 拿数据</li></ul></li><li>下面的是<strong>写</strong><ul><li><strong>HDFS</strong> 不支持修改， 没有 leader 角色， <strong>不支持并发写</strong>， 只能支持非并发的追加</li><li>HBase 支持并发写和修改</li></ul></li><li><strong>删除</strong>： 删除的是<strong>元数据</strong>（索引信息）<ul><li>Datanode 会定期向 Namenode <strong>发送心跳</strong>， <strong>同步信息</strong>， 当 Namenode 发现 Datanode 上没有自己存储的信息时，就会把这部分信息删除掉。</li></ul></li></ul><p><img src="http://p6i5vzkfk.bkt.clouddn.com/study/2018-06-02-065117.png" alt="image-20180602145116939"></p><h3 id="1-5-HDFS-副本存放策略"><a href="#1-5-HDFS-副本存放策略" class="headerlink" title="1.5 HDFS 副本存放策略"></a>1.5 HDFS 副本存放策略</h3><ul><li><strong>复制因子为3时的 存放策略</strong><ul><li>如果写入者在一个 datanode 上， 则把一份拷贝放在本地机器上， 否则随机放到一个 datande 上</li><li>另一个副本放在不同的（远程）机架的节点上， 最后一个副本存放在同一个机架的不同节点上</li><li>这一策略削减了机架间的写入流量，通常提高了写入性能</li></ul></li><li>复制因子大于3， 则随机确定第4个和其它的副本位置，同时将每个拷贝的数目保持在上限以下(基本上是<code>(副本数 - 1) / racks + 2</code>)。</li></ul><p><img src="http://p6i5vzkfk.bkt.clouddn.com/study/2018-06-02-093751.png" alt="image-20180602173750873"></p><h2 id="2-资源调度系统-YARN"><a href="#2-资源调度系统-YARN" class="headerlink" title="2. 资源调度系统 YARN"></a>2. 资源调度系统 YARN</h2><h3 id="2-1-基本概念"><a href="#2-1-基本概念" class="headerlink" title="2.1 基本概念"></a>2.1 基本概念</h3><ul><li>YARN:  Yet Another Resource Negotiator</li><li>负责整个集群资源的管理和调度</li><li>YAEN特点: 扩展性 &amp; 容错性 &amp; 多框架资源统一调度</li></ul><h3 id="2-2-图示"><a href="#2-2-图示" class="headerlink" title="2.2 图示"></a>2.2 图示</h3><p><img src="http://p6i5vzkfk.bkt.clouddn.com/study/2018-05-30-165444.png" alt="image-20180531005443543"></p><h2 id="3-分布式计算框架-MapReduce"><a href="#3-分布式计算框架-MapReduce" class="headerlink" title="3. 分布式计算框架 MapReduce"></a>3. 分布式计算框架 MapReduce</h2><h3 id="3-1-基本概念"><a href="#3-1-基本概念" class="headerlink" title="3.1 基本概念"></a>3.1 基本概念</h3><ul><li>源于Google的MapReduce论文, 论文发表于2004年12月</li><li>MapReduce是Google MapReduce的克隆版</li><li>MapReduce的特点: 扩展性 &amp; 容错性 &amp; 海量数据离线处理</li></ul><h3 id="3-2-图示"><a href="#3-2-图示" class="headerlink" title="3.2 图示"></a>3.2 图示</h3><p><img src="http://p6i5vzkfk.bkt.clouddn.com/study/2018-05-30-165821.png" alt="image-20180531005821191"></p><hr><h1 id="Hadoop优势"><a href="#Hadoop优势" class="headerlink" title="Hadoop优势"></a>Hadoop优势</h1><h3 id="1-高可靠性"><a href="#1-高可靠性" class="headerlink" title="1.  高可靠性"></a>1.  高可靠性</h3><ul><li>数据存储: 数据块多副本</li><li>数据计算: 重新调度作业计算</li></ul><h3 id="2-高扩展性"><a href="#2-高扩展性" class="headerlink" title="2.  高扩展性"></a>2.  高扩展性</h3><ul><li>存储/计算资源不够时, 可以横向的线性扩展机器</li><li>一个集群中可以包含数以千计的节点</li></ul><h3 id="3-其它"><a href="#3-其它" class="headerlink" title="3.  其它"></a>3.  其它</h3><ul><li>存储在廉价机器上, 降低成本</li><li>成熟的生态圈</li></ul><hr><h1 id="Hadoop的发展史"><a href="#Hadoop的发展史" class="headerlink" title="Hadoop的发展史"></a>Hadoop的发展史</h1><p><a href="http://www.infoq.com/cn/articles/hadoop-ten-years-interpretation-and-development-forecast" target="_blank" rel="noopener">见文章: Hadoop十年解读与发展预测</a></p><p><a href="http://hadoop.apache.org/" target="_blank" rel="noopener">Hadoop官网</a></p><hr><h1 id="Hadoop生态系统"><a href="#Hadoop生态系统" class="headerlink" title="Hadoop生态系统"></a>Hadoop生态系统</h1><h3 id="1-图示"><a href="#1-图示" class="headerlink" title="1. 图示"></a>1. 图示</h3><p><img src="http://p6i5vzkfk.bkt.clouddn.com/study/2018-05-30-171338.png" alt="image-20180531011337987"></p><h3 id="2-特点"><a href="#2-特点" class="headerlink" title="2. 特点"></a>2. 特点</h3><ul><li>开源,  社区活跃</li><li>囊括了大数据处理的方方面面</li><li>成熟的生态圈</li></ul><hr><h1 id="Hadoop常用发行版及选型"><a href="#Hadoop常用发行版及选型" class="headerlink" title="Hadoop常用发行版及选型"></a>Hadoop常用发行版及选型</h1><ul><li>Apache Hadoop</li><li><strong>CDH : Cloudera Distributed Hadoop</strong>  （国内用的比较多）</li><li>HDP : Hortonworks Data Platform  </li></ul><blockquote><p><strong>使用:</strong></p><p>CDH使用占比 60-70</p><p>hadoop:  hadoop-2.6.0-cdh5.7.0  </p><p>hive : hive-1.1.0-cdh5.7.0</p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Hadoop核心组件&quot;&gt;&lt;a href=&quot;#Hadoop核心组件&quot; class=&quot;headerlink&quot; title=&quot;Hadoop核心组件&quot;&gt;&lt;/a&gt;Hadoop核心组件&lt;/h1&gt;&lt;h2 id=&quot;1-分布式文件系统HDFS&quot;&gt;&lt;a href=&quot;#1-分布式文件系
      
    
    </summary>
    
      <category term="Hadoop" scheme="https://airpoet.github.io/categories/Hadoop/"/>
    
      <category term="学习笔记" scheme="https://airpoet.github.io/categories/Hadoop/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="原创" scheme="https://airpoet.github.io/tags/%E5%8E%9F%E5%88%9B/"/>
    
      <category term="技术" scheme="https://airpoet.github.io/tags/%E6%8A%80%E6%9C%AF/"/>
    
      <category term="Hadoop" scheme="https://airpoet.github.io/tags/Hadoop/"/>
    
  </entry>
  
  <entry>
    <title>Java基础增强-2 并发编程</title>
    <link href="https://airpoet.github.io/2018/05/30/Java/Java%E5%9F%BA%E7%A1%80%E5%A2%9E%E5%BC%BA-2/"/>
    <id>https://airpoet.github.io/2018/05/30/Java/Java基础增强-2/</id>
    <published>2018-05-30T06:28:56.938Z</published>
    <updated>2018-05-31T02:05:38.240Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-多线程基本知识"><a href="#1-多线程基本知识" class="headerlink" title="1. 多线程基本知识"></a>1. 多线程基本知识</h2><h3 id="1-1-多线程运行的原理"><a href="#1-1-多线程运行的原理" class="headerlink" title="1.1 多线程运行的原理"></a>1.1 多线程运行的原理</h3><blockquote><p>原理：CPU 在线程中做时间片的切换。</p></blockquote><p><strong>一个(多核中的一个) CPU</strong> 在在运行程序的过程中<strong>某个时刻点上</strong>，<strong>只能运行一个</strong>程序。而 CPU 可以在 <strong>多个程序之间进行高速的切换 (轮询制)</strong>。而切换频率和速度太快，导致人的肉眼看不到。</p><h3 id="1-2-实现线程的两种方式"><a href="#1-2-实现线程的两种方式" class="headerlink" title="1.2 实现线程的两种方式"></a>1.2 实现线程的两种方式</h3><ol><li>继承 Thread</li><li><strong>声明实现Runnable接口</strong></li><li>还可以实现Callable接口 </li></ol><h3 id="1-3-线程的状态图解"><a href="#1-3-线程的状态图解" class="headerlink" title="1.3 线程的状态图解"></a>1.3 线程的状态图解</h3><p><img src="http://p6i5vzkfk.bkt.clouddn.com/study/2018-05-30-063904.jpg" alt=""></p><p><img src="http://p6i5vzkfk.bkt.clouddn.com/study/2018-05-30-064204.jpg" alt="Attachment.jpeg"> </p><ol><li><strong>新建状态（New）</strong>：新创建了一个线程对象。</li><li><strong>就绪状态（Runnable）</strong>：线程对象创建后，其他线程调用了该对象的 <code>start()</code>方法。该状态 的线程位于可运行线程池中，变得可运行，等待获取 CPU 的使用权。</li><li><strong>运行状态（Running）</strong>：就绪状态的线程获取了 CPU，执行程序代码。</li><li><strong>阻塞状态（Blocked）</strong>：阻塞状态是线程因为某种原因放弃 CPU 使用权，暂时停止运行。 直到线程进入就绪状态，才有机会转到运行状态。阻塞的情况分三种：<ul><li><strong>等待阻塞</strong>：运行的线程执行 <code>wait()</code>方法，JVM 会把该线程放入等待池中。(wait 会释 放持有的锁)</li><li><strong>同步阻塞</strong>：运行的线程在获取对象的同步锁时，若该同步锁被别的线程占用，则 JVM 会把该线程放入锁池中。</li><li><strong>其他阻塞</strong>：运行的线程执行 sleep()或 join()方法，或者发出了 I/O 请求时，JVM 会把 该线程置为阻塞状态。当 sleep()状态超时、join()等待线程终止或者超时、或者 I/O 处理完毕 时，线程重新转入就绪状态。（注意：sleep 是不会释放持有的锁）</li></ul></li><li><strong>死亡状态（Dead）</strong>：线程执行完了或者因异常退出了 run()方法，该线程结束生命周期。</li></ol><h3 id="1-4-几个重要的方法的区别："><a href="#1-4-几个重要的方法的区别：" class="headerlink" title="1.4 几个重要的方法的区别："></a>1.4 几个重要的方法的区别：</h3><blockquote><p><strong><code>sleep(timeout)</code></strong>：当前线程进入阻塞状态，暂停执行一定时间，不会释放锁标记</p><p><strong><code>join()</code></strong>：join()方法会使当前线程等待调用 <code>join()</code>方法的线程结束后才能继续执行</p><p><strong><code>yield()</code></strong>：调用该方法的线程重回可执行状态，不会释放锁标记，可以理解为交出 CPU 时间片， 但是不一定有效果，因为有可能又被马上执行。该方法的真正作用是使具有相同或者更高优 先级的方法得到执行机会。</p><p><strong><code>wait(timeout)</code></strong>：wait 方法通常和 <code>notify()</code>/<code>notifyAll()</code>搭配使用，当前线程暂停执行，会释放锁 标记。进入对象等待池。直到调用 <code>notify()</code>方法之后，线程被移动到锁标记等待池。只有锁 标记等待池的线程才能获得锁</p></blockquote><h3 id="1-5-Join的用法"><a href="#1-5-Join的用法" class="headerlink" title="1.5 Join的用法"></a>1.5 Join的用法</h3><p><strong>联合线程:</strong></p><p>线程的join方法表示一个线程等待另一个线程完成后才执行。有人也把这种方式称为联合线程，就是说把当前线程和当前线程所在的线程联合成一个线程。join方法被调用之后，线程对象处于阻塞状态。</p><p>适用于A线程需要等到B线程执行完毕,再拿B线程的结果再继续运行A线程.</p><p>说人话: A线程需要拿到B线程的执行结果,才能继续往下.</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Join</span> <span class="keyword">extends</span> <span class="title">Thread</span></span>&#123;</span><br><span class="line">   <span class="meta">@Override</span></span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">       <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">50</span>; i++) &#123;</span><br><span class="line">           System.out.println(<span class="string">"This is join: "</span> + i);</span><br><span class="line">       &#125;</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">JoinThread</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</span><br><span class="line">        </span><br><span class="line">        System.out.println(<span class="string">"begin..."</span>);</span><br><span class="line">        Join joinThread = <span class="keyword">new</span> Join();<span class="comment">//创建join线程对象</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">50</span>; i++) &#123;</span><br><span class="line">            System.out.println(<span class="string">"main: "</span> +i);</span><br><span class="line">            <span class="keyword">if</span> (i == <span class="number">10</span>)&#123;</span><br><span class="line">                <span class="comment">//启动join对象</span></span><br><span class="line">                joinThread.start();</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span> (i == <span class="number">20</span>)&#123;</span><br><span class="line">                System.out</span><br><span class="line">                        .println(<span class="string">"------------------------------------------"</span>);</span><br><span class="line">                joinThread.join();<span class="comment">//在此处强制运行该线程</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">    </span><br><span class="line">===================执行结果===================</span><br><span class="line">begin...</span><br><span class="line">main: <span class="number">0</span></span><br><span class="line">main: <span class="number">1</span></span><br><span class="line">main: <span class="number">2</span></span><br><span class="line">main: <span class="number">3</span></span><br><span class="line">main: <span class="number">4</span></span><br><span class="line">main: <span class="number">5</span></span><br><span class="line">main: <span class="number">6</span></span><br><span class="line">main: <span class="number">7</span></span><br><span class="line">main: <span class="number">8</span></span><br><span class="line">main: <span class="number">9</span></span><br><span class="line">main: <span class="number">10</span></span><br><span class="line">main: <span class="number">11</span></span><br><span class="line">main: <span class="number">12</span></span><br><span class="line">main: <span class="number">13</span></span><br><span class="line">This is join: <span class="number">0</span></span><br><span class="line">main: <span class="number">14</span></span><br><span class="line">This is join: <span class="number">1</span></span><br><span class="line">This is join: <span class="number">2</span></span><br><span class="line">This is join: <span class="number">3</span></span><br><span class="line">main: <span class="number">15</span></span><br><span class="line">This is join: <span class="number">4</span></span><br><span class="line">main: <span class="number">16</span></span><br><span class="line">main: <span class="number">17</span></span><br><span class="line">main: <span class="number">18</span></span><br><span class="line">main: <span class="number">19</span></span><br><span class="line">main: <span class="number">20</span></span><br><span class="line">------------------------------------------</span><br><span class="line">This is join: <span class="number">5</span></span><br><span class="line">This is join: <span class="number">6</span></span><br><span class="line">This is join: <span class="number">7</span></span><br><span class="line">This is join: <span class="number">8</span></span><br><span class="line">This is join: <span class="number">9</span></span><br><span class="line">This is join: <span class="number">10</span></span><br><span class="line">...</span><br><span class="line">...</span><br><span class="line">This is join: <span class="number">44</span></span><br><span class="line">This is join: <span class="number">45</span></span><br><span class="line">This is join: <span class="number">46</span></span><br><span class="line">This is join: <span class="number">47</span></span><br><span class="line">This is join: <span class="number">48</span></span><br><span class="line">This is join: <span class="number">49</span></span><br><span class="line">main: <span class="number">21</span></span><br><span class="line">main: <span class="number">22</span></span><br><span class="line">main: <span class="number">23</span></span><br><span class="line">main: <span class="number">24</span></span><br><span class="line">main: <span class="number">25</span></span><br><span class="line">main: <span class="number">26</span></span><br><span class="line">main: <span class="number">27</span></span><br><span class="line">main: <span class="number">28</span></span><br><span class="line">main: <span class="number">29</span></span><br><span class="line">main: <span class="number">30</span></span><br></pre></td></tr></table></figure><hr><h2 id="2-Java同步关键词解释"><a href="#2-Java同步关键词解释" class="headerlink" title="2.  Java同步关键词解释"></a>2.  Java同步关键词解释</h2><h3 id="2-1-synchronized"><a href="#2-1-synchronized" class="headerlink" title="2.1.  synchronized"></a>2.1.  synchronized</h3><p>属于 JVM 级别加锁，底层实现是： 在编译过程中，在指令级别加入一些标识来实现的。</p><p><strong>1.  锁对象注意点: 必须是锁的同一个对象</strong></p><p><img src="http://p6i5vzkfk.bkt.clouddn.com/study/2018-05-30-232550.jpg" alt=""></p><p><strong>2.  锁获取和释放</strong></p><ul><li>锁的获取是由JVM决定的, 用户无法操作</li><li>锁的释放也是由JVM决定的</li><li><code>Synchronized</code> 无法中断正在阻塞队列或者等待队列的线程。</li></ul><p><strong>3.  什么时候会释放</strong></p><ul><li>获取锁的线程执行完了该代码块，然后线程释放对锁的占有；</li><li>线程执行发生异常，此时 JVM 会让线程自动释放锁。</li></ul><p><strong>4.格式</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 加同步格式：</span></span><br><span class="line"><span class="keyword">synchronized</span>(需要一个任意的对象（锁）)&#123;</span><br><span class="line">代码块中放操作共享数据的代码。</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>5.线程执行互斥代码的过程</strong></p><ol><li><p>获得互斥锁</p></li><li><p>清空工作内存</p></li><li><p>从主内存拷贝变量的最新副本到工作内存</p></li><li><p>执行代码</p></li><li><p>将更新后的共享变量的值刷新到主内存</p></li><li><p>释放互斥锁</p><p><code>Lock -&gt; 主内存 -&gt; 工作内存 -&gt; 主内存 -&gt; unlock</code></p></li></ol><h3 id="2-2-Lock"><a href="#2-2-Lock" class="headerlink" title="2.2  Lock"></a>2.2  Lock</h3><p><strong>手动获取或释放锁, 提供了比 synchronized 更多的功能</strong></p><p>Lock 锁是 <strong>Java 代码级别</strong>来实现的，相对于 synchronized 在功能性上，有所加强，主要是，公平锁，轮 询锁，定时锁，可中断锁等，还增加了多路通知机制（Condition），可以用一个锁来管理多 个同步块。另外在使用的时候，必须手动的释放锁。Lock 锁的实现，主要是借助于队列同 步器（我们常常见到的 AQS）来实现。它包括一个 int 变量来表示状态；一个 FIFO 队列，来 存储获取资源的排队线程。</p><p><strong>基本使用</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">X</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 创建一把锁</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> ReentrantLock lock = <span class="keyword">new</span> ReentrantLock();</span><br><span class="line">    <span class="comment">// 需要做同步的方法</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">m</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        lock.lock();     <span class="comment">//获取🔐, 加锁</span></span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">// 代码</span></span><br><span class="line">        &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">            lock.unlock(); <span class="comment">// 释放🔐</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="1-lock-和-synchronized-的区别"><a href="#1-lock-和-synchronized-的区别" class="headerlink" title="1. lock 和 synchronized 的区别"></a>1. lock 和 synchronized 的区别</h4><ol><li>Lock 不是 Java 语言内置的，<strong>synchronized 是 Java 语言的关键字，因此是内置特性</strong>。<strong>Lock 是一个类</strong>，通过这个类可以实现同步访问；</li><li>Lock 和 synchronized 有一点非常大的不同，采用 <strong>synchronized 不需要用户去手动释放锁</strong>， 当 synchronized 方法或者 synchronized 代码块执行完之后，系统会自动让线程释放对锁的占 用；而 <strong>Lock 则必须要用户去手动释放锁</strong>，如果没有主动释放锁，就有可能导致出现死锁现 象。</li></ol><h4 id="2-Lock-接口中方法的使用"><a href="#2-Lock-接口中方法的使用" class="headerlink" title="2. Lock 接口中方法的使用"></a>2. Lock 接口中方法的使用</h4><blockquote><p><strong>ReentrantLock 类</strong></p><p>ReentrantLock 是唯一实现了 Lock 接口的类，并且 ReentrantLock 提供了更多的方法，ReentrantLock，意思是“可重入锁”。        </p><p><code>lock()、tryLock()、tryLock(long time, TimeUnit unit)、lockInterruptibly()</code>是用来获取锁的。</p><p><code>unLock()</code>方法是用来释放锁的。</p></blockquote><p><strong>四个获取锁方法的区别</strong></p><ol><li><strong><code>lock()</code>，阻塞方法</strong>，该方法是平常使用得最多的一个方法，就是用来获取锁。如果锁已被 其他线程获取，则进行等待。由于在前面讲到如果采用 Lock，必须主动去释放锁，并且在 发生异常时，不会自动释放锁。因此一般来说，使用 Lock 必须在 try{}catch{}块中进行，并 且将释放锁的操作放在 finally 块中进行，以保证锁一定被被释放，防止死锁的发生。</li><li><p><strong><code>tryLock()</code>，非阻塞方法</strong>，该方法是有返回值的，它表示用来尝试获取锁，如果获取成功， 则返回 true，如果获取失败（即锁已被其他线程获取），则返回 false，也就说这个方法无论 如何都会立即返回。在拿不到锁时不会一直在那等待。</p></li><li><p><code>tryLock(long time, TimeUnit unit)</code>，阻塞方法，阻塞给定时长，该方法和 tryLock()方法是 类似的，只不过区别在于这个方法在拿不到锁时会等待一定的时间，在时间期限之内如果还 拿不到锁，就返回 false。如果一开始拿到锁或者在等待期间内拿到了锁，则返回 true。</p></li><li><p><code>lockInterruptibly()</code>这个方法比较特殊，当通过这个方法去获取锁时，如果线程正在等待 获取锁，则这个线程能够响应中断，即中断线程的等待状态。也就使说，当两个线程同时通 过 lock.lockInterruptibly()想获取某个锁时，假若此时线程 A 获取到了锁，而线程 B 只有在等 待，那么对线程 B 调用 <code>threadB.interrupt()</code>方法能够中断线程 B 的等待过程。</p></li></ol><h3 id="2-3-Lock-与-synchronized-的选择"><a href="#2-3-Lock-与-synchronized-的选择" class="headerlink" title="2.3 Lock 与 synchronized 的选择"></a>2.3 Lock 与 synchronized 的选择</h3><ol><li>Lock 是一个接口，而 synchronized 是 Java 中的关键字，synchronized 是内置的语言实现；</li><li>synchronized 在发生异常时，会自动释放线程占有的锁，因此不会导致死锁现象发生； 而 Lock 在发生异常时，如果没有主动通过 unLock()去释放锁，则很可能造成死锁现象，因 此使用 Lock 时需要在 finally 块中释放锁；</li><li>Lock 可以让等待锁的线程响应中断，而 synchronized 却不行，使用 synchronized 时，等 待的线程会一直等待下去，不能够响应中断；</li><li>通过 Lock 可以知道有没有成功获取锁，而 synchronized 却无法办到。</li><li>Lock 可以提高多个线程进行读操作的效率。</li></ol><h3 id="2-4-读写锁"><a href="#2-4-读写锁" class="headerlink" title="2.4 读写锁"></a>2.4 读写锁</h3><ul><li><strong>线程进入读锁的前提条件</strong>：     没有其他线程的写锁, 没有写请求或者有写请求，但调用线程和持有锁的线程是同一个  </li><li><strong>线程进入写锁的前提条件</strong>：     没有其他线程的读锁, 没有其他线程的写锁</li></ul><p><strong>ReentrantReadWriteLock 与 ReentrantLock 都是单独的实现，彼此之间没有继承或实现的关系。</strong></p><h4 id="ReadWriteLock-类"><a href="#ReadWriteLock-类" class="headerlink" title="ReadWriteLock 类"></a>ReadWriteLock 类</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// API</span></span><br><span class="line"><span class="comment">// 可以区别对待读、写的操作</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">ReadWriteLock</span> </span>&#123;</span><br><span class="line">    <span class="function">Lock <span class="title">readLock</span><span class="params">()</span></span>;</span><br><span class="line">    <span class="function">Lock <span class="title">writeLock</span><span class="params">()</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="ReentrantReadWriteLock-类"><a href="#ReentrantReadWriteLock-类" class="headerlink" title="ReentrantReadWriteLock 类"></a>ReentrantReadWriteLock 类</h4><blockquote><p> ReentrantReadWriteLock 里面提供了很多丰富的方法，不过最主要的有两个方法：readLock()和 writeLock()用来获取读锁和写锁。</p></blockquote><p>注意：不过要注意的是，如果有一个线程已经占用了读锁，则此时其他线程如果要申请写 锁，则申请写锁的线程会一直等待释放读锁。</p><p>如果有一个线程已经占用了写锁，则此时其他线程如果申请写锁或者读锁，则申请的线程 会一直等待释放写锁。</p><h3 id="2-5-死锁"><a href="#2-5-死锁" class="headerlink" title="2.5 死锁"></a>2.5 死锁</h3><p>死锁是指两个或两个以上的进程在执行过程中，因争夺资源而造成的一种<strong>互相等待</strong>的现象， 若无外力作用，它们都将无法推进下去。这是一个严重的问题，因为死锁会让你的程序挂起 无法完成任务。</p><p><strong>死锁的发生必须满足</strong>以下四个条件：</p><ul><li>互斥条件：一个资源每次只能被一个进程使用。</li><li>请求与保持条件：一个进程因请求资源而阻塞时，对已获得的资源保持不放。</li><li>不剥夺条件：进程已获得的资源，在末使用完之前，不能强行剥夺。</li><li>循环等待条件：若干进程之间形成一种头尾相接的循环等待资源关系。</li></ul><p><strong>避免死锁</strong>最简单的方法就是阻止循环等待条件，将系统中所有的资源设置标志位、排序，规 定所有的进程申请资源必须以一定的顺序（升序或降序）做操作来避免死锁</p><h3 id="2-6-Volatile-特殊域变量"><a href="#2-6-Volatile-特殊域变量" class="headerlink" title="2.6 Volatile 特殊域变量"></a>2.6 Volatile 特殊域变量</h3><p>多线程编程，我们要解决的问题集中在三个方面：</p><ol><li><strong>原子性。</strong>最简单的例子就是，i++,在多线程环境下，最终的结果是不确定的，为什么？就 是因为这么一个++操作，被编译为计算机底层指令后，是多个指令来完成的。那么遇到并发 的情况，就会导致彼此“覆盖”的情况。</li><li><strong>可见性。</strong>通俗解释就是，在 A 线程对一个变量做了修改，在 B 线程中，能正确的读取到 修改后的结果。究其原理，是 cpu 不是直接和系统内存通信，而是把变量读取到 L1，L2 等 内部的缓存中，也叫作私有的数据工作栈。修改也是在内部缓存中，但是何时同步到系统内 存是不能确定的，有了这个时间差，在并发的时候，就可能会导致，读到的值，不是最新值。</li><li><strong>指令重排。</strong>这里只说指令重排序，虚拟机在把代码编译为指令后执行，出于优化的目的， 在保证结果不变的情况下，可能会调整指令的执行顺序。</li></ol><p>valotile，能满足上述的可见性和有序性。但是无法保证原子性。</p><p>可见性，是在修改后，强制把对变量的修改同步到系统内存。而其他 cpu 在读取自己的内部 缓存中的值的时候，发现是 valotile 修饰的，会把内部缓存中的值，置为无效，然后从系统 内存读取。</p><p>有序性，是通过内存屏障来实现的。所谓的内存屏障，可以理解为，在某些指令中，插入屏 障指令，用以确保，在向屏障指令后面继续执行的时候，其前面的所有指令已经执行完毕。</p><h2 id="3-Java多线程中常见的面试题"><a href="#3-Java多线程中常见的面试题" class="headerlink" title="3.  Java多线程中常见的面试题"></a>3.  Java多线程中常见的面试题</h2><h4 id="1-sleep-wait-join-yield-四个方法的区别"><a href="#1-sleep-wait-join-yield-四个方法的区别" class="headerlink" title="1. sleep(),wait(),join(),yield()四个方法的区别"></a>1. <code>sleep(),wait(),join(),yield()</code>四个方法的区别</h4><p>总结：</p><p>1）：sleep()，Thread 类中的方法，表示当前线程进入阻塞状态，不释放锁</p><p>2）：wait()，Object 类中的方法，表示线程进入等待状态，释放锁，所以一般能调用这个方 法的都是同步代码块，或者获取了锁的线程代码，通常和 notify()和 notifyAll()方法结合使用</p><p>3）：join()，Thread 类中的方法，假如在 a 线程中调用 b 线程对象的 join()方法，表示当前 a 线程阻塞，直到 b 线程运行结束</p><p>4）：yield()，Thread 类中的方法，表示线程回可执行状态。跟 sleep 方法一样，也不交出锁， 只不过不带时间参数，是指交出 cpu</p><h4 id="2-Thread-和-Runnable-的区别"><a href="#2-Thread-和-Runnable-的区别" class="headerlink" title="2. Thread 和 Runnable 的区别"></a>2. <code>Thread</code> 和 <code>Runnable</code> 的区别</h4><p>总结：</p><p>实现 Runnable 接口比继承 Thread 类所具有的优势：</p><p>1）：适合多个相同的程序代码的线程去处理同一个资源</p><p>2）：可以避免 java 中的单继承的限制</p><p>3）：增加程序的健壮性，代码可以被多个线程共享，代码和数据独立</p><p>4）：线程池只能放入实现 Runable 或 callable 类线程，不能直接放入继承 Thread 的类</p><p>…</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;1-多线程基本知识&quot;&gt;&lt;a href=&quot;#1-多线程基本知识&quot; class=&quot;headerlink&quot; title=&quot;1. 多线程基本知识&quot;&gt;&lt;/a&gt;1. 多线程基本知识&lt;/h2&gt;&lt;h3 id=&quot;1-1-多线程运行的原理&quot;&gt;&lt;a href=&quot;#1-1-多线程运行的原
      
    
    </summary>
    
      <category term="Java" scheme="https://airpoet.github.io/categories/Java/"/>
    
      <category term="学习笔记" scheme="https://airpoet.github.io/categories/Java/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="原创" scheme="https://airpoet.github.io/tags/%E5%8E%9F%E5%88%9B/"/>
    
      <category term="技术" scheme="https://airpoet.github.io/tags/%E6%8A%80%E6%9C%AF/"/>
    
      <category term="Java" scheme="https://airpoet.github.io/tags/Java/"/>
    
  </entry>
  
  <entry>
    <title>Java基础增强-1 集合反射设计模式排序</title>
    <link href="https://airpoet.github.io/2018/05/29/Java/Java%E5%9F%BA%E7%A1%80%E5%A2%9E%E5%BC%BA-1/"/>
    <id>https://airpoet.github.io/2018/05/29/Java/Java基础增强-1/</id>
    <published>2018-05-29T01:39:15.028Z</published>
    <updated>2018-05-31T01:21:12.547Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1、集合框架"><a href="#1、集合框架" class="headerlink" title="1、集合框架"></a>1、集合框架</h1><h2 id="1-1-、集合框架体系图"><a href="#1-1-、集合框架体系图" class="headerlink" title="1.1  、集合框架体系图"></a>1.1  、集合框架体系图</h2><p><img src="http://p6i5vzkfk.bkt.clouddn.com/study/2018-05-29-030737.jpg" alt=""></p><h4 id="Java-的集合框架主要分为五大类体系："><a href="#Java-的集合框架主要分为五大类体系：" class="headerlink" title="Java  的集合框架主要分为五大类体系："></a>Java  的集合框架主要分为五大类体系：</h4><p>1、Collection（常用的 List 和 Set，和不常用的 Queue 和 Vector 和 Stack），单元素集合<br>2、Map（常用的 HashMap 和 TreeMap，不常用的 HashTable），Key-Value 映射<br>3、Iterator（迭代器）<br>4、工具类（Collections 和 Arrays）<br>5、Comparable 和 Comparator 比较器</p><h4 id="Java-中的集合和数组的区别"><a href="#Java-中的集合和数组的区别" class="headerlink" title="Java  中的集合和数组的区别:"></a>Java  中的集合和数组的区别:</h4><p>1、数组长度在初始化时指定，意味着只能保存定长的数据。而集合可以保存数量不确定的 数据。同时可以保存具有映射关系的数据（即关联数组，键值对 key-value）。</p><p>2、数组元素即可以是基本类型的值，也可以是对象。集合里只能保存对象（实际上只是保存对象的引用变量），基本数据类型的变量要转换成对应的包装类才能放入集合类中。</p><h4 id="Collection-接口中的方法："><a href="#Collection-接口中的方法：" class="headerlink" title="Collection 接口中的方法："></a>Collection 接口中的方法：</h4><p><img src="http://p6i5vzkfk.bkt.clouddn.com/study/2018-05-29-031118.jpg" alt=""></p><h4 id="Map-接口中的方法："><a href="#Map-接口中的方法：" class="headerlink" title="Map 接口中的方法："></a>Map 接口中的方法：</h4><p><img src="http://p6i5vzkfk.bkt.clouddn.com/study/2018-05-29-031258.jpg" alt=""></p><h2 id="1-2、常用集合特性概述"><a href="#1-2、常用集合特性概述" class="headerlink" title="1.2、常用集合特性概述"></a>1.2、常用集合特性概述</h2><h3 id="1-2-1-List-系"><a href="#1-2-1-List-系" class="headerlink" title="1.2.1 List 系"></a>1.2.1 List 系</h3><p><img src="http://p6i5vzkfk.bkt.clouddn.com/study/2018-05-29-032801.jpg" alt=""></p><p>List 特点：<strong>元素有放入顺序，元素可重复</strong></p><p>List 接口有三个实现类：LinkedList，ArrayList，Vector</p><p>LinkedList：底层基于链表实现，链表内存是散乱的，每一个元素存储本身内存地址的同时还 存储下一个元素的地址。<strong>链表增删快，查找慢</strong></p><p><strong>ArrayList 和 Vector 底层都是基于数组实现的，查询快，增删慢</strong>，区别是 ArrayList 是非线程安全的，效率高；Vector 是基于线程安全的，效率低</p><p><strong>ArrayList 的初始化大小是 10，扩容策略是 1.5 倍原元素数量的大小</strong></p><h4 id="数组-初始容量-扩容-jdk10"><a href="#数组-初始容量-扩容-jdk10" class="headerlink" title="数组 初始容量+扩容 (jdk10)"></a>数组 <strong>初始容量+扩容</strong> (jdk10)</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 初始容量</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> DEFAULT_CAPACITY = <span class="number">10</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 扩容</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">int</span> <span class="title">newCapacity</span><span class="params">(<span class="keyword">int</span> minCapacity)</span> </span>&#123;</span><br><span class="line">        <span class="comment">// overflow-conscious code</span></span><br><span class="line">        <span class="keyword">int</span> oldCapacity = elementData.length;</span><br><span class="line">        <span class="keyword">int</span> newCapacity = oldCapacity + (oldCapacity &gt;&gt; <span class="number">1</span>);</span><br><span class="line">        <span class="keyword">if</span> (newCapacity - minCapacity &lt;= <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="keyword">if</span> (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA)</span><br><span class="line">                <span class="keyword">return</span> Math.max(DEFAULT_CAPACITY, minCapacity);</span><br><span class="line">            <span class="keyword">if</span> (minCapacity &lt; <span class="number">0</span>) <span class="comment">// overflow</span></span><br><span class="line">                <span class="keyword">throw</span> <span class="keyword">new</span> OutOfMemoryError();</span><br><span class="line">            <span class="keyword">return</span> minCapacity;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> (newCapacity - MAX_ARRAY_SIZE &lt;= <span class="number">0</span>)</span><br><span class="line">            ? newCapacity</span><br><span class="line">            : hugeCapacity(minCapacity);</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p><strong>选择标准：</strong></p><p>如果涉及到“动态数组”、“栈”、“队列”、“链表”等结构，应该考虑用 List，具体的选择哪 个 List，根据下面的标准来取舍。</p><p>1、对于需要快速插入，删除元素，应该使用 LinkedList。（增删改）</p><p>2、对于需要快速随机访问元素，应该使用 ArrayList。（查询）</p><p>3、对于“单线程环境”或者“多线程环境，但 List 仅仅只会被单个线程操作”，此时应该使 用非同步的类(如 ArrayList)。对于“多线程环境，且 List 可能同时被多个线程操作”，此时， 应该使用同步的类(如 Vector)。</p><h4 id="LinkedList-add-E-e"><a href="#LinkedList-add-E-e" class="headerlink" title="LinkedList  add(E e)"></a>LinkedList  add(E e)</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"># add(E e) 源码</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">add</span><span class="params">(E e)</span> </span>&#123;</span><br><span class="line">        linkLast(e);</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">&#125;</span><br><span class="line">    </span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">linkLast</span><span class="params">(E e)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">final</span> Node&lt;E&gt; l = last;</span><br><span class="line">    <span class="keyword">final</span> Node&lt;E&gt; newNode = <span class="keyword">new</span> Node&lt;&gt;(l, e, <span class="keyword">null</span>);</span><br><span class="line">    last = newNode;</span><br><span class="line">    <span class="keyword">if</span> (l == <span class="keyword">null</span>)</span><br><span class="line">        first = newNode;</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        l.next = newNode;</span><br><span class="line">    size++;</span><br><span class="line">    modCount++;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><hr><h3 id="1-2-2、Set-系"><a href="#1-2-2、Set-系" class="headerlink" title="1.2.2、Set 系"></a>1.2.2、Set 系</h3><p><img src="http://p6i5vzkfk.bkt.clouddn.com/study/2018-05-29-033547.jpg" alt=""></p><p><strong>Set</strong> 特点：<strong>元素放入无顺序，元素不可重复</strong></p><p><strong>Set</strong> 接口的实现类：HashSet，TreeSet，LinkedHashSet</p><p><strong>HashSet</strong>（底层由 HashMap 实现）底层通过 hashCode()和 equals()进行去重。</p><h4 id="HashSet-内部判断相等的标准"><a href="#HashSet-内部判断相等的标准" class="headerlink" title="HashSet 内部判断相等的标准"></a>HashSet 内部判断相等的标准</h4><p><em>HashSet 判断两个元素相等的标准</em>：</p><p>​    两个对象通过 equals()方法比较相等，并且两个对象的 hashCode()方法返回值也相等</p><p><strong>HashSet 中判断集合元素相等，</strong>两个对象比较具体分为如下四个情况：</p><ol><li>如果有两个元素通过 equal()方法比较返回 false，并且它们的 hashCode()方法返回不相等，</li></ol><p>HashSet 将会把它们存储在不同的位置。</p><ol start="2"><li>如果有两个元素通过 equal()方法比较返回 true，并且它们的 hashCode()方法返回不相等，</li></ol><p>HashSet 将会把它们存储在不同的位置。</p><ol start="3"><li>如果两个对象通过 equals()方法比较不相等，hashCode()方法比较相等，HashSet 将会把它们存储在相同的位置，在这个位置以链表式结构来保存多个对象。这是因为当向 HashSet 集合中存入一个元素时，HashSet 会调用对象的 hashCode()方法来得到对象的 hashCode 值， 然后根据该 hashCode 值来决定该对象存储在 HashSet 中存储位置。</li><li>如果有两个元素通过 equal()方法比较返回 true，并且它们的 hashCode()方法返回 true，HashSet 将不予添加。</li></ol><p><strong>LinkedHashSet</strong>，是 HashSet 的子类，在插入元素的时候，同时使用链表维持插入元素的顺序</p><p><strong>SortedSet</strong> 接口有一个实现类：TreeSet（底层由平衡二叉树实现）确保集合中的元素都是出于排序状态</p><p>注意 <strong>LinkedHashSet</strong> 和 <em>SortedSet</em> 区别，前者<strong>存插入顺序</strong>，后者<em>存插入之后的顺序</em></p><p><strong>另外:</strong> </p><p>JDK5 : 桶表 + 链表</p><p>JDK8 : 桶表 + 链表 + 二叉树 </p><pre><code>- **二叉树**: 检索深度 &gt; 8 的时候, 转化为二叉树, 减少查询深度</code></pre><p><img src="http://p6i5vzkfk.bkt.clouddn.com/study/2018-05-29-035232.jpg" alt=""></p><h4 id="HashSet-—-HashMap-的源码实现"><a href="#HashSet-—-HashMap-的源码实现" class="headerlink" title="HashSet — HashMap 的源码实现"></a>HashSet — HashMap 的源码实现</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * The default initial capacity - MUST be a power of two.</span></span><br><span class="line"><span class="comment"> * 桶表默认容量 16</span></span><br><span class="line"><span class="comment"> * 控制hashcode 不超16范围, a.hashcode = xx % 16 (hashcode 取模 桶个数)</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> DEFAULT_INITIAL_CAPACITY = <span class="number">1</span> &lt;&lt; <span class="number">4</span>; <span class="comment">// aka 16</span></span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * MUST be a power of two &lt;= 1&lt;&lt;30.</span></span><br><span class="line"><span class="comment"> * 桶表最大 2^30</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> MAXIMUM_CAPACITY = <span class="number">1</span> &lt;&lt; <span class="number">30</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 扩容因子: 0.75</span></span><br><span class="line"><span class="comment"> * 扩容: 每次2倍</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">float</span> DEFAULT_LOAD_FACTOR = <span class="number">0.75f</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 链表: hash算法值相同的时候, 会把值相同的放在一个链表上, 链表上的元素个数</span></span><br><span class="line"><span class="comment"> * 超过8个时, 转化为二叉树, 提升查询效率</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> TREEIFY_THRESHOLD = <span class="number">8</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * The bin count threshold for untreeifying a (split) bin during a</span></span><br><span class="line"><span class="comment"> * resize operation. Should be less than TREEIFY_THRESHOLD, and at</span></span><br><span class="line"><span class="comment"> * most 6 to mesh with shrinkage detection under removal.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> UNTREEIFY_THRESHOLD = <span class="number">6</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * The smallest table capacity for which bins may be treeified.</span></span><br><span class="line"><span class="comment"> * (Otherwise the table is resized if too many nodes in a bin.)</span></span><br><span class="line"><span class="comment"> * Should be at least 4 * TREEIFY_THRESHOLD to avoid conflicts</span></span><br><span class="line"><span class="comment"> * between resizing and treeification thresholds.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> MIN_TREEIFY_CAPACITY = <span class="number">64</span>;</span><br></pre></td></tr></table></figure><h4 id="TreeSet的默认排序"><a href="#TreeSet的默认排序" class="headerlink" title="TreeSet的默认排序"></a>TreeSet的默认排序</h4><ul><li>TreeSet是有序的不可重复的, 有序是指元素值的大小</li><li>数值类型: 按照大小进行升序排序</li><li>字符串类型: 按照字典顺序进行升序排序<ul><li>字符串从左到右, 一位一位的比较</li></ul></li><li>自定义TreeSet类型: 实现 <code>compareTo</code>方法, <strong>返回为0</strong>的情况会默认<strong>覆盖</strong></li></ul><hr><h3 id="1-2-2、Map-系"><a href="#1-2-2、Map-系" class="headerlink" title="1.2.2、Map 系"></a>1.2.2、Map 系</h3><p><strong>Map 特点</strong>：存储的元素是键值对，在 JDK1.8 版本中是 Node，在老版本中是 Entry</p><p><strong>Map 接 口 有 五 个 常用 实 现 类</strong> ： HashMap ， HashTable ， LinkeHashMap ， TreeMap ，</p><p><u>ConcurrentHashMap</u></p><h4 id="1-HashMap-amp-Hashtable-的区别"><a href="#1-HashMap-amp-Hashtable-的区别" class="headerlink" title="1. HashMap &amp; Hashtable 的区别"></a>1. HashMap &amp; Hashtable 的区别</h4><p><strong>HashMap</strong></p><pre><code>1.   非线程安全, 效率高   2.   key不可以重复   3.   key可以为null,  但只能有一个key为null</code></pre><p><strong>Hashtable</strong></p><ol><li>线程安全, 效率低</li><li>key不可以重复</li><li>不可以为null</li></ol><h4 id="2-concurrentHash-简单分析"><a href="#2-concurrentHash-简单分析" class="headerlink" title="2. concurrentHash 简单分析"></a>2. concurrentHash 简单分析</h4><p>是从 JDK1.5 之后提供的一个 HashTable 的替代实现，采 一个 map 中的元素分成很多的 segment，通过 lock 机制可以对每个 segment 加读写锁，从 而提高 map 的效率，底层实现采用数组+链表+红黑树的存储结构</p><ul><li>Java并发包中的,  既是线程安全的, 又不至于效率过低</li><li>怎么实现: <strong>分段锁机制</strong><ul><li>分段锁: 只加载在某一段数据上</li></ul></li><li>MySql: 查询 - 95%,  增删改 - 5%<ul><li><strong>读锁:  共享锁,</strong>  一个线程进行操作的时候不应吸纳另一个线程的结构</li><li><strong>写锁:  排它锁,</strong>  一个线程在进行操作的时候不允许其他任何线程的操作</li></ul></li></ul><h4 id="3-put-amp-get-的流程"><a href="#3-put-amp-get-的流程" class="headerlink" title="3. put &amp; get 的流程"></a>3. put &amp; get 的流程</h4><p><strong>put 的大致流程如下：</strong></p><ol><li>通过 hashcode 方法计算出 key 的 hash 值</li><li>通过 hash%length 计算出存储在 table 中的 index（源码中是使用 hash&amp;(length-1)，这样结 果相同，但是更快）</li><li>如果此时 table[index]的值为空，那么就直接存储，如果不为空那么就链接到这个数所在 的链表的头部。（在 JDK1.8 中，如果链表长度大于 8 就转化成红黑树）</li></ol><p><strong>get 的大致流程如下：</strong></p><ol><li><p>通过 hashcode 计算出 key 的 hash 值</p></li><li><p>通过 hash%length 计算出存储在 table 中的 index（源码中是使用 hash&amp;(length-1)，这样结 果相同，但是更快）</p></li><li>遍历 table[index]所在的链表，只有当 key 与该节点中的 key 的值相同时才取出。</li></ol><h2 id="1-3-掌握重点"><a href="#1-3-掌握重点" class="headerlink" title="1.3 掌握重点"></a>1.3 掌握重点</h2><p><strong>List</strong>:  ArrayList,   LinkList</p><p><strong>Set</strong>:   HashSet,    TreeSet</p><ul><li>需要掌握的方法:  add ,   get,    contains</li></ul><p><strong>Map</strong>:  HashMap, TreeMap  </p><ul><li>需要掌握的方法:    put    get    map的循环遍历    containsKey….</li></ul><blockquote><p>以上的都需要跟下源码</p></blockquote><h2 id="1-4-功能方法"><a href="#1-4-功能方法" class="headerlink" title="1.4 功能方法"></a>1.4 功能方法</h2><h4 id="1-4-1-List-的功能方法"><a href="#1-4-1-List-的功能方法" class="headerlink" title="1.4.1 List 的功能方法"></a>1.4.1 List 的功能方法</h4><p><strong>ArrayList</strong>: 由数组实现的 List。允许对元素进行快速随机访问，但是向 List 中间插入与移 除元素的速度很慢。ListIterator 只应该用来由后向前遍历 ArrayList，而不是用来插入和移除 元素。因为那比 LinkedList 开销要大很多。</p><p><strong>LinkedList</strong> : 对顺序访问进行了优化，向 List 中间插入与删除的开销并不大。随机访问则 相对较慢。(使用 ArrayList 代替。)还具有下列方 法：addFirst(), addLast(), getFirst(), getLast(), removeFirst() 和 removeLast(), 这些方法 (没有在任何接口或基类中定义过)使得 LinkedList 可以当作堆栈、队列和双向队列使用。</p><h4 id="1-4-2-Set的功能方法"><a href="#1-4-2-Set的功能方法" class="headerlink" title="1.4.2 Set的功能方法"></a>1.4.2 Set的功能方法</h4><p><strong>Set</strong> : 存入 Set 的每个元素都必须是唯一的，因为 Set 不保存重复元素。加入 Set 的元素 必须定义 equals()方法以确保对象的唯一性。Set 与 Collection 有完全一样的接口。Set 接口 不保证维护元素的次序。</p><p><strong>HashSet</strong> : 为快速查找设计的 Set。存入 HashSet 的对象必须定义 hashCode()。</p><p>TreeSet : 保存次序的 Set，底层为树结构。使用它可以从 Set 中提取有序的序列。</p><p><strong>LinkedHashSet</strong> : 具有 HashSet 的查询速度，且内部使用链表维护元素的顺序(插入的次 序 。于是在使用迭代器遍历 Set 时，结果会按元素插入的次序显示。</p><h4 id="1-4-3-Map-的功能方法"><a href="#1-4-3-Map-的功能方法" class="headerlink" title="1.4.3 Map 的功能方法"></a>1.4.3 Map 的功能方法</h4><p>Map : 维护“键值对”的关联性，使你可以通过“键”查找“值”</p><p><strong>HashMap</strong> : Map 基于散列表的实现。插入和查询“键值对”的开销是固定的。可以通过 构造器设置容量 capacity 和负载因子 load factor，以调整容器的性能。</p><p><strong>LinkedHashMap</strong> : 类似于 HashMap，但是迭代遍历它时，取得“键值对”的顺序是其插 入次序，或者是最近最少使用(LRU)的次序。只比 HashMap 慢一点。而在迭代访问时发而更 快，因为它使用链表维护内部次序。</p><p><strong>TreeMap</strong> : 基于红黑树数据结构的实现。查看“键”或“键值对”时，它们会被排序(次 序由 Comparabel 或 Comparator 决定)。TreeMap 的特点在 于，你得到的结果是经过排序的。 TreeMap 是唯一的带有 subMap()方法的 Map，它可以返回一个子树。</p><p>WeakHashMap : 弱键(weak key)Map，Map 中使用的对象也被允许释放: 这是为解决特 殊问题设计的。如果没有 map 之外的引用指向某个“键”，则此“键”可以被垃圾收集器回 收。</p><p>IdentifyHashMap : 使用==代替 equals()对“键”作比较的 hash map。专为解决特殊问题 而设计。</p><hr><h1 id="2、反射"><a href="#2、反射" class="headerlink" title="2、反射"></a>2、反射</h1><h3 id="2-1-反射"><a href="#2-1-反射" class="headerlink" title="2.1 反射"></a>2.1 反射</h3><p><strong>反射</strong>: 将 Java 类中的各个<strong>成分</strong> (属性, 方法, 构造方法) <strong>映射成对应的类</strong></p><ul><li>在运行时判断任意一个对象的所属的类 Class。</li><li>在运行时判断构造任意一个类的对象 Constructor。</li><li>在运行时判断任意一个类所具有的成员变量 Field 和方法 Method。</li><li>在运行时调用任意一个对象的方法。method.invoke(object, args)</li></ul><p><strong>反射的好处</strong></p><ul><li>提高了整个代码的灵活性</li><li>不需要知道细节</li></ul><p>反射用的最多的时候, 就是写框架的时候</p><p><strong>反射中需要掌握3个类:</strong> </p><ul><li>Constructor: 构造器的描述类</li><li>Field: 属性的描述类</li><li>Method: 方法的描述类</li></ul><p><strong>Java 预定义类型</strong></p><p>是否是预定义类型: <code>isPromitive()</code>,  8种基本数据类型 + void 都是预定义类型</p><p>引用类型, 包装类不是预定义类型.</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">System.out.println(<span class="keyword">int</span>.class.isPrimitive());     <span class="comment">// true</span></span><br><span class="line">System.out.println(Integer.class.isPrimitive()); <span class="comment">// false</span></span><br></pre></td></tr></table></figure><h3 id="2-2-Class"><a href="#2-2-Class" class="headerlink" title="2.2 Class"></a>2.2 Class</h3><p><strong>Class</strong> : 用于<strong>描述所有类的类</strong>,  Class 类描述了类的属性信息，如类名、访问权限、包名、字 段名称列表、方法名称列表等,  <strong>Class就是反射的基础.</strong></p><p><strong>获取Class的3种方式</strong></p><pre><code>1. `Class.forName`(&quot;类名字符串&quot;) (注意：类名字符串必须是全称，包名+类名)- 如果 `.class`已经被加载到内存了, 直接返回- 如果没有的话, 就先加载到内存2. `类名.class`   3. `实例对象.getClass()`</code></pre><h3 id="2-3-Constructor"><a href="#2-3-Constructor" class="headerlink" title="2.3 Constructor"></a>2.3 Constructor</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// API</span></span><br><span class="line"><span class="comment">// 补充: 可变参数  Class&lt;?&gt;... parameterTypes</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> Constructor&lt;T&gt; <span class="title">getConstructor</span><span class="params">(Class&lt;?&gt;... parameterTypes)</span> </span>&#123;&#125;</span><br><span class="line"><span class="keyword">public</span> Constructor&lt;?&gt;[] getConstructors() <span class="keyword">throws</span> SecurityException &#123;&#125; </span><br><span class="line"></span><br><span class="line">================<span class="comment">//使用=============================</span></span><br><span class="line"><span class="comment">////////获取构造方法//////////</span></span><br><span class="line"><span class="comment">// 获取某个类的所有构造方法：</span></span><br><span class="line">Constructor[] constructor = Class.forName(<span class="string">"java.lang.String"</span>).getConstructors();</span><br><span class="line"></span><br><span class="line"><span class="comment">// 获取某个特殊（特定参数）的构造方法：</span></span><br><span class="line">Constructor constructor = Class.forName(<span class="string">"java.lang.String"</span>).getConstructor(StringBuffer.class);</span><br><span class="line"></span><br><span class="line"><span class="comment">////////创建实例对象//////////</span></span><br><span class="line"><span class="comment">// 通常方式，直接调用构造方法：</span></span><br><span class="line">String str = <span class="keyword">new</span> String(<span class="string">"huangbo"</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 反射方式：调用实参构造</span></span><br><span class="line">String str = (String)constructor.newInstance(<span class="keyword">new</span> StringBuffer(<span class="string">"huangbo"</span>));</span><br><span class="line"></span><br><span class="line"><span class="comment">// 反射方式：调用空参构造</span></span><br><span class="line">String obj = (String)Class.forName(<span class="string">"java.lanng.String"</span>).newInstance();</span><br><span class="line"></span><br><span class="line">只有两个类拥有 newInstance()方法，分别是 Class 类和 Constructor 类 </span><br><span class="line">Class 类中的 newInstance() 方法是不带参数的，</span><br><span class="line">Constructor 类中的 newInstance()方法是带参数的(Object)，需要提供 必要的参数</span><br></pre></td></tr></table></figure><h3 id="2-4-Field"><a href="#2-4-Field" class="headerlink" title="2.4 Field"></a>2.4 Field</h3><p><code>Field</code>类代表某个类中的一个成员变量，设有一个 obj 对象，Field 对象不是 obj 具体的变量值， 而是指代的是 obj 所属类的哪一个变量，可以通过 <code>Field(对象).get(obj)</code>获取相应的变量值</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// API</span></span><br><span class="line"><span class="keyword">public</span> Field[] getFields() <span class="keyword">throws</span> SecurityException &#123;&#125;</span><br><span class="line"><span class="function"><span class="keyword">public</span> Field <span class="title">getField</span><span class="params">(String name)</span> </span>&#123;&#125;</span><br><span class="line"></span><br><span class="line">================<span class="comment">//使用=============================</span></span><br><span class="line"><span class="comment">// getField 方法只能获取声明为 public 的变量，对于私有变量，可以通过 getDeclaredField()方法获 取 private 变量</span></span><br><span class="line">Field field = obj.getClass().getDeclaredField();</span><br><span class="line"><span class="comment">// 将 private 变量设置为可访问；继承自父类AccessibleObject 的方法才可获取变量值</span></span><br><span class="line">field.setAccessible(<span class="keyword">true</span>); </span><br><span class="line"><span class="comment">// 获得对象值, 传入对象</span></span><br><span class="line">field.get(obj); </span><br><span class="line"><span class="comment">// 反射替换,设置对象值</span></span><br><span class="line"><span class="comment">// 传入对象,值</span></span><br><span class="line"><span class="comment">// 把 obj 对象的 field 属性的值替换为 newValue</span></span><br><span class="line">field.set(obj,newValue)</span><br></pre></td></tr></table></figure><h3 id="2-5-Method"><a href="#2-5-Method" class="headerlink" title="2.5 Method"></a>2.5 Method</h3><p>Method 类代表某个类中的成员方法</p><p>Method 对象不是具体的方法，而是来代表类中哪一个方法，与对象无关</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 获取: 得到类中某一个方法：</span></span><br><span class="line">Method methodCharAt = Class.forName(<span class="string">"java.lang.String"</span>).getMethod(<span class="string">"charAt"</span>,<span class="keyword">int</span>.class)</span><br><span class="line"></span><br><span class="line"><span class="comment">// getMethod 方法用于得到一个方法对象，该方法接受的参数首先要有该方法名（String 类型），</span></span><br><span class="line"><span class="comment">// 然后通过参数列表来区分重载那个方法，参数类型用 Class 对象来表示(如为 int 就用 int.class)</span></span><br><span class="line">    </span><br><span class="line"><span class="comment">// 调用方法：</span></span><br><span class="line"><span class="comment">//普通方式：</span></span><br><span class="line">str.charAt(<span class="number">1</span>)</span><br><span class="line"><span class="comment">//反射方式：</span></span><br><span class="line">methodCharAt.invoke(str,<span class="number">1</span>)</span><br><span class="line"><span class="comment">// 以上两种调用方式等价</span></span><br></pre></td></tr></table></figure><h1 id="3-设计模式"><a href="#3-设计模式" class="headerlink" title="3. 设计模式"></a>3. 设计模式</h1><p>设计模式（Design pattern）代表了面向对象编程中最佳的实践，通常被有经验的面向对象的 软件开发人员所采用。设计模式是软件开发人员在软件开发过程中面临的一般问题的解决方 案。这些解决方案是众多软件开发人员经过相当长的一段时间的试验和错误总结出来的。</p><p>设计模式只不过针对某些具体场景提供了一些效率较高的以复杂度换灵活性的手段而已</p><p><a href="http://www.runoob.com/design-pattern/design-pattern-tutorial.html" target="_blank" rel="noopener">推荐学习站点</a></p><h3 id="3-1-设计模式-–-六大原则"><a href="#3-1-设计模式-–-六大原则" class="headerlink" title="3.1 设计模式 – 六大原则"></a>3.1 设计模式 – 六大原则</h3><p><strong>总原则：开闭原则</strong>（Open Close Principle）</p><p>开闭原则就是说对扩展开放，对修改关闭。在程序需要进行拓展的时候，不能去修改原有的 代码，而是要扩展原有代码，实现一个热插拔的效果。所以一句话概括就是：为了使程序的 扩展性好，易于维护和升级。想要达到这样的效果，我们需要使用接口和抽象类等，后面的 具体设计中我们会提到这点。</p><p><strong>六大原则：</strong></p><ol><li><p><strong>单一职责原则</strong> </p><p>不要存在多于一个导致类变更的原因，也就是说每个类应该实现单一的职责，如若不然，就 应该把类拆分。</p></li><li><p><strong>里氏替换原则</strong>（Liskov Substitution Principle）</p><p>里氏替换原则中，子类对父类的方法尽量不要重写和重载。因为父类代表了定义好的结构，通过这个规范的接口与外界交互，子类不应该随便破坏它。</p></li><li><p><strong>依赖倒转原则</strong>（Dependence Inversion Principle）</p><p>这个是开闭原则的基础，具体内容：面向接口编程，依赖于抽象而不依赖于具体。写代码 时用到具体类时，不与具体类交互，而与具体类的上层接口交互。</p></li><li><p><strong>接口隔离原则</strong>（Interface Segregation Principle）</p><p>这个原则的意思是：每个接口中不存在子类用不到却必须实现的方法，如果不然，就要将 接口拆分。使用多个隔离的接口，比使用单个接口（多个接口方法集合到一个的接口）要好。</p></li><li><p><strong>迪米特法则</strong>（最少知道原则）（Demeter Principle）</p><p>就是说：一个类对自己依赖的类知道的越少越好 。也就是说无论被依赖的类多么复杂，都 应该将逻辑封装在方法的内部，通过 public 方法提供给外部。这样当被依赖的类变化时，才 能最小的影响该类。</p></li><li><p><strong>合成复用原则</strong>（Composite Reuse Principle）</p><p>原则是尽量首先使用合成/聚合的方式，而不是使用继承。</p></li></ol><h3 id="3-2-设计模式-–-分类"><a href="#3-2-设计模式-–-分类" class="headerlink" title="3.2 设计模式 – 分类"></a>3.2 设计模式 – 分类</h3><p>总体来说设计模式分为三大类：</p><ul><li><strong>创建型模式</strong>，共五种：工厂方法模式、抽象工厂模式、<u><strong>单例模式</strong></u>、建造者模式、原型模式。</li><li><strong>结构型模式</strong>，共七种：适配器模式、<u><strong>装饰器模式</strong></u>、<u><strong>代理模式</strong></u>、外观模式、桥接模式、组合 模式、享元模式。</li><li><strong>行为型模式</strong>，共十一种：策略模式、模板方法模式、观察者模式、迭代子模式、责任链模 式、命令模式、备忘录模式、状态模式、访问者模式、中介者模式、解释器模式。</li></ul><h3 id="3-3-常见设计模式"><a href="#3-3-常见设计模式" class="headerlink" title="3.3 常见设计模式"></a>3.3 常见设计模式</h3><h4 id="3-3-1-单例模式-手写"><a href="#3-3-1-单例模式-手写" class="headerlink" title="3.3.1 单例模式(手写)"></a>3.3.1 单例模式(手写)</h4><p>单例模式（Singleton Pattern）是 Java 中最简单的,也是最最最常用的设计模式之一。这种类 型的设计模式属于创建型模式，它提供了一种创建对象的最佳方式。</p><p>注意: </p><ol><li>单例类只能有一个实例。</li><li>单例类必须自己创建自己的唯一实例。</li><li>单例类必须给所有其他对象提供这一实例。</li></ol><p><strong>共有六种实现：</strong></p><p>1、懒汉式，线程不安全</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Singleton</span> </span>&#123;  </span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> Singleton instance;  </span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="title">Singleton</span> <span class="params">()</span></span>&#123;&#125;  </span><br><span class="line">  </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Singleton <span class="title">getInstance</span><span class="params">()</span> </span>&#123;  </span><br><span class="line">    <span class="keyword">if</span> (instance == <span class="keyword">null</span>) &#123;  </span><br><span class="line">        instance = <span class="keyword">new</span> Singleton();  </span><br><span class="line">    &#125;  </span><br><span class="line">    <span class="keyword">return</span> instance;  </span><br><span class="line">    &#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>2、懒汉式，线程安全</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Singleton</span> </span>&#123;  </span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> Singleton instance;  </span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="title">Singleton</span> <span class="params">()</span></span>&#123;&#125;  </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">synchronized</span> Singleton <span class="title">getInstance</span><span class="params">()</span> </span>&#123;  </span><br><span class="line">    <span class="keyword">if</span> (instance == <span class="keyword">null</span>) &#123;  </span><br><span class="line">        instance = <span class="keyword">new</span> Singleton();  </span><br><span class="line">    &#125;  </span><br><span class="line">    <span class="keyword">return</span> instance;  </span><br><span class="line">    &#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>3、饿汉式</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Singleton</span> </span>&#123;  </span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> Singleton instance = <span class="keyword">new</span> Singleton();  </span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="title">Singleton</span> <span class="params">()</span></span>&#123;&#125;  </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Singleton <span class="title">getInstance</span><span class="params">()</span> </span>&#123;  </span><br><span class="line">    <span class="keyword">return</span> instance;  </span><br><span class="line">    &#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>4、<strong>双检锁/双重校验锁</strong>（DCL，即 double-checked locking） –面试必备</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Singleton</span> </span>&#123;  </span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">volatile</span> <span class="keyword">static</span> Singleton singleton;  </span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="title">Singleton</span> <span class="params">()</span></span>&#123;&#125;  </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Singleton <span class="title">getSingleton</span><span class="params">()</span> </span>&#123;  </span><br><span class="line">    <span class="keyword">if</span> (singleton == <span class="keyword">null</span>) &#123;  </span><br><span class="line">        <span class="keyword">synchronized</span> (Singleton.class) &#123;  </span><br><span class="line">        <span class="keyword">if</span> (singleton == <span class="keyword">null</span>) &#123;  </span><br><span class="line">            singleton = <span class="keyword">new</span> Singleton();  </span><br><span class="line">        &#125;  </span><br><span class="line">        &#125;  </span><br><span class="line">    &#125;  </span><br><span class="line">    <span class="keyword">return</span> singleton;  </span><br><span class="line">    &#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>5、登记式/静态内部类</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Singleton</span> </span>&#123;  </span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">SingletonHolder</span> </span>&#123;  </span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Singleton INSTANCE = <span class="keyword">new</span> Singleton();  </span><br><span class="line">    &#125;  </span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="title">Singleton</span> <span class="params">()</span></span>&#123;&#125;  </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> Singleton <span class="title">getInstance</span><span class="params">()</span> </span>&#123;  </span><br><span class="line">    <span class="keyword">return</span> SingletonHolder.INSTANCE;  </span><br><span class="line">    &#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>6、枚举</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">enum</span> Singleton &#123;  </span><br><span class="line">    INSTANCE;  </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">whateverMethod</span><span class="params">()</span> </span>&#123;  </span><br><span class="line">    &#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><a href="http://www.runoob.com/design-pattern/singleton-pattern.html" target="_blank" rel="noopener">详细请看</a></p><h4 id="3-3-2-装饰器模式-手写"><a href="#3-3-2-装饰器模式-手写" class="headerlink" title="3.3.2 装饰器模式(手写)"></a>3.3.2 装饰器模式(手写)</h4><p><strong>首先看一段代码</strong></p><p><img src="http://p6i5vzkfk.bkt.clouddn.com/study/2018-05-29-085510.jpg" alt=""></p><blockquote><p> <strong>代码分析:</strong> </p><ol><li>构造一个缓冲的字符输入流。包装了一个文件字符输入流。</li><li>事实上，BufferedReader 就是用来<strong>增强</strong> FileReader 的读取的功能的。</li><li>FileReader 只有 read()方法， 但是 BufferedReader 中却增加了一个 readLine()的逐行读取 的功能</li><li>所以这就相当于是 BufferedReader 装饰了 FileReader，让 FileReader 变得更强大</li></ol></blockquote><h5 id="装饰器模式概念"><a href="#装饰器模式概念" class="headerlink" title="装饰器模式概念"></a>装饰器模式概念</h5><ul><li>装饰器模式（Decorator Pattern）允许向一个现有的对象添加新的功能，同时又不改变其结 构。这种类型的设计模式属于结构型模式，它是作为现有的类的一个包装。</li><li>这种模式创建了一个装饰类，用来包装原有的类，并在保持类方法签名完整性的前提下， 提供了额外的功能。</li></ul><h5 id="装饰器模式实现方式"><a href="#装饰器模式实现方式" class="headerlink" title="装饰器模式实现方式"></a>装饰器模式实现方式</h5><pre><code>1. 定义包装类 2. 将要装饰的模式作为参数传入包装类 3. 实现要加强的方法</code></pre><h4 id="3-3-2-代理模式"><a href="#3-3-2-代理模式" class="headerlink" title="3.3.2 代理模式"></a>3.3.2 代理模式</h4><h5 id="1-静态代理"><a href="#1-静态代理" class="headerlink" title="1. 静态代理"></a>1. 静态代理</h5><p>静态代理的缺点很明显：一个代理类只能对一个业务接口的实现类进行包装，如果有多个业 务接口的话就要定义很多实现类和代理类才行。</p><p>…</p><h5 id="2-动态代理"><a href="#2-动态代理" class="headerlink" title="2. 动态代理"></a>2. 动态代理</h5><p><strong>第一种：JDK 动态代理实现</strong></p><p>JDK 动态代理所用到的代理类在程序调用到代理类对象时才由 JVM 真正创建，JVM 根据传 进来的业务实现类对象以及方法名，动态地创建了一个代理类的 class 文件并被字节码引擎 执行，然后通过该代理类对象进行方法调用。我们需要做的，只需指定代理类的预处理、 调用后操作即可。</p><p><strong>只能对实现了接口的类生成代理</strong>，<strong>而不是针对类</strong>，该目标类型实现的接口都将被代理。原理 是通过在运行期间创建一个接口的实现类来完成对目标对象的代理。<strong>具体实现步骤：</strong></p><ol><li>定义一个实现接口 <code>InvocationHandler</code> 的类</li><li>通过构造函数或者静态工厂方法等，注入被代理类</li><li>实现 <code>invoke(Object proxy, Method method, Object[] args)</code>方法</li><li>在主函数中获得被代理类的类加载器</li><li>使用 <code>Proxy.newProxyInstance(classLoader, interfaces, args)</code>产生一个代理对象</li><li>通过代理对象调用各种方法</li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line">=============<span class="comment">//实现InvocationHandler====================</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.lang.reflect.InvocationHandler;</span><br><span class="line"><span class="keyword">import</span> java.lang.reflect.Method;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> shixuanji</span></span><br><span class="line"><span class="comment"> * 动态代理: JDK</span></span><br><span class="line"><span class="comment"> * 1. 实现一个接口 InvocationHandler</span></span><br><span class="line"><span class="comment"> * 2. 将代理对象作为属性传入  代理所有的类</span></span><br><span class="line"><span class="comment"> * 3. 重写 invoke()方法</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ProxyDynamicStudentDao</span> <span class="keyword">implements</span> <span class="title">InvocationHandler</span> </span>&#123;</span><br><span class="line"><span class="keyword">private</span> Object o;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">ProxyDynamicStudentDao</span><span class="params">(Object o)</span> </span>&#123;</span><br><span class="line"><span class="keyword">this</span>.o = o;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">/* </span></span><br><span class="line"><span class="comment"> *  @param proxy:  代理对象, 基本不用 ???应该是代理对象把, 老师写的被代理对象</span></span><br><span class="line"><span class="comment"> *  @param method: 拦截下来的被代理对象的方法 - 反射中描述方法的类</span></span><br><span class="line"><span class="comment"> *  @param args:   被代理对象业务方法的参数</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> Object <span class="title">invoke</span><span class="params">(Object proxy, Method method, Object[] args)</span></span></span><br><span class="line"><span class="function"><span class="keyword">throws</span> Throwable </span>&#123;</span><br><span class="line"></span><br><span class="line">String methodName = method.getName().toString();</span><br><span class="line"><span class="keyword">if</span> (methodName.equals(<span class="string">"insert"</span>)) &#123;</span><br><span class="line"><span class="comment">// xxx</span></span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line"><span class="comment">//ssssss</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 做的事情就是对代理方法的方法的增强</span></span><br><span class="line"><span class="comment">// 增强</span></span><br><span class="line">System.out.println(<span class="string">"开始执行"</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 业务方法调用, 一定要调用被代理对象的</span></span><br><span class="line"><span class="comment">// obj: 对象  </span></span><br><span class="line"><span class="comment">// args:方法的参数</span></span><br><span class="line">Object res = method.invoke(o, args);</span><br><span class="line"><span class="comment">// 增强</span></span><br><span class="line">System.out.println(<span class="string">"执行完了"</span>);</span><br><span class="line"><span class="keyword">return</span> res;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">============== <span class="comment">// 使用========================</span></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">* 参数1: 被代理对象的类加载器   </span></span><br><span class="line"><span class="comment">* 参数2: 要实现的接口</span></span><br><span class="line"><span class="comment">* 参数3: 代理类对象 </span></span><br><span class="line"><span class="comment">* </span></span><br><span class="line"><span class="comment">* 能.出来什么看 左边接收着</span></span><br><span class="line"><span class="comment">* 运行时看 真正创建的对象</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="comment">// 目前看来 代理实例只能是接口</span></span><br><span class="line">BaseDAO newProxyInstance = (BaseDAO)Proxy.newProxyInstance(StudentDAO.class.getClassLoader(), </span><br><span class="line">StudentDAO.class.getInterfaces()</span><br><span class="line">, <span class="keyword">new</span> ProxyDynamicStudentDao(<span class="keyword">new</span> StudentDAO()));</span><br><span class="line">newProxyInstance.insert(<span class="keyword">new</span> Teacher());</span><br></pre></td></tr></table></figure><p><strong>第二种：CGLIB 动态代理实现：</strong></p><p><strong>CGLIB 是针对类来实现代理的</strong>，<strong>原理是对指定的业务类生成一个子类，并覆盖其中业务方法 实现代理</strong>。因为采用的是<strong>继承</strong>，所以不能对 final 修饰的类进行代理，final 的方法也不能</p><p>针对类实现代理，对是否实现接口无要求。原理是对指定的类生成一个子类，覆盖其中的方 法，因为是继承，所以被代理的类或方法最好不要声明为 final 类型。<strong>具体实现步骤</strong>：</p><p>1、定义一个实现了 <code>MethodInterceptor</code> 接口的类</p><p>2、实现其 <code>intercept()</code>方法，在其中调用 <code>proxy.invokeSuper()</code></p><h5 id="3-静态代理和动态代理的区别"><a href="#3-静态代理和动态代理的区别" class="headerlink" title="3. 静态代理和动态代理的区别"></a>3. 静态代理和动态代理的区别</h5><p>静态代理：自己编写创建代理类，然后再进行编译，在程序运行前，代理类的.class 文件就 已经存在了。</p><p>动态代理：在实现阶段不用关心代理谁，而在运行阶段（通过反射机制）才指定代理哪一个 对象。</p><h3 id="3-4-重点掌握"><a href="#3-4-重点掌握" class="headerlink" title="3.4 重点掌握"></a>3.4 重点掌握</h3><h4 id="3-4-1-装饰者模式-和-静态代理模式-区别"><a href="#3-4-1-装饰者模式-和-静态代理模式-区别" class="headerlink" title="3.4.1. 装饰者模式 和 静态代理模式 区别"></a>3.4.1. 装饰者模式 和 静态代理模式 区别</h4><p>在代码上的区别:</p><ul><li>一般情况下, 装饰者模式被装饰的对象一般是从外部传入, 装饰的是一类的事务, 只要是某一类的(Class)都可以</li><li>静态代理模式被代理对象的初始化一般是内部创建的, 代理的是一个类的对象.</li></ul><p>从功能上: </p><ul><li>装饰者模式, 用于对被装饰者业务逻辑实现或增强, 对方法名没有要求</li><li>静态代理: 主要用于权限控制, 日志打印, 错误预警等功能</li></ul><h4 id="3-4-2-三种设计模式必须掌握的"><a href="#3-4-2-三种设计模式必须掌握的" class="headerlink" title="3.4.2. 三种设计模式必须掌握的"></a>3.4.2. 三种设计模式必须掌握的</h4><ul><li>单例设计模式</li><li>装饰者模式</li><li>动态代理模式</li></ul><h4 id="3-4-3-手写代码"><a href="#3-4-3-手写代码" class="headerlink" title="3.4.3. 手写代码"></a>3.4.3. 手写代码</h4><ul><li>冒泡排序</li><li>快速排序</li><li>设计模式</li><li>hadoop 的 wordcount</li><li>scala 的 wordcount</li><li>spark 的 wordcount</li></ul><h1 id="4-排序算法"><a href="#4-排序算法" class="headerlink" title="4.  排序算法"></a>4.  排序算法</h1><blockquote><p>核心概念：<strong>算法复杂度、稳定性</strong></p><p><strong>算法复杂度</strong>：算法复杂度是指算法在编写成可执行程序后，运行时所需要的资源，资源包括 时间资源和内存资源。应用于数学和计算机导论。</p><p><strong>稳定性</strong>：一个排序算法是稳定的，就是当有两个相等记录的关键字 R 和 S，且在原本的列表 中 R 出现在 S 之前，在排序过的列表中 R 也将会是在 S 之前。</p></blockquote><h3 id="4-1-排序分类"><a href="#4-1-排序分类" class="headerlink" title="4.1.  排序分类"></a>4.1.  排序分类</h3><p><strong>按照排序结果是否稳定性分类：</strong></p><ol><li>稳定排序：插入排序，<strong>冒泡排序</strong>，<strong>归并排序</strong>，计数排序，基数排序，桶排序（如果桶内 排序采用的是稳定性排序）</li><li>非稳定排序：选择排序，<strong>快速排序</strong>，堆排序。</li></ol><p><strong>按照排序过程中是否需要额外空间：</strong></p><ol><li>原地排序：插入排序，选择排序，冒泡排序，快速排序，堆排序。</li><li>非原地排序：归并排序，计数排序，基数排序，桶排序。</li></ol><p><strong>按照排序的主要操作分类：</strong></p><ol><li>交换类：冒泡排序、快速排序；此类的特点是通过不断的比较和交换进行排序；</li><li>插入类：简单插入排序、希尔排序；此类的特点是通过插入的手段进行排序；</li><li>选择类：简单选择排序、堆排序；此类的特点是看准了再移动；</li><li>归并类：归并排序；此类的特点是先分割后合并；</li></ol><p><strong>按照是否需要比较分类：</strong></p><ol><li>比较排序，时间复杂度 O(nlogn) ~ O(n^2)，主要有：冒泡排序，选择排序，插入排序， 归并排序，堆排序，快速排序等。</li><li>非比较排序，时间复杂度可以达到 O(n)，主要有：计数排序，基数排序，桶排序等。</li></ol><h3 id="4-2-常见排序的时间复杂度"><a href="#4-2-常见排序的时间复杂度" class="headerlink" title="4.2 常见排序的时间复杂度"></a>4.2 常见排序的时间复杂度</h3><p><img src="http://p6i5vzkfk.bkt.clouddn.com/study/2018-05-30-235952.jpg" alt="Attachment.jpeg"> </p><p><a href="http://v.youku.com/v_show/id_XNjkzODY2NjMy.html" target="_blank" rel="noopener">有趣的排序算法视频</a></p><h3 id="4-3-常见排序算法的核心实现"><a href="#4-3-常见排序算法的核心实现" class="headerlink" title="4.3 常见排序算法的核心实现"></a>4.3 常见排序算法的核心实现</h3><p>4.3.1 冒泡排序</p><p>4.3.2 归并排序</p><p>4.3.3 快速排序</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;1、集合框架&quot;&gt;&lt;a href=&quot;#1、集合框架&quot; class=&quot;headerlink&quot; title=&quot;1、集合框架&quot;&gt;&lt;/a&gt;1、集合框架&lt;/h1&gt;&lt;h2 id=&quot;1-1-、集合框架体系图&quot;&gt;&lt;a href=&quot;#1-1-、集合框架体系图&quot; class=&quot;head
      
    
    </summary>
    
      <category term="Java" scheme="https://airpoet.github.io/categories/Java/"/>
    
      <category term="学习笔记" scheme="https://airpoet.github.io/categories/Java/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="原创" scheme="https://airpoet.github.io/tags/%E5%8E%9F%E5%88%9B/"/>
    
      <category term="技术" scheme="https://airpoet.github.io/tags/%E6%8A%80%E6%9C%AF/"/>
    
      <category term="Java" scheme="https://airpoet.github.io/tags/Java/"/>
    
  </entry>
  
  <entry>
    <title>Linux学习笔记-5</title>
    <link href="https://airpoet.github.io/2018/05/28/Linux/Linux%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-5/"/>
    <id>https://airpoet.github.io/2018/05/28/Linux/Linux学习笔记-5/</id>
    <published>2018-05-28T01:27:24.977Z</published>
    <updated>2018-05-29T12:39:44.979Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-Shell操作日期时间"><a href="#1-Shell操作日期时间" class="headerlink" title="1.Shell操作日期时间"></a>1.Shell操作日期时间</h1><h2 id="date"><a href="#date" class="headerlink" title="date"></a>date</h2><p>在类UNIX系统中，日期被存储为一个整数，其大小为自世界标准时间（UTC）1970年1月1日0时0分0秒起流逝的秒数。</p><ol><li><p><strong>语法</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">date(选项)(参数)</span><br></pre></td></tr></table></figure></li><li><p><strong>选项</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">-d&lt;字符串&gt;：显示字符串所指的日期与时间。字符串前后必须加上双引号；</span><br><span class="line">-s&lt;字符串&gt;：根据字符串来设置日期与时间。字符串前后必须加上双引号；</span><br><span class="line">-u：显示GMT, 即目前的格林威治时间；</span><br><span class="line">--<span class="built_in">help</span>：在线帮助；</span><br><span class="line">--version：显示版本信息。</span><br></pre></td></tr></table></figure></li><li><p><strong>参数</strong></p><p>&lt;+时间日期格式&gt;：指定显示时使用的日期时间格式。</p></li><li><p><strong>日期格式字符串列表</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">%r 时间，12小时制</span><br><span class="line">%s 从1970年1月1日0点到目前经历的秒数</span><br><span class="line">%S 秒（00～59） </span><br><span class="line">%T 时间（24小时制）（hh:mm:ss）</span><br><span class="line">%X 显示时间的格式（％H时％M分％S秒）</span><br><span class="line">%Z 按字母表排序的时区缩写</span><br><span class="line">%a 星期名缩写</span><br><span class="line">%A 星期名全称</span><br><span class="line">%b 月名缩写</span><br><span class="line">%B 月名全称</span><br><span class="line">%c 日期和时间</span><br><span class="line">%d 按月计的日期（01～31）</span><br><span class="line">%D 日期（mm/dd/yy） </span><br><span class="line">%h 和%b选项相同</span><br><span class="line">%j 一年的第几天（001~366）</span><br><span class="line">%m 月份（01～12）</span><br><span class="line">%w 一个星期的第几天（0代表星期天）</span><br><span class="line">%W 一年的第几个星期（00～53，星期一为第一天）</span><br><span class="line">%x 显示日期的格式（mm/dd/yy）</span><br><span class="line">%y 年份的最后两个数字（1999则是99）</span><br><span class="line">%Y 年份（比如1970、1996等）</span><br><span class="line">%C   世纪，通常为省略当前年份的后两位数字</span><br><span class="line">%U  一年中的第几周，以周日为每星期第一天</span><br><span class="line">%e   按月计的日期，添加空格，等于%_d</span><br></pre></td></tr></table></figure></li><li><p>实例</p><p>格式化输出</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">date +<span class="string">"%Y-%m-%d"</span></span><br><span class="line">2009-12-07</span><br></pre></td></tr></table></figure><p>输出昨天日期：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">date -d <span class="string">"1 day ago"</span> +<span class="string">"%Y-%m-%d"</span></span><br><span class="line">2012-11-19</span><br></pre></td></tr></table></figure><p>2秒后输出：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">date -d <span class="string">"2 second"</span> +<span class="string">"%Y-%m-%d %H:%M.%S"</span></span><br><span class="line">2012-11-20 14:21.31</span><br></pre></td></tr></table></figure><p>传说中的 1234567890 秒：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">date -d <span class="string">"1970-01-01 1234567890 seconds"</span> +<span class="string">"%Y-%m-%d %H:%m:%S"</span></span><br><span class="line">2009-02-13 23:02:30</span><br></pre></td></tr></table></figure><p>普通转格式：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">date -d <span class="string">"2009-12-12"</span> +<span class="string">"%Y/%m/%d %H:%M.%S"</span></span><br><span class="line">2009/12/12 00:00.00</span><br></pre></td></tr></table></figure><p>apache格式转换：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">date -d <span class="string">"Dec 5, 2009 12:00:37 AM"</span> +<span class="string">"%Y-%m-%d %H:%M.%S"</span></span><br><span class="line">2009-12-05 00:00.37</span><br></pre></td></tr></table></figure><p>格式转换后时间游走：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">date -d <span class="string">"Dec 5, 2009 12:00:37 AM 2 year ago"</span> +<span class="string">"%Y-%m-%d %H:%M.%S"</span></span><br><span class="line">2007-12-05 00:00.37</span><br></pre></td></tr></table></figure><p>加减操作：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">date +%Y%m%d                   //显示前天年月日</span><br><span class="line">date -d <span class="string">"+1 day"</span> +%Y%m%d       //显示前一天的日期</span><br><span class="line">date -d <span class="string">"-1 day"</span> +%Y%m%d       //显示后一天的日期</span><br><span class="line">date -d <span class="string">"-1 month"</span> +%Y%m%d     //显示上一月的日期</span><br><span class="line">date -d <span class="string">"+1 month"</span> +%Y%m%d     //显示下一月的日期</span><br><span class="line">date -d <span class="string">"-1 year"</span> +%Y%m%d      //显示前一年的日期</span><br><span class="line">date -d <span class="string">"+1 year"</span> +%Y%m%d      //显示下一年的日期</span><br></pre></td></tr></table></figure><p>设定时间：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">date -s                        //设置当前时间，只有root权限才能设置，其他只能查看</span><br><span class="line">date -s 20120523               //设置成20120523，这样会把具体时间设置成空00:00:00</span><br><span class="line">date -s 01:01:01               //设置具体时间，不会对日期做更改</span><br><span class="line">date -s <span class="string">"01:01:01 2012-05-23"</span>  //这样可以设置全部时间</span><br><span class="line">date -s <span class="string">"01:01:01 20120523"</span>    //这样可以设置全部时间</span><br><span class="line">date -s <span class="string">"2012-05-23 01:01:01"</span>  //这样可以设置全部时间</span><br><span class="line">date -s <span class="string">"20120523 01:01:01"</span>    //这样可以设置全部时间</span><br></pre></td></tr></table></figure><p>有时需要检查一组命令花费的时间，举例：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"></span><br><span class="line">start=$(date +%s)</span><br><span class="line">nmap man.linuxde.net &amp;&gt; /dev/null</span><br><span class="line"></span><br><span class="line">end=$(date +%s)</span><br><span class="line">difference=$(( end - start ))</span><br><span class="line"><span class="built_in">echo</span> <span class="variable">$difference</span> seconds.</span><br></pre></td></tr></table></figure><p>计算活了多少年</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">echo</span> $[($(date +%s -d $[date])-$(date +%s -d <span class="string">"19900318"</span>))/86400/365]</span><br></pre></td></tr></table></figure></li><li><p><strong><code>date -d</code>其它的一些用法.</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## 获取下一天的时间</span></span><br><span class="line">[root@hadoop ~]<span class="comment"># date -d next-day '+%Y-%m-%d %H:%M:%S'</span></span><br><span class="line">[root@hadoop ~]<span class="comment"># date -d 'next day' '+%Y-%m-%d %H:%M:%S'</span></span><br><span class="line">另外一种写法：</span><br><span class="line">[root@hadoop ~]<span class="comment"># date '+%Y-%m-%d %H:%M:%S' -d tomorrow</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## 获取上一天的时间</span></span><br><span class="line">[root@hadoop ~]<span class="comment"># date -d last-day '+%Y-%m-%d %H:%M:%S'</span></span><br><span class="line">另外一种写法：</span><br><span class="line">[root@hadoop ~]<span class="comment"># date '+%Y-%m-%d %H:%M:%S' -d yesterday</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## 获取下一月的时间</span></span><br><span class="line">[root@hadoop ~]<span class="comment"># date -d next-month '+%Y-%m-%d %H:%M:%S'</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## 获取上一月的时间</span></span><br><span class="line">[root@hadoop ~]<span class="comment"># date -d last-month '+%Y-%m-%d %H:%M:%S'</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## 获取下一年的时间</span></span><br><span class="line">[root@hadoop ~]<span class="comment"># date -d next-year '+%Y-%m-%d %H:%M:%S'</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## 获取上一年的时间</span></span><br><span class="line">[root@hadoop ~]<span class="comment"># date -d last-year '+%Y-%m-%d %H:%M:%S'</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## 获取上一周的日期时间：</span></span><br><span class="line">[root@hadoop ~]<span class="comment"># date -d next-week '+%Y-%m-%d %H:%M:%S'</span></span><br><span class="line">[root@hadoop ~]<span class="comment"># date -d next-monday '+%Y-%m-%d %H:%M:%S'</span></span><br><span class="line">[root@hadoop ~]<span class="comment"># date -d next-thursday '+%Y-%m-%d %H:%M:%S'</span></span><br></pre></td></tr></table></figure><p>那么类似的，其实，last-year，last-month，last-day，last-week，last-hour，last-minute，last-second都有对应的实现。相反的，last对应next，自己可以根据实际情况灵活组织 </p></li><li><p><strong>接下来，我们来看</strong>‘–date’，<strong>它帮我实现任意时间前后的计算，来看具体的例子：</strong> </p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## 获取一天以后的日期时间</span></span><br><span class="line">[root@hadoop ~]<span class="comment"># date '+%Y-%m-%d %H:%M:%S' --date='1 day'</span></span><br><span class="line">[root@hadoop ~]<span class="comment"># date '+%Y-%m-%d %H:%M:%S' --date='-1 day ago'</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## 获取一天以前的日期时间</span></span><br><span class="line">[root@hadoop ~]<span class="comment"># date '+%Y-%m-%d %H:%M:%S' --date='-1 day'</span></span><br><span class="line">[root@hadoop ~]<span class="comment"># date '+%Y-%m-%d %H:%M:%S' --date='1 day ago'</span></span><br></pre></td></tr></table></figure><p>上面的例子显示出来了使用的格式，使用精髓在于改变前面的字符串显示格式，改变数据，改变要操作的日期对应字段，除了天也有对应的其他实现：year，month，week，day，hour，minute，second，monday（星期，七天都可） </p></li><li><p>date 能用来显示或设定系统的日期和时间，在显示方面，使用者能设定欲显示的格式，格式设定为一个<strong>加号</strong>后接数个标记，其中可用的标记列表如下：</p><p>使用范例：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop ~]<span class="comment"># date '+%Y-%m-%d %H:%M:%S'</span></span><br></pre></td></tr></table></figure><p><strong>日期方面</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">%a : 星期几 (Sun..Sat) </span><br><span class="line">%A : 星期几 (Sunday..Saturday) </span><br><span class="line">%b : 月份 (Jan..Dec) </span><br><span class="line">%B : 月份 (January..December) </span><br><span class="line">%c : 直接显示日期和时间 </span><br><span class="line">%d : 日 (01..31) </span><br><span class="line">%D : 直接显示日期 (mm/dd/yy) </span><br><span class="line">%h : 同 %b </span><br><span class="line">%j : 一年中的第几天 (001..366) </span><br><span class="line">%m : 月份 (01..12) </span><br><span class="line">%U : 一年中的第几周 (00..53) (以 Sunday 为一周的第一天的情形) </span><br><span class="line">%w : 一周中的第几天 (0..6) </span><br><span class="line">%W : 一年中的第几周 (00..53) (以 Monday 为一周的第一天的情形) </span><br><span class="line">%x : 直接显示日期 (mm/dd/yyyy) </span><br><span class="line">%y : 年份的最后两位数字 (00.99) </span><br><span class="line">%Y : 完整年份 (0000..9999)</span><br></pre></td></tr></table></figure><p><strong>时间方面</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">%%: 打印出%</span><br><span class="line">%n : 下一行</span><br><span class="line">%t : 跳格</span><br><span class="line">%H : 小时(00..23)</span><br><span class="line">%k : 小时(0..23)</span><br><span class="line">%l : 小时(1..12)</span><br><span class="line">%M : 分钟(00..59)</span><br><span class="line">%p : 显示本地AM或PM</span><br><span class="line">%P : 显示本地am或pm</span><br><span class="line">%r : 直接显示时间(12 小时制，格式为 hh:mm:ss [AP]M)</span><br><span class="line">%s : 从 1970 年 1 月 1 日 00:00:00 UTC 到目前为止的秒数</span><br><span class="line">%S : 秒(00..61)</span><br><span class="line">%T : 直接显示时间(24小时制)</span><br><span class="line">%X : 相当于%H:%M:%S %p</span><br><span class="line">%Z : 显示时区</span><br></pre></td></tr></table></figure></li><li><p>若是不以加号作为开头，则表示要设定时间，而时间格式为 <code>MMDDhhmm[[CC]YY][.ss]</code></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">MM 为月份， </span><br><span class="line">DD 为日，</span><br><span class="line">hh 为小时，</span><br><span class="line">mm 为分钟，</span><br><span class="line">CC 为年份前两位数字，</span><br><span class="line">YY 为年份后两位数字，</span><br><span class="line">ss 为秒数</span><br></pre></td></tr></table></figure></li><li><h4 id="有用的小技巧"><a href="#有用的小技巧" class="headerlink" title="有用的小技巧"></a>有用的小技巧</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## 获取相对某个日期前后的日期：</span></span><br><span class="line">cts1 ~ <span class="comment"># date -d 'may 14 -2 weeks'</span></span><br><span class="line">2018年 04月 30日 星期一 00:00:00 CST</span><br><span class="line"></span><br><span class="line"><span class="comment">## 把时间当中无用的0去掉，比如：01:02:25会变成1:2:25</span></span><br><span class="line">cts1 ~ <span class="comment"># date '+%-H:%-M:%-S'</span></span><br><span class="line">19:18:22</span><br><span class="line"></span><br><span class="line"><span class="comment">## 显示文件最后被更改的时间</span></span><br><span class="line">cts1 ~ <span class="comment"># date "+%Y-%m-%d %H:%M:%S" -r install.log</span></span><br><span class="line">2018-05-23 10:11:14</span><br><span class="line"></span><br><span class="line"><span class="comment">## 求两个字符串日期之间相隔的天数</span></span><br><span class="line">[root@hadoop ~]<span class="comment"># </span></span><br><span class="line">expr <span class="string">'('</span> $(date +%s -d <span class="string">"2016-08-08"</span>) - $(date +%s -d <span class="string">"2016-09-09"</span>) <span class="string">')'</span> / 86400</span><br><span class="line">expr `expr $(date +%s -d <span class="string">"2016-08-08"</span>) - $(date +%s -d <span class="string">"2016-09-09"</span>)` / 86400</span><br><span class="line"></span><br><span class="line"><span class="comment">## shell中加减指定间隔单位</span></span><br><span class="line">cts1 ~ <span class="comment">#  A=`date +%Y-%m-%d`</span></span><br><span class="line">cts1 ~ <span class="comment"># B=`date +%Y-%m-%d -d "$A +48 hours"`</span></span><br><span class="line">cts1 ~ <span class="comment"># echo $B</span></span><br><span class="line">2018-05-30</span><br></pre></td></tr></table></figure></li></ol><h1 id="2-文本处理"><a href="#2-文本处理" class="headerlink" title="2. 文本处理"></a>2. 文本处理</h1><h2 id="wc"><a href="#wc" class="headerlink" title="wc"></a>wc</h2><p>功能： 统计文件行数、字节、字符数 </p><h3 id="选项"><a href="#选项" class="headerlink" title="选项"></a>选项</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">-c <span class="comment"># 统计字节数，或--bytes或——chars：只显示Bytes数；。</span></span><br><span class="line">-l <span class="comment"># 统计行数，或——lines：只显示列数；。</span></span><br><span class="line">-m <span class="comment"># 统计字符数。这个标志不能与 -c 标志一起使用。</span></span><br><span class="line">-w <span class="comment"># 统计字数，或——words：只显示字数。一个字被定义为由空白、跳格或换行字符分隔的字符串。</span></span><br><span class="line">-L <span class="comment"># 打印最长行的长度。</span></span><br><span class="line">-<span class="built_in">help</span>     <span class="comment"># 显示帮助信息</span></span><br><span class="line">--version <span class="comment"># 显示版本信息</span></span><br></pre></td></tr></table></figure><h3 id="例子"><a href="#例子" class="headerlink" title="例子"></a>例子</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">wc -l *       <span class="comment"># 统计当前目录下的所有文件行数</span></span><br><span class="line">wc -l *.js    <span class="comment"># 统计当前目录下的所有 .js 后缀的文件行数</span></span><br><span class="line">find  . * | xargs wc -l <span class="comment"># 当前目录以及子目录的所有文件行数 </span></span><br><span class="line">wc test.txt   <span class="comment"># 查看文件的字节数、字数、行数</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看文件的字节数、字数、行数</span></span><br><span class="line">wc test.txt</span><br><span class="line"><span class="comment"># 输出结果</span></span><br><span class="line">7     8     70     test.txt</span><br><span class="line">行数 单词数 字节数   文件名</span><br><span class="line"></span><br><span class="line"><span class="comment"># 用wc命令只打印统计文件行数不打印文件名</span></span><br><span class="line">wc -l test.txt </span><br><span class="line"><span class="comment"># 输出结果</span></span><br><span class="line">7 test.txt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 用来统计当前目录下的文件数</span></span><br><span class="line">ls -l | wc -l</span><br><span class="line"><span class="comment"># 输出结果</span></span><br><span class="line">8</span><br><span class="line"></span><br><span class="line"><span class="comment"># 统计文件字数：</span></span><br><span class="line">cts1 ~ <span class="comment"># wc -w date.txt</span></span><br><span class="line">30 date.txt</span><br></pre></td></tr></table></figure><h2 id="sort"><a href="#sort" class="headerlink" title="sort"></a>sort</h2><p><strong>sort命令</strong> 是在Linux里非常有用，它将文件进行排序，并将排序结果标准输出。sort命令既可以从特定的文件，也可以从stdin中获取输入。</p><h4 id="选项-1"><a href="#选项-1" class="headerlink" title="选项"></a>选项</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">-b：忽略每行前面开始出的空格字符；</span><br><span class="line">-c：检查文件是否已经按照顺序排序；</span><br><span class="line">-d：排序时，处理英文字母、数字及空格字符外，忽略其他的字符；</span><br><span class="line">-f：排序时，将小写字母视为大写字母；</span><br><span class="line">-i：排序时，除了040至176之间的ASCII字符外，忽略其他的字符；</span><br><span class="line">-m：将几个排序号的文件进行合并；</span><br><span class="line">-M：将前面3个字母依照月份的缩写进行排序；</span><br><span class="line">-n：依照数值的大小排序；</span><br><span class="line">-o&lt;输出文件&gt;：将排序后的结果存入制定的文件；</span><br><span class="line">-r：以相反的顺序来排序；</span><br><span class="line">-t&lt;分隔字符&gt;：指定排序时所用的栏位分隔字符；</span><br><span class="line">-g：按照常规数值排序</span><br><span class="line">-k：位置1,位置2根据关键字排序，在从第位置1开始，位置2结束</span><br><span class="line"></span><br><span class="line">+&lt;起始栏位&gt;-&lt;结束栏位&gt;：以指定的栏位来排序，范围由起始栏位到结束栏位的前一栏位。</span><br></pre></td></tr></table></figure><h4 id="实例"><a href="#实例" class="headerlink" title="实例"></a>实例</h4><ol><li><p>sort将文件/文本的每一行作为一个单位，相互比较，比较原则是从首字符向后，依次按ASCII码值进行比较，最后将他们按升序输出。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">root@[mail text]<span class="comment"># cat sort.txt</span></span><br><span class="line">aaa:10:1.1</span><br><span class="line">ccc:30:3.3</span><br><span class="line">ddd:40:4.4</span><br><span class="line">bbb:20:2.2</span><br><span class="line">eee:50:5.5</span><br><span class="line">eee:50:5.5</span><br><span class="line"></span><br><span class="line">[root@mail text]<span class="comment"># sort sort.txt</span></span><br><span class="line">aaa:10:1.1</span><br><span class="line">bbb:20:2.2</span><br><span class="line">ccc:30:3.3</span><br><span class="line">ddd:40:4.4</span><br><span class="line">eee:50:5.5</span><br><span class="line">eee:50:5.5</span><br></pre></td></tr></table></figure></li><li><p>忽略相同行使用-u选项或者uniq：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">[root@mail text]<span class="comment"># cat sort.txt</span></span><br><span class="line">aaa:10:1.1</span><br><span class="line">ccc:30:3.3</span><br><span class="line">ddd:40:4.4</span><br><span class="line">bbb:20:2.2</span><br><span class="line">eee:50:5.5</span><br><span class="line">eee:50:5.5</span><br><span class="line"></span><br><span class="line">[root@mail text]<span class="comment"># sort -u sort.txt</span></span><br><span class="line">aaa:10:1.1</span><br><span class="line">bbb:20:2.2</span><br><span class="line">ccc:30:3.3</span><br><span class="line">ddd:40:4.4</span><br><span class="line">eee:50:5.5</span><br><span class="line"></span><br><span class="line">或者</span><br><span class="line"></span><br><span class="line">[root@mail text]<span class="comment"># uniq sort.txt</span></span><br><span class="line">aaa:10:1.1</span><br><span class="line">ccc:30:3.3</span><br><span class="line">ddd:40:4.4</span><br><span class="line">bbb:20:2.2</span><br><span class="line">eee:50:5.5</span><br></pre></td></tr></table></figure></li><li><p>sort的-n、-r、-k、-t选项的使用：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">[root@mail text]<span class="comment"># cat sort.txt</span></span><br><span class="line">AAA:BB:CC</span><br><span class="line">aaa:30:1.6</span><br><span class="line">ccc:50:3.3</span><br><span class="line">ddd:20:4.2</span><br><span class="line">bbb:10:2.5</span><br><span class="line">eee:40:5.4</span><br><span class="line">eee:60:5.1</span><br><span class="line"></span><br><span class="line"><span class="comment">#将BB列按照数字从小到大顺序排列：</span></span><br><span class="line">[root@mail text]<span class="comment"># sort -nk 2 -t: sort.txt</span></span><br><span class="line">AAA:BB:CC</span><br><span class="line">bbb:10:2.5</span><br><span class="line">ddd:20:4.2</span><br><span class="line">aaa:30:1.6</span><br><span class="line">eee:40:5.4</span><br><span class="line">ccc:50:3.3</span><br><span class="line">eee:60:5.1</span><br><span class="line"></span><br><span class="line"><span class="comment">#将CC列数字从大到小顺序排列：</span></span><br><span class="line">[root@mail text]<span class="comment"># sort -nrk 3 -t: sort.txt</span></span><br><span class="line">eee:40:5.4</span><br><span class="line">eee:60:5.1</span><br><span class="line">ddd:20:4.2</span><br><span class="line">ccc:50:3.3</span><br><span class="line">bbb:10:2.5</span><br><span class="line">aaa:30:1.6</span><br><span class="line">AAA:BB:CC</span><br><span class="line"></span><br><span class="line"><span class="comment"># -n是按照数字大小排序，-r是以相反顺序，-k是指定需要排序的栏位，-t指定栏位分隔符为冒号</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 多列排序：以:分隔，按第二列数值排倒序，第三列正序</span></span><br><span class="line">[linux@linux ~]$ sort -n -t: -k2,2r -k3 sort.txt</span><br></pre></td></tr></table></figure></li><li><p><strong>-k选项的具体语法格式：</strong> x,x 表示一个范围</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">FStart.CStart Modifie,FEnd.CEnd Modifier</span><br><span class="line">-------Start--------,-------End--------</span><br><span class="line"> FStart.CStart 选项  ,  FEnd.CEnd 选项</span><br></pre></td></tr></table></figure><p>这个语法格式可以被其中的逗号<code>,</code>分为两大部分， <strong>Start</strong> 部分和 <strong>End</strong> 部分。Start部分也由三部分组成，其中的Modifier部分就是我们之前说过的类似n和r的选项部分。我们重点说说<code>Start</code>部分的<code>FStart</code>和<code>C.Start</code>。<code>C.Start</code>也是可以省略的，省略的话就表示从本域的开头部分开始。<code>FStart.CStart</code>，其中<code>FStart</code>就是表示使用的域，而<code>CStart</code>则表示在<code>FStart</code>域中从第几个字符开始算“排序首字符”。同理，在End部分中，你可以设定<code>FEnd.CEnd</code>，如果你省略<code>.CEnd</code>，则表示结尾到“域尾”，即本域的最后一个字符。或者，如果你将CEnd设定为0(零)，也是表示结尾到“域尾”。</p></li><li><p><strong>从公司英文名称的第二个字母开始进行排序：</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 先创建此txt文件</span></span><br><span class="line"><span class="comment"># 再排序</span></span><br><span class="line">$ sort -t <span class="string">' '</span> -k 1.2 facebook.txt</span><br><span class="line">baidu 100 5000</span><br><span class="line">sohu 100 4500</span><br><span class="line">google 110 5000</span><br><span class="line">guge 50 3000</span><br></pre></td></tr></table></figure><p><code>-t &#39; &#39;</code>, 首先用<code>&#39; &#39;</code>空格, 把字段分割成了3个域.</p><p>使用了<code>-k 1.2</code>，表示对第一个域的第二个字符开始到本域的最后一个字符为止的字符串进行排序。你会发现baidu因为第二个字母是a而名列榜首。sohu和 google第二个字符都是o，但sohu的h在google的o前面，所以两者分别排在第二和第三。guge只能屈居第四了。</p></li><li><p><strong>只针对</strong>公司英文名称的第二个字母进行排序，<strong>如果相同的</strong>按照员工工资进行降序排序：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ sort -t <span class="string">' '</span> -k 1.2,1.2 -nrk 3,3 facebook.txt</span><br><span class="line">baidu 100 5000</span><br><span class="line">google 110 5000</span><br><span class="line">sohu 100 4500</span><br><span class="line">guge 50 3000</span><br></pre></td></tr></table></figure><p>由于只对第二个字母进行排序，所以我们使用了<code>-k 1.2,1.2</code>的表示方式，表示我们“只”对第二个字母进行排序。（如果你问“我使用<code>-k 1.2</code>怎么不行？”，当然不行，因为你省略了End部分，这就意味着你将对从第二个字母起到本域最后一个字符为止的字符串进行排序）。对于员工工资进行排 序，我们也使用了<code>-k 3,3</code>，这是最准确的表述，表示我们“只”对本域进行排序，因为如果你省略了后面的3，就变成了我们“对第3个域开始到最后一个域位置的内容进行排序” 了。</p></li></ol><h2 id="uniq"><a href="#uniq" class="headerlink" title="uniq"></a>uniq</h2><p><strong>uniq命令</strong> 用于报告或忽略文件中的重复行，一般与sort命令结合使用。</p><h4 id="选项-2"><a href="#选项-2" class="headerlink" title="选项"></a>选项</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">-c或——count：在每列旁边显示该行重复出现的次数；</span><br><span class="line">-d或--repeated：仅显示重复出现的行列；</span><br><span class="line">-f&lt;栏位&gt;或--skip-fields=&lt;栏位&gt;：忽略比较指定的栏位；</span><br><span class="line">-s&lt;字符位置&gt;或--skip-chars=&lt;字符位置&gt;：忽略比较指定的字符；</span><br><span class="line">-u或——unique：仅显示出一次的行列；</span><br><span class="line">-w&lt;字符位置&gt;或--check-chars=&lt;字符位置&gt;：指定要比较的字符。</span><br></pre></td></tr></table></figure><h4 id="参数"><a href="#参数" class="headerlink" title="参数"></a>参数</h4><ul><li>输入文件：指定要去除的重复行文件。如果不指定此项，则从标准读取数据；</li><li>输出文件：指定要去除重复行后的内容要写入的输出文件。如果不指定此选项，则将内容显示到标准输出设备（显示终端）。</li></ul><h4 id="实例-1"><a href="#实例-1" class="headerlink" title="实例"></a>实例</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line">[root]<span class="comment"># cat sort.txt: 原本行</span></span><br><span class="line">aaa:10:1.1</span><br><span class="line">ccc:30:3.3</span><br><span class="line">ddd:40:4.4</span><br><span class="line">bbb:20:2.2</span><br><span class="line">eee:50:5.5</span><br><span class="line">eee:50:5.5</span><br><span class="line"></span><br><span class="line">[root]<span class="comment"># uniq sort.txt  : 不展示重复行</span></span><br><span class="line">aaa:10:1.1</span><br><span class="line">ccc:30:3.3</span><br><span class="line">ddd:40:4.4</span><br><span class="line">bbb:20:2.2</span><br><span class="line">eee:50:5.5</span><br><span class="line">[cts1:Desktop]</span><br><span class="line"></span><br><span class="line">[cts1:Desktop]</span><br><span class="line">[root]<span class="comment"># sort sort.txt | uniq : 不展示重复行</span></span><br><span class="line">aaa:10:1.1</span><br><span class="line">bbb:20:2.2</span><br><span class="line">ccc:30:3.3</span><br><span class="line">ddd:40:4.4</span><br><span class="line">eee:50:5.5</span><br><span class="line"></span><br><span class="line">[cts1:Desktop]</span><br><span class="line">[root]<span class="comment"># uniq -u sort.txt     : 删除重复行</span></span><br><span class="line">aaa:10:1.1</span><br><span class="line">ccc:30:3.3</span><br><span class="line">ddd:40:4.4</span><br><span class="line">bbb:20:2.2</span><br><span class="line">[cts1:Desktop]</span><br><span class="line">[root]<span class="comment"># sort sort.txt | uniq -u : 排序并删除重复行</span></span><br><span class="line">aaa:10:1.1</span><br><span class="line">bbb:20:2.2</span><br><span class="line">ccc:30:3.3</span><br><span class="line">ddd:40:4.4</span><br><span class="line">[cts1:Desktop]</span><br><span class="line">[root]<span class="comment"># sort sort.txt | uniq -c : 展示每行出现的次数</span></span><br><span class="line">      1 aaa:10:1.1</span><br><span class="line">      1 bbb:20:2.2</span><br><span class="line">      1 ccc:30:3.3</span><br><span class="line">      1 ddd:40:4.4</span><br><span class="line">      2 eee:50:5.5</span><br><span class="line">[cts1:Desktop]</span><br><span class="line">[root]<span class="comment"># sort sort.txt | uniq -d : 只展示重复行</span></span><br><span class="line">eee:50:5.5</span><br><span class="line"></span><br><span class="line"><span class="comment"># 求a.txt和b.txt的差集 </span></span><br><span class="line"><span class="comment">## 首先a b 去掉重复的, 再跟a b去重, 把b其它的部分也去掉</span></span><br><span class="line">cts1 Desktop <span class="comment"># cat a b b | sort | uniq -u</span></span><br><span class="line">a</span><br><span class="line">b</span><br><span class="line"></span><br><span class="line"><span class="comment"># 求b.txt和a.txt的差集  </span></span><br><span class="line"><span class="comment">## 同上</span></span><br><span class="line">cts1 Desktop <span class="comment"># cat b a a | sort | uniq -u</span></span><br><span class="line">e</span><br><span class="line">f</span><br></pre></td></tr></table></figure><h2 id="cut"><a href="#cut" class="headerlink" title="cut"></a>cut</h2><p><strong>cut命令</strong> 用来显示行中的指定部分，删除文件中指定字段。cut经常用来显示文件的内容，类似于下的type命令。</p><p>说明：该命令有两项功能，其一是用来显示文件的内容，它依次读取由参数file所指 明的文件，将它们的内容输出到标准输出上；其二是连接两个或多个文件，如<code>cut fl f2 &gt; f3</code>将把文件fl和几的内容合并起来，然后通过输出重定向符“&gt;”的作用，将它们放入文件f3中。</p><p>当文件较大时，文本在屏幕上迅速闪过（滚屏），用户往往看不清所显示的内容。因此，一般用more等命令分屏显示。为了控制滚屏，可以按Ctrl+S键，停止滚屏；按Ctrl+Q键可以恢复滚屏。按Ctrl+C（中断）键可以终止该命令的执行，并且返回Shell提示符状态。</p><h4 id="选项-3"><a href="#选项-3" class="headerlink" title="选项"></a>选项</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">-b：仅显示行中指定直接范围的内容；</span><br><span class="line">-c：仅显示行中指定范围的字符；  </span><br><span class="line">-d：指定字段的分隔符，默认的字段分隔符为“TAB”；  </span><br><span class="line">-f：显示指定字段的内容；</span><br><span class="line">-n：与“-b”选项连用，不分割多字节字符；</span><br><span class="line">--complement：补足被选择的字节、字符或字段；</span><br><span class="line">--out-delimiter=&lt;字段分隔符&gt;：指定输出内容是的字段分割符；</span><br><span class="line">--<span class="built_in">help</span>：显示指令的帮助信息；</span><br><span class="line">--version：显示指令的版本信息。</span><br></pre></td></tr></table></figure><h4 id="参数-1"><a href="#参数-1" class="headerlink" title="参数"></a>参数</h4><p>文件：指定要进行内容过滤的文件。</p><h4 id="实例-2"><a href="#实例-2" class="headerlink" title="实例"></a>实例</h4><p>例如有一个学生报表信息，包含No、Name、Mark、Percent：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost text]<span class="comment"># cat cut.txt </span></span><br><span class="line">No Name Mark Percent</span><br><span class="line">01 tom 69 91</span><br><span class="line">02 jack 71 87</span><br><span class="line">03 alex 68 98</span><br></pre></td></tr></table></figure><h5 id="f"><a href="#f" class="headerlink" title="-f"></a><code>-f</code></h5><p>使用<code>-f</code> 选项提取指定字段</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost text]<span class="comment"># cut -d ' ' -f1 cut.txt </span></span><br><span class="line">No</span><br><span class="line">01</span><br><span class="line">02</span><br><span class="line">03</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost text]<span class="comment"># cut -d ' ' -f2,3 test.txt </span></span><br><span class="line">Name Mark</span><br><span class="line">tom 69</span><br><span class="line">jack 71</span><br><span class="line">alex 68</span><br></pre></td></tr></table></figure><h5 id="–complement"><a href="#–complement" class="headerlink" title="–complement"></a><strong>–complement</strong></h5><p>选项提取指定字段之外的列（打印除了第二列之外的列）：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">cut -d <span class="string">' '</span> -f2 --complement cut.txt</span><br><span class="line">No Mark Percent</span><br><span class="line">01 69 91</span><br><span class="line">02 71 87</span><br><span class="line">03 68 98</span><br></pre></td></tr></table></figure><h5 id="指定字段的字符或者字节范围-amp-例子"><a href="#指定字段的字符或者字节范围-amp-例子" class="headerlink" title="指定字段的字符或者字节范围 &amp; 例子"></a>指定字段的字符或者字节范围 &amp; 例子</h5><p>cut命令可以将一串字符作为列来显示，字符字段的记法：</p><ul><li><strong>N-</strong> ：从第N个字节、字符、字段到结尾；</li><li><strong>N-M</strong> ：从第N个字节、字符、字段到第M个（包括M在内）字节、字符、字段；</li><li><strong>-M</strong> ：从第1个字节、字符、字段到第M个（包括M在内）字节、字符、字段。</li></ul><p>上面是记法，结合下面选项将摸个范围的字节、字符指定为字段：</p><ul><li><strong>-b</strong>  表示字节；</li><li><strong>-c</strong>  表示字符；</li><li><strong>-f</strong>  表示定义字段。</li></ul><h5 id="实例-3"><a href="#实例-3" class="headerlink" title="实例"></a>实例</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost text]<span class="comment"># cat test.txt </span></span><br><span class="line">abcdefghijklmnopqrstuvwxyz</span><br><span class="line">abcdefghijklmnopqrstuvwxyz</span><br><span class="line">abcdefghijklmnopqrstuvwxyz</span><br><span class="line">abcdefghijklmnopqrstuvwxyz</span><br><span class="line">abcdefghijklmnopqrstuvwxyz</span><br><span class="line"></span><br><span class="line"><span class="comment"># 打印第1个到第3个字符：</span></span><br><span class="line">cut -c1-3 test.txt </span><br><span class="line">abc</span><br><span class="line">abc</span><br><span class="line">abc</span><br><span class="line">abc</span><br><span class="line">abc</span><br><span class="line"></span><br><span class="line"><span class="comment"># 打印前2个字符：</span></span><br><span class="line">cut -c-2 test.txt </span><br><span class="line">ab</span><br><span class="line">ab</span><br><span class="line">ab</span><br><span class="line">ab</span><br><span class="line">ab</span><br><span class="line"></span><br><span class="line"><span class="comment"># 打印从第5个字符开始到结尾：</span></span><br><span class="line">cut -c5- test.txt </span><br><span class="line">efghijklmnopqrstuvwxyz</span><br><span class="line">efghijklmnopqrstuvwxyz</span><br><span class="line">efghijklmnopqrstuvwxyz</span><br><span class="line">efghijklmnopqrstuvwxyz</span><br><span class="line">efghijklmnopqrstuvwxyz</span><br></pre></td></tr></table></figure><h2 id="grep-文本生成器"><a href="#grep-文本生成器" class="headerlink" title="grep(文本生成器)"></a>grep(文本生成器)</h2><p><strong>grep</strong> （global search regular expression(RE) and print  out the  line，全面搜索正则表达式并把行打印出来）是一种强大的文本搜索工具，它能使用正则表达式搜索文本，并把匹配的行打印出来。用于过滤/搜索的特定字符。可使用正则表达式能多种命令配合使用，使用上十分灵活。</p><h4 id="选项-4"><a href="#选项-4" class="headerlink" title="选项"></a>选项</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">-a --text  <span class="comment"># 不要忽略二进制数据。</span></span><br><span class="line">-A &lt;显示行数&gt;   --after-context=&lt;显示行数&gt;   <span class="comment"># 除了显示符合范本样式的那一行之外，并显示该行之后的内容。</span></span><br><span class="line">-b --byte-offset                           <span class="comment"># 在显示符合范本样式的那一行之外，并显示该行之前的内容。</span></span><br><span class="line">-B&lt;显示行数&gt;   --before-context=&lt;显示行数&gt;   <span class="comment"># 除了显示符合样式的那一行之外，并显示该行之前的内容。</span></span><br><span class="line">-c --count    <span class="comment"># 计算符合范本样式的列数。</span></span><br><span class="line">-C&lt;显示行数&gt; --context=&lt;显示行数&gt;或-&lt;显示行数&gt; <span class="comment"># 除了显示符合范本样式的那一列之外，并显示该列之前后的内容。</span></span><br><span class="line">-d&lt;进行动作&gt; --directories=&lt;动作&gt;  <span class="comment"># 当指定要查找的是目录而非文件时，必须使用这项参数，否则grep命令将回报信息并停止动作。</span></span><br><span class="line">-e&lt;范本样式&gt; --regexp=&lt;范本样式&gt;   <span class="comment"># 指定字符串作为查找文件内容的范本样式。</span></span><br><span class="line">-E --extended-regexp             <span class="comment"># 将范本样式为延伸的普通表示法来使用，意味着使用能使用扩展正则表达式。</span></span><br><span class="line">-f&lt;范本文件&gt; --file=&lt;规则文件&gt;     <span class="comment"># 指定范本文件，其内容有一个或多个范本样式，让grep查找符合范本条件的文件内容，格式为每一列的范本样式。</span></span><br><span class="line">-F --fixed-regexp   <span class="comment"># 将范本样式视为固定字符串的列表。</span></span><br><span class="line">-G --basic-regexp   <span class="comment"># 将范本样式视为普通的表示法来使用。</span></span><br><span class="line">-h --no-filename    <span class="comment"># 在显示符合范本样式的那一列之前，不标示该列所属的文件名称。</span></span><br><span class="line">-H --with-filename  <span class="comment"># 在显示符合范本样式的那一列之前，标示该列的文件名称。</span></span><br><span class="line">-i --ignore-case    <span class="comment"># 忽略字符大小写的差别。</span></span><br><span class="line">-l --file-with-matches   <span class="comment"># 列出文件内容符合指定的范本样式的文件名称。</span></span><br><span class="line">-L --files-without-match <span class="comment"># 列出文件内容不符合指定的范本样式的文件名称。</span></span><br><span class="line">-n --line-number         <span class="comment"># 在显示符合范本样式的那一列之前，标示出该列的编号。</span></span><br><span class="line">-q --quiet或--silent     <span class="comment"># 不显示任何信息。</span></span><br><span class="line">-R/-r  --recursive       <span class="comment"># 此参数的效果和指定“-d recurse”参数相同。</span></span><br><span class="line">-s --no-messages  <span class="comment"># 不显示错误信息。</span></span><br><span class="line">-v --revert-match <span class="comment"># 反转查找。</span></span><br><span class="line">-V --version      <span class="comment"># 显示版本信息。   </span></span><br><span class="line">-w --word-regexp  <span class="comment"># 只显示全字符合的列。</span></span><br><span class="line">-x --line-regexp  <span class="comment"># 只显示全列符合的列。</span></span><br><span class="line">-y <span class="comment"># 此参数效果跟“-i”相同。</span></span><br><span class="line">-o <span class="comment"># 只输出文件中匹配到的部分。</span></span><br></pre></td></tr></table></figure><h4 id="grep中的正则表达式"><a href="#grep中的正则表达式" class="headerlink" title="grep中的正则表达式"></a>grep中的正则表达式</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">&lt;sup&gt;    <span class="comment"># 锚定行的开始 如：'&lt;/sup&gt;grep'匹配所有以grep开头的行。    </span></span><br><span class="line">$    <span class="comment"># 锚定行的结束 如：'grep$'匹配所有以grep结尾的行。    </span></span><br><span class="line">.    <span class="comment"># 匹配一个非换行符的字符 如：'gr.p'匹配gr后接一个任意字符，然后是p。    </span></span><br><span class="line">*    <span class="comment"># 匹配零个或多个先前字符 如：'*grep'匹配所有一个或多个空格后紧跟grep的行。    </span></span><br><span class="line">.*   <span class="comment"># 一起用代表任意字符。   </span></span><br><span class="line">[]   <span class="comment"># 匹配一个指定范围内的字符，如'[Gg]rep'匹配Grep和grep。    </span></span><br><span class="line">[&lt;sup&gt;]  <span class="comment"># 匹配一个不在指定范围内的字符，如：'[&lt;/sup&gt;A-FH-Z]rep'匹配不包含A-R和T-Z的一个字母开头，紧跟rep的行。    </span></span><br><span class="line">\    <span class="comment"># 转义</span></span><br><span class="line">\(..\)  <span class="comment"># 标记匹配字符，如'\(love\)'，love被标记为1。    </span></span><br><span class="line">\&lt;      <span class="comment"># 锚定单词的开始，如:'\&lt;grep'匹配包含以grep开头的单词的行。    </span></span><br><span class="line">\&gt;      <span class="comment"># 锚定单词的结束，如'grep\&gt;'匹配包含以grep结尾的单词的行。    </span></span><br><span class="line">x\&#123;m\&#125;  <span class="comment"># 重复字符x，m次，如：'o\&#123;5\&#125;'匹配包含5个o的行。    </span></span><br><span class="line">x\&#123;m,\&#125;   <span class="comment"># 重复字符x,至少m次，如：'o\&#123;5,\&#125;'匹配至少有5个o的行。    </span></span><br><span class="line">x\&#123;m,n\&#125;  <span class="comment"># 重复字符x，至少m次，不多于n次，如：'o\&#123;5,10\&#125;'匹配5--10个o的行。   </span></span><br><span class="line">\w    <span class="comment"># 匹配文字和数字字符，也就是[A-Za-z0-9]，如：'G\w*p'匹配以G后跟零个或多个文字或数字字符，然后是p。   </span></span><br><span class="line">\W    <span class="comment"># \w的反置形式，匹配一个或多个非单词字符，如点号句号等。   </span></span><br><span class="line">\b    <span class="comment"># 单词锁定符，如: '\bgrep\b'只匹配grep。</span></span><br><span class="line"></span><br><span class="line">增录</span><br><span class="line">.  <span class="comment"># 任意一个字符</span></span><br><span class="line">a* <span class="comment"># 任意多个a(0个或多个)</span></span><br><span class="line">a? <span class="comment"># 0个或1个a</span></span><br><span class="line">a+  <span class="comment"># 一个或多个a</span></span><br><span class="line">[A-Z]</span><br><span class="line">[ABC]</span><br></pre></td></tr></table></figure><h4 id="grep命令常见用法"><a href="#grep命令常见用法" class="headerlink" title="grep命令常见用法"></a>grep命令常见用法</h4><ol><li><p>在文件中搜索一个单词，命令会返回一个包含 <strong>“match_pattern”</strong> 的文本行：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">grep match_pattern file_name</span><br><span class="line">grep <span class="string">"match_pattern"</span> file_name</span><br></pre></td></tr></table></figure></li><li><p>在多个文件中查找</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">grep <span class="string">"match_pattern"</span> file_1 file_2 file_3 ...</span><br></pre></td></tr></table></figure></li><li><p>输出除  “match_pattern” 之外的所有行  &gt;&gt;   <strong>-v</strong>  选项：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">grep -v <span class="string">"match_pattern"</span> file_name</span><br></pre></td></tr></table></figure></li><li><p>标记匹配颜色  <strong>–color=auto</strong>  选项：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">grep <span class="string">"match_pattern"</span> file_name --color=auto</span><br><span class="line"></span><br><span class="line">eg: 查找当前目录下所有文件中的 `a`</span><br><span class="line">cts1 Desktop <span class="comment"># grep "\(a\)" ./* --color=auto</span></span><br><span class="line">---</span><br><span class="line">./a:a</span><br><span class="line">./abc.txt:abcdefghijklmnopqrstuvwxyz</span><br><span class="line">./abc.txt:abcdefghijklmnopqrstuvwxyz</span><br><span class="line">./abc.txt:abcdefghijklmnopqrstuvwxyz</span><br><span class="line">...</span><br></pre></td></tr></table></figure></li><li><h4 id="使用正则表达式-E-选项："><a href="#使用正则表达式-E-选项：" class="headerlink" title="使用正则表达式  -E  选项："></a>使用正则表达式  <strong>-E</strong>  选项：</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">grep -E <span class="string">"[1-9]+"</span></span><br><span class="line">或</span><br><span class="line">egrep <span class="string">"[1-9]+"</span></span><br></pre></td></tr></table></figure></li><li><p><strong>只输出文件中匹配到的部分  -o  选项：</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">echo</span> this is a <span class="built_in">test</span> line. | grep -o -E <span class="string">"[a-z]+\."</span></span><br><span class="line">line.</span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> this is a <span class="built_in">test</span> line. | egrep -o <span class="string">"[a-z]+\."</span></span><br><span class="line">line.</span><br></pre></td></tr></table></figure></li><li><p>统计文件或者文本中包含匹配字符串的行数  <strong>-c</strong>  选项：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">grep -c <span class="string">"text"</span> file_name</span><br></pre></td></tr></table></figure></li><li><p>输出包含匹配字符串的行数  <strong>-n</strong>  选项：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">grep <span class="string">"text"</span> -n file_name</span><br><span class="line">或</span><br><span class="line">cat file_name | grep <span class="string">"text"</span> -n</span><br><span class="line"></span><br><span class="line"><span class="comment">#多个文件</span></span><br><span class="line">grep <span class="string">"text"</span> -n file_1 file_2</span><br></pre></td></tr></table></figure></li><li><p>打印样式匹配所位于的字符或字节偏移</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">echo</span> gun is not unix | grep -b -o <span class="string">"not"</span></span><br><span class="line">7:not</span><br><span class="line"></span><br><span class="line"><span class="comment">#一行中字符串的字符便宜是从该行的第一个字符开始计算，起始值为0。选项  **-b -o**  一般总是配合使用。</span></span><br></pre></td></tr></table></figure></li><li><p>搜索多个文件并查找匹配文本在哪些文件中</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">grep -l <span class="string">"text"</span> file1 file2 file3...</span><br></pre></td></tr></table></figure></li></ol><h4 id="grep递归搜索文件"><a href="#grep递归搜索文件" class="headerlink" title="grep递归搜索文件"></a>grep递归搜索文件</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在多级目录中对文本进行递归搜索</span></span><br><span class="line">grep <span class="string">"text"</span> . -r -n</span><br><span class="line"><span class="comment"># .表示当前目录。</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 忽略匹配样式中的字符大小写</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"hello world"</span> | grep -i <span class="string">"HELLO"</span></span><br><span class="line">hello</span><br><span class="line"></span><br><span class="line"><span class="comment"># 选项 -e 制动多个匹配样式：</span></span><br><span class="line"><span class="built_in">echo</span> this is a text line | grep -e <span class="string">"is"</span> -e <span class="string">"line"</span> -o</span><br><span class="line">is</span><br><span class="line">line</span><br><span class="line"></span><br><span class="line"><span class="comment">#也可以使用 **-f** 选项来匹配多个样式，在样式文件中逐行写出需要匹配的字符。</span></span><br><span class="line">cat patfile</span><br><span class="line">aaa</span><br><span class="line">bbb</span><br><span class="line"></span><br><span class="line"><span class="comment"># 用文件名称匹配, 实际上就是匹配文件中的内容</span></span><br><span class="line"><span class="built_in">echo</span> aaa bbb ccc ddd eee | grep -f patfile -o</span><br><span class="line">aaa</span><br><span class="line">bbb</span><br><span class="line"></span><br><span class="line"><span class="comment"># 在grep搜索结果中包括或者排除指定文件：</span></span><br><span class="line">---</span><br><span class="line"><span class="comment">#只在目录中所有的.php和.html文件中递归搜索字符"main()"</span></span><br><span class="line">grep <span class="string">"main()"</span> . -r --include *.&#123;php,html&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">#在搜索结果中排除所有README文件</span></span><br><span class="line">grep <span class="string">"main()"</span> . -r --exclude <span class="string">"README"</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#在搜索结果中排除filelist文件列表里的文件</span></span><br><span class="line">grep <span class="string">"main()"</span> . -r --exclude-from filelist</span><br><span class="line">---</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用0值字节后缀的grep与xargs：</span></span><br><span class="line">---</span><br><span class="line"><span class="comment"># 测试文件：</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"aaa"</span> &gt; file1</span><br><span class="line"><span class="built_in">echo</span> <span class="string">"bbb"</span> &gt; file2</span><br><span class="line"><span class="built_in">echo</span> <span class="string">"aaa"</span> &gt; file3</span><br><span class="line"></span><br><span class="line">grep <span class="string">"aaa"</span> file* -lZ | xargs -0 rm</span><br><span class="line"></span><br><span class="line"><span class="comment">#执行后会删除file1和file3，grep输出用-Z选项来指定以0值字节作为终结符文件名（\0），xargs -0 读取输入并用0值字节终结符分隔文件名，然后删除匹配文件，-Z通常和-l结合使用。</span></span><br><span class="line"><span class="comment"># 好吧, 暂时我也没懂是啥意思...</span></span><br><span class="line">---</span><br><span class="line"></span><br><span class="line"><span class="comment"># grep静默输出：</span></span><br><span class="line">grep -q <span class="string">"test"</span> filename</span><br><span class="line"><span class="comment"># 不会输出任何信息，如果命令运行成功返回0，失败则返回非0值。一般用于条件测试。</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 打印出匹配文本之前或者之后的行：</span></span><br><span class="line"><span class="comment"># 显示匹配某个结果之后的3行，使用 -A 选项：</span></span><br><span class="line">seq 10 | grep <span class="string">"5"</span> -A 3</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示匹配某个结果之前的3行，使用 -B 选项：</span></span><br><span class="line">seq 10 | grep <span class="string">"5"</span> -B 3</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示匹配某个结果的前三行和后三行，使用 -C 选项：</span></span><br><span class="line">seq 10 | grep <span class="string">"5"</span> -C 3</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line"></span><br><span class="line"><span class="comment"># 如果匹配结果有多个，会用“--”作为各匹配结果之间的分隔符：</span></span><br><span class="line"><span class="built_in">echo</span> -e <span class="string">"a\nb\nc\na\nb\nc"</span> | grep a -A 1</span><br><span class="line">a</span><br><span class="line">b</span><br><span class="line">--</span><br><span class="line">a</span><br><span class="line">b</span><br></pre></td></tr></table></figure><h4 id="grep其它常用用法"><a href="#grep其它常用用法" class="headerlink" title="grep其它常用用法"></a>grep其它常用用法</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 统计出现某个字符串的行的总行数 '-c'</span></span><br><span class="line">cts1 Desktop <span class="comment"># echo "hello" &gt;&gt; hello.sh</span></span><br><span class="line">cts1 Desktop <span class="comment"># grep -c 'hello' hello.sh</span></span><br><span class="line">1</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查询不包含hello的行, 带有hello的整行都不会被查询到'-v'</span></span><br><span class="line">cts1 Desktop <span class="comment"># grep -v 'hello' hello.sh</span></span><br><span class="line">....</span><br><span class="line"></span><br><span class="line"><span class="comment"># `.*`的用法, 前后都是 `.*` , 只要包含 parrten 的 整行 都会被查出来</span></span><br><span class="line">grep <span class="string">'.*hello.*'</span> hello.sh</span><br><span class="line"></span><br><span class="line"><span class="comment"># 任何由 'h..p'包含的都会被查出来. 查的当前行, .* 代表任意字符</span></span><br><span class="line">cts1 Desktop <span class="comment"># grep 'h.*p' /etc/passwd</span></span><br><span class="line">gopher:x:13:30:gopher:/var/gopher:/sbin/nologin</span><br><span class="line">rpc:x:32:32:Rpcbind Daemon:/var/cache/rpcbind:/sbin/nolo</span><br><span class="line"></span><br><span class="line"><span class="comment"># 正则表达以 ro 开头</span></span><br><span class="line">cts1 Desktop <span class="comment"># grep '^ro' /etc/passwd</span></span><br><span class="line">root:x:0:0:root:/root:/bin/zsh</span><br><span class="line"></span><br><span class="line"><span class="comment"># 正则表达以 t 结尾</span></span><br><span class="line">cts1 Desktop <span class="comment"># grep 't$' /etc/passwd</span></span><br><span class="line">halt:x:7:0:halt:/sbin:/sbin/halt</span><br><span class="line"></span><br><span class="line"><span class="comment"># '[Gg]rep'匹配Grep和grep</span></span><br><span class="line"><span class="comment">## 此处是匹配 以 h || r 开头的</span></span><br><span class="line">cts1 Desktop <span class="comment"># </span></span><br><span class="line">grep <span class="string">'^[hr]'</span> /etc/passwd</span><br><span class="line">root:x:0:0:root:/root:/bin/zsh</span><br><span class="line">halt:x:7:0:halt:/sbin:/sbin/halt</span><br><span class="line">rpc:x:32:32:Rpcbind Daemon:/var/cache/rpcbind:/sbin/nologin</span><br><span class="line"></span><br><span class="line"><span class="comment"># 匹配非h之外其他的,  和 r 开头的, 也就是匹配 h以外的</span></span><br><span class="line">cts1 Desktop <span class="comment"># </span></span><br><span class="line">grep <span class="string">'^[hr]'</span> /etc/passwd</span><br><span class="line">root:x:0:0:root:/root:/bin/zsh</span><br><span class="line">halt:x:7:0:halt:/sbin:/sbin/halt</span><br><span class="line">rpc:x:32:32:Rpcbind Daemon:/var/cache/rpcbind:/sbin/nologin</span><br><span class="line"></span><br><span class="line"><span class="comment"># 匹配 h-r 以外的</span></span><br><span class="line">cts1 Desktop <span class="comment"># </span></span><br><span class="line">grep <span class="string">'&lt;sup&gt;[&lt;/sup&gt;h-r]'</span> /etc/passwd</span><br><span class="line">bin:x:1:1:bin:/bin:/sbin/nologin</span><br><span class="line">daemon:x:2:2:daemon:/sbin:/sbin/nologin</span><br><span class="line">...</span><br></pre></td></tr></table></figure><h2 id="sed-流编辑器"><a href="#sed-流编辑器" class="headerlink" title="sed(流编辑器)"></a>sed(流编辑器)</h2><p>sed叫做流编辑器，在shell脚本和Makefile中作为过滤一使用非常普遍，也就是把前一个程序的输出引入sed的输入，经过一系列编辑命令转换成为另一种格式输出。sed是一种在线编辑器，它一次处理一行内容，处理时，把当前处理的行存储在临时缓冲区中，称为”模式空间”,接着用sed命令处理缓冲区中的内容，处理完成后，把缓冲区的内容送往屏幕。接着处理下一行，这样不断重复，直到文件末尾。文件内容并没有改变，除非你使用重定向存储输出。 </p><h3 id="选项-5"><a href="#选项-5" class="headerlink" title="选项"></a>选项</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">-n：一般sed命令会把所有数据都输出到屏幕，如果加入-n选项的话，则只会把经过sed命令处理的行输出到屏幕。</span><br><span class="line">-e&lt;script&gt;或--expression=&lt;script&gt;：以选项中的指定的script来处理输入的文本文件； 允许对输入数据应用多条sed命令编辑。</span><br><span class="line">-i：用sed的修改结果直接修改读取数据的文件，而不是由屏幕输出。</span><br><span class="line">-f&lt;script文件&gt;或--file=&lt;script文件&gt;：以选项中指定的script文件来处理输入的文本文件；</span><br><span class="line">-n或--quiet或——silent：仅显示script处理后的结果；</span><br><span class="line">--version：显示版本信息。</span><br><span class="line"></span><br><span class="line"><span class="comment"># 动作:</span></span><br><span class="line">a：追加，在当前行后添加一行或多行。</span><br><span class="line">c：行替换，用c后面的字符串替换原数据行。</span><br><span class="line">i：插入，在当前行前插入一行或多行。</span><br><span class="line">p：打印，输出指定的行。</span><br><span class="line">s：字符串替换，用一个字符串替换另外一个字符串。格式为**\<span class="string">'**行范围s/旧字符串/新字符串/g**\'</span>** (如果不加g的话，则表示只替换每行第一个匹配的串)</span><br></pre></td></tr></table></figure><h3 id="sed元字符集-正则"><a href="#sed元字符集-正则" class="headerlink" title="sed元字符集(正则)"></a>sed元字符集(正则)</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">**&lt;sup&gt;**  匹配行开始，如：/&lt;/sup&gt;sed/匹配所有以sed开头的行。</span><br><span class="line">**$**  匹配行结束，如：/sed$/匹配所有以sed结尾的行。</span><br><span class="line">**.**  匹配一个非换行符的任意字符，如：/s.d/匹配s后接一个任意字符，最后是d。</span><br><span class="line">**** * 匹配0个或多个字符，如：/*sed/匹配所有模板是一个或多个空格后紧跟sed的行。</span><br><span class="line">**[]**  匹配一个指定范围内的字符，如/[ss]ed/匹配sed和Sed。  </span><br><span class="line">**[&lt;sup&gt;]**  匹配一个不在指定范围内的字符，如：/[&lt;/sup&gt;A-RT-Z]ed/匹配不包含A-R和T-Z的一个字母开头，紧跟ed的行。</span><br><span class="line">**\(..\)**  匹配子串，保存匹配的字符，如s/\(love\)able/\1rs，loveable被替换成lovers。</span><br><span class="line">**&amp;**  保存搜索字符用来替换其他字符，如s/love/ **&amp;** /，love这成 **love** 。</span><br><span class="line">**\&lt;**  匹配单词的开始，如:/\&lt;love/匹配包含以love开头的单词的行。</span><br><span class="line">**\&gt;**  匹配单词的结束，如/love\&gt;/匹配包含以love结尾的单词的行。</span><br><span class="line">**x\&#123;m\&#125;**  重复字符x，m次，如：/0\&#123;5\&#125;/匹配包含5个0的行。</span><br><span class="line">**x\&#123;m,\&#125;**  重复字符x，至少m次，如：/0\&#123;5,\&#125;/匹配至少有5个0的行。</span><br><span class="line">**x\&#123;m,n\&#125;**  重复字符x，至少m次，不多于n次，如：/0\&#123;5,10\&#125;/匹配5~10个0的行。</span><br></pre></td></tr></table></figure><h3 id="实例-4"><a href="#实例-4" class="headerlink" title="实例"></a>实例</h3><ol><li><p><strong>删除: d命令</strong></p><blockquote><p><strong>sed ‘2d’ sed.txt</strong>                            —–删除sed<strong>.txt</strong>文件的第二行。</p><p><strong>sed ‘2,$d’ sed.txt</strong>                            —–删除sed<strong>.txt</strong>文件的第二行到末尾所有行。</p><p><strong>sed ‘$d’ sed.txt</strong>                      —–删除sed<strong>.txt</strong>文件的最后一行。</p><p><strong>sed ‘/test/d ‘ sed.txt</strong>             —–删除sed<strong>.txt</strong>文件所有包含test的行。</p><p><strong>sed ‘/[A-Za-z]/d ‘ sed.txt</strong>    —–删除sed<strong>.txt</strong>文件所有包含字母的行。</p></blockquote></li><li><p><strong>整行替换: c命令</strong></p><blockquote><p>将第二行替换成hello world</p><p><strong>sed \’2c hello world\’ sed.txt</strong></p></blockquote></li><li><p><strong>字符串替换：s命令</strong></p><blockquote><ol><li><p><strong>sed ‘s/hello/hi/g’ sed.txt</strong>                                    </p><p>##  在整行范围内把hello替换为hi。如果没有g标记，则只有每行第一个匹配的hello被替换成hi。</p></li></ol><ol start="2"><li><p><strong>sed ‘s/hello/hi/2’ sed.txt</strong></p><p>##  此种写法表示只替换每行的第2个hello为hi</p></li></ol><ol start="3"><li><p><strong>sed ‘s/hello/hi/2g’ sed.txt</strong></p><p>##  此种写法表示只替换每行的第2个以后的hello为hi（包括第2个）</p></li></ol><ol start="4"><li><p><strong>sed -n ‘s/^hello/hi/p’ sed.txt</strong>                            </p><p>## <strong>(-n)选项和p标志一起使用表示只打印那些发生替换的行</strong>。也就是说，如果某一行开头的hello被替换成hi，就打印它。</p></li></ol><ol start="5"><li><p><strong>sed -n ‘2,4p’ sed.txt</strong></p><p>##  打印输出sed.txt中的第2行和第4行</p></li></ol><ol start="6"><li><p><strong>sed -n ‘s/hello/&amp;-hi/gp’ sed.txt</strong></p><p><strong>sed ‘s/^192.168.0.1/&amp;-localhost/‘ sed.txt</strong>  </p><p><strong>sed ‘s/^192.168.0.1/[&amp;]/‘ sed.txt</strong>       </p><p>##  &amp;符号表示追加一个串到找到的串后, &amp;代表前一个串。</p><p>所有以192.168.0.1开头的行都会被替换成它自已加 -localhost，变成192.168.0.1-localhost。</p><p>第三句表示给IP地址添加中括号</p></li></ol><ol start="7"><li><p><strong>sed -n ‘s/(liu)jialing/\1tao/p’ sed.txt</strong></p><p><strong>sed -n ‘s/(liu)jia(ling)/\1tao\2ss/p’ sed.txt</strong></p><p>##  liu被标记为\1，所以liu会被保留下来（\1 == liu）</p><p>##  ling被标记为\2，所以ling也会被保留下来（\2 == ling）</p><p>##  所以最后的结果就是\1tao\2ss == “liu” + “tao” + “ling” + “ss”</p><p>此处切记：\1代表的是被第一个()包含的内容，\1代表的是被第一个()包含的内容，……</p><p>上面命令的意思就是：被括号包含的字符串会保留下来，然后跟其他的字符串比如tao和ss组成新的字符串liutaolingss</p></li></ol><ol start="8"><li><p><strong>sed ‘s#hello#hi#g’ sed.txt</strong></p><p>##  不论什么字符，紧跟着s命令的都被认为是新的分隔符，所以，”#”在这里是分隔符，代替了默认的”/“分隔符。表示把所有hello替换成hi。</p></li></ol><p><u>选定行的范围：逗号</u></p><ol><li><p><strong>sed -n ‘/today/,/hello/p’ sed.txt</strong></p><p>## 所有在模板today和hello所确定的范围内的行都被打印。都找第一个，也就是说，从第一个today到第一个hello</p></li></ol><ol start="2"><li><p><strong>sed -n ‘5,/^hello/p’ sed.txt</strong></p><p><strong>sed -n ‘/^hello/,8p’ sed.txt</strong></p><p>## 打印从第五行开始到第一个包含以hello开始的行之间的所有行。</p></li><li><p><strong>sed ‘/today/,/hello/s/$/www/‘ sed.txt</strong></p><p>## 对于模板today和hello之间的行，每行的末尾用字符串www替换。</p><p><strong>sed ‘/today/,/hello/s/^/www/‘ sed.txt</strong></p><p>## 对于模板today和hello之间的行，每行的开头用字符串www替换。</p></li><li><p><strong>sed ‘/^[A-Za-z]/s/5/five/g’ sed.txt</strong></p><p>## 将以字母开头的行中的数字5替换成five</p></li></ol></blockquote></li></ol><ol start="4"><li><p><strong>多点编辑：e命令</strong> </p><blockquote><ol><li><p><strong>sed -e ‘1,5d’ -e ‘s/hello/hi/‘ sed.txt</strong></p><p>##  (-e)选项允许在同一行里执行多条命令。如例子所示，第一条命令删除1至5行，第二条命令用hello替换hi。命令的执行顺序对结果有影响。如果两个命令都是替换命令，那么第一个替换命令将影响第二个替换命令的结果。</p></li><li><p><strong>sed –expression=’s/hello/hi/‘ –expression=’/today/d’ sed.txt</strong></p><p>##  一个比-e更好的命令是–expression。它能给sed表达式赋值。</p></li></ol></blockquote></li><li><p><strong>从文件读入：r命令</strong> </p><blockquote><p><strong>sed ‘/hello/r file’ sed.txt</strong></p><p>##  file里的内容被读进来，显示在与hello匹配的行下面，如果匹配多行，则file的内容将显示在所有匹配行的下面。</p></blockquote></li><li><p><strong>写入文件：w命令</strong> </p><blockquote><p><strong>sed -n ‘/hello/w file’ sed.txt</strong></p><p>##  在huangbo.txt中所有包含hello的行都被写入file里。</p></blockquote></li><li><p><strong>追加命令：a命令</strong> </p><blockquote><p><strong>sed ‘/^hello/a\—&gt;this is a example’ sed.txt</strong>    </p><p>##  ‘—&gt;this is a example’被追加到以hello开头的行(另起一行)后面，sed要求命令a后面有一个反斜杠。</p></blockquote></li><li><p><strong>插入：i命令</strong> </p><blockquote><p><strong>sed ‘/will/i\some thing new ————————-‘ sed.txt</strong></p><p>##  如果test被匹配，则把反斜杠后面的文本插入到匹配行的前面。</p></blockquote></li><li><p><strong>下一个：n命令</strong> </p><blockquote><p><strong>sed ‘/hello/{n; s/aa/bb/;}’ sed.txt</strong>            <strong>替换下一行的第一个aa</strong></p><p><strong>sed ‘/hello/{n; s/aa/bb/g;}’ sed.txt</strong>     <strong>替换下一行的全部aa</strong></p><p>##  如果hello被匹配，则移动到匹配行的下一行，替换这一行的aa，变为bb，并打印该行，然后继续。</p></blockquote></li><li><p><strong>退出：q命令</strong> </p><blockquote><p><strong>sed ‘10q’ sed.txt</strong></p><p>##  打印完第10行后，退出sed。</p><p>同样的写法： <strong>sed -n ‘1,10p ‘ sed.txt</strong></p></blockquote></li></ol><h2 id="awk-报表生成器"><a href="#awk-报表生成器" class="headerlink" title="awk(报表生成器)"></a>awk(报表生成器)</h2><p>Awk是一个强大的处理文本的编程语言工具，其名称得自于它的创始人Alfred Aho、Peter Weinberger和Brian Kernighan 姓氏的首个字母，相对于grep的查找，sed的编辑，awk在其对数据分析并生成报告时，显得尤为强大。AWK 提供了极其强大的功能：可以进行样式装入、流控制、数学运算符、进程控制语句甚至于内置的变量和函数。简单来说awk就是扫描文件中的每一行，查找与命令行中所给定内容相匹配的模式。如果发现匹配内容，则进行下一个编程步骤。如果找不到匹配内容，则继续处理下一行。 </p><h3 id="语法"><a href="#语法" class="headerlink" title="语法"></a>语法</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">awk [options] <span class="string">'script'</span> var=value file(s)</span><br><span class="line">awk [options] -f scriptfile var=value file(s)</span><br></pre></td></tr></table></figure><p>… TODO 待补充</p><h3 id="实例-5"><a href="#实例-5" class="headerlink" title="实例"></a>实例</h3><ol><li><p>假设last -n 5的输出如下: </p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">root@cts1:~ <span class="comment"># last -n 5</span></span><br><span class="line">root     pts/1        192.168.170.1    Mon May 28 09:28   still logged <span class="keyword">in</span></span><br><span class="line">root     pts/1        192.168.170.1    Sun May 27 20:53 - 07:21  (10:28)</span><br><span class="line">root     pts/0        192.168.170.1    Sun May 27 19:39   still logged <span class="keyword">in</span></span><br><span class="line">reboot   system boot  2.6.32-573.el6.x Sun May 27 19:34 - 14:48  (19:13)</span><br><span class="line">root     pts/1        192.168.170.1    Sat May 26 20:43 - 22:36  (01:53)</span><br></pre></td></tr></table></figure></li><li><p>只显示五个最近登录的账号： </p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">root@cts1:~ <span class="comment"># last -n 5 | awk '&#123;print $1&#125;'</span></span><br><span class="line">root</span><br><span class="line">root</span><br><span class="line">root</span><br><span class="line">reboot</span><br><span class="line">root</span><br><span class="line"></span><br><span class="line"><span class="comment"># awk工作流程是这样的：读入有'\n'换行符分割的一条记录，然后将记录按指定的域分隔符划分域，填充域，$0则表示所有域,$1表示第一个域,$n表示第n个域。默认域分隔符是"空白键" 或 "[tab]键",所以$1表示登录用户，$3表示登录用户ip,以此类推</span></span><br></pre></td></tr></table></figure></li><li><p>显示/etc/passwd的账户： </p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">root@cts1:~ <span class="comment"># cat /etc/passwd | awk -F':' '&#123;print $1&#125;'</span></span><br><span class="line">root</span><br><span class="line">bin</span><br><span class="line">daemon</span><br><span class="line">...</span><br><span class="line"></span><br><span class="line"><span class="comment"># 这种是awk+action的示例，每行都会执行action&#123;print $1&#125;。</span></span><br><span class="line"><span class="comment"># -F指定域分隔符为':'</span></span><br></pre></td></tr></table></figure></li><li><p>显示/etc/passwd的账户和账户对应的shell,而账户与shell之间以tab键分割 </p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">root@cts1:~ <span class="comment"># cat /etc/passwd | awk -F':' '&#123;print $1"\t"$7&#125;'</span></span><br><span class="line">root/bin/zsh</span><br><span class="line">bin/sbin/nologin</span><br><span class="line">daemon/sbin/nologin</span><br><span class="line">...</span><br></pre></td></tr></table></figure></li><li><p><strong>BEGIN and END</strong> </p><p>如果只是显示/etc/passwd的账户和账户对应的shell,而账户与shell之间以逗号分割,而且在所有行添加列名name,shell,在最后一行添加”blue,/bin/nosh”。 </p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">root@cts1:~ <span class="comment"># cat /etc/passwd |awk  -F ':'  'BEGIN &#123;print "name,shell"&#125;  &#123;print $1","$7&#125; END &#123;print "blue,/bin/nosh"&#125;'</span></span><br><span class="line">---</span><br><span class="line">name,shell</span><br><span class="line">root,/bin/zsh</span><br><span class="line">bin,/sbin/nologin</span><br><span class="line">...</span><br><span class="line">mysql,/bin/bash</span><br><span class="line">blue,/bin/nosh</span><br><span class="line">-------------------------</span><br><span class="line"></span><br><span class="line">root@cts1:~ <span class="comment"># cat /etc/passwd | awk -F ':' 'BEGIN &#123;print "name \t shell"&#125; &#123;print$1"\t"$7&#125; END &#123;print "blue,/bin/bash"&#125;'</span></span><br><span class="line">---</span><br><span class="line">name  shell</span><br><span class="line">root/bin/zsh</span><br><span class="line">bin/sbin/nologin</span><br><span class="line">...</span><br><span class="line">mysql/bin/bash</span><br><span class="line">blue,/bin/bash</span><br></pre></td></tr></table></figure><p>awk工作流程是这样的：先执行BEGIN，然后读取文件，读入有/n换行符分割的一条记录，然后将记录按指定的域分隔符划分域，填充域，$0则表示所有域,$1表示第一个域,$n表示第n个域,随后开始执行模式所对应的动作action。接着开始读入第二条记录••••••直到所有的记录都读完，最后执行END操作。 </p></li><li><p><strong>搜索/etc/passwd有root关键字的所有行</strong> </p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">1. root@cts1:~ <span class="comment"># awk  -F:  '/root/'  /etc/passwd</span></span><br><span class="line">    ---</span><br><span class="line">    root:x:0:0:root:/root:/bin/zsh</span><br><span class="line">    operator:x:11:0:operator:/root:/sbin/nologin</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 这种是pattern的使用示例，匹配了pattern(这里是root)的行才会执行action(没有指定action，默认输出每行的内容)。</span></span><br><span class="line"></span><br><span class="line">2. 搜索支持正则，例如找root开头的: awk -F:  <span class="string">'/^root/'</span>  /etc/passwd</span><br><span class="line"><span class="comment"># 搜索/etc/passwd有root关键字的所有行，并显示对应的shell</span></span><br><span class="line">root@cts1:~ </span><br><span class="line"><span class="comment"># awk  -F ':'  '/root/&#123;print $7&#125;'  /etc/passwd</span></span><br><span class="line">/bin/zsh</span><br><span class="line">/sbin/nologin</span><br><span class="line"></span><br><span class="line"><span class="comment"># 这里指定了action&#123;print $7&#125;</span></span><br></pre></td></tr></table></figure></li><li><p><strong>awk常见内置变量</strong></p><blockquote><p>FILENAME：awk浏览的文件名</p><p>FNR：浏览文件的记录数，也就是行数。awk是以行为单位处理的，所以每行就是一个记录</p><p>NR：awk读取文件每行内容时的行号</p><p>NF：浏览记录的域的个数。可以用它来输出最后一个域</p><p>FS：设置输入域分隔符，等价于命令行-F选项</p><p>OFS：输出域分隔符</p></blockquote><p>统计/etc/passwd:文件名，每行的行号，每行的列数，对应的完整行内容 </p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">root@cts1:~ <span class="comment"># awk  -F ':'  '&#123;print "filename:" FILENAME ",linenumber:" NR ",columns:" NF ",linecontent:"$0&#125;' /etc/passwd</span></span><br><span class="line">---</span><br><span class="line">filename:/etc/passwd,linenumber:1,columns:7,linecontent:root:x:0:0:root:/root:/bin/zsh</span><br><span class="line">filename:/etc/passwd,linenumber:2,columns:7,linecontent:bin:x:1:1:bin:/bin:/sbin/nologin</span><br></pre></td></tr></table></figure><p>使用printf替代print,可以让代码更加简洁，易读 </p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">root@cts1:~ <span class="comment">#  awk  -F ':'  '&#123;printf("filename:%s,linenumber:%s,columns:%s,linecontent:%s\n",FILENAME,NR,NF,$0)&#125;' /etc/passwd</span></span><br><span class="line">---</span><br><span class="line">filename:/etc/passwd,linenumber:1,columns:7,linecontent:root:x:0:0:root:/root:/bin/zsh</span><br><span class="line">filename:/etc/passwd,linenumber:2,columns:7,linecontent:bin:x:1:1:bin:/bin:/sbin/nologin</span><br></pre></td></tr></table></figure><p>指定输入分隔符，指定输出分隔符： </p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">root@cts1:~ <span class="comment"># awk 'BEGIN &#123;FS=":"; OFS="\t"&#125; &#123;print $1, $2&#125;' /etc/passwd</span></span><br><span class="line">---</span><br><span class="line">rootx</span><br><span class="line">binx</span><br><span class="line">...</span><br></pre></td></tr></table></figure></li><li><p><strong>实用例子</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># A：打印最后一列：</span></span><br><span class="line">awk -F: <span class="string">'&#123;print $NF&#125;'</span> /etc/passwd</span><br><span class="line">awk -F: <span class="string">'&#123;printf("%s\n",$NF);&#125;'</span> /etc/passwd</span><br><span class="line"></span><br><span class="line"><span class="comment"># B：统计文件行数：</span></span><br><span class="line">awk <span class="string">'BEGIN &#123;x=0&#125; &#123;x++&#125; END &#123;print x&#125;'</span> /etc/passwd</span><br><span class="line"></span><br><span class="line"><span class="comment"># C：打印9*9乘法表：</span></span><br><span class="line">awk <span class="string">'BEGIN&#123;for(n=0;n++&lt;9;)&#123;for(i=0;i++&lt;n;)printf i"*"n"="i*n" ";print ""&#125;&#125;'</span></span><br><span class="line">awk <span class="string">'BEGIN &#123;for(i=1;i&lt;=9;i++)&#123;for(j=1;j&lt;=i;j++)&#123;printf i"*"j"="i*j" ";&#125;print ""&#125;&#125;'</span></span><br><span class="line">awk <span class="string">'BEGIN &#123;for(i=9;i&gt;=1;i--)&#123;for(j=i;j&gt;=1;j--)&#123;printf i"*"j"="i*j" ";&#125;print ""&#125;&#125;'</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># D: 计算1-100 之和</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"sum"</span> | awk <span class="string">'BEGIN &#123;sum=0;&#125; &#123;i=0;while(i&lt;101)&#123;sum+=i;i++&#125;&#125; END &#123;print sum&#125;'</span></span><br></pre></td></tr></table></figure></li><li><p><a href="http://www.gnu.org/software/gawk/manual/gawk.html" target="_blank" rel="noopener">更多详细用法参见官网</a></p></li></ol><h2 id="find"><a href="#find" class="headerlink" title="find"></a>find</h2><p>功能： 搜索文件目录层次结构</p><p>格式： find path -option actions</p><p><strong>find &lt;路径&gt; &lt;选项&gt; [表达式]</strong></p><h3 id="常用可选项："><a href="#常用可选项：" class="headerlink" title="常用可选项："></a>常用可选项：</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">-name 根据文件名查找，支持(\<span class="string">'\* \'</span> , \<span class="string">'? \'</span>)</span><br><span class="line"></span><br><span class="line">-<span class="built_in">type</span> 根据文件类型查找(f-普通文件，c-字符设备文件，b-块设备文件，l-链接文件，d-目录)</span><br><span class="line"></span><br><span class="line">-perm 根据文件的权限查找，比如 755</span><br><span class="line"></span><br><span class="line">-user 根据文件拥有者查找</span><br><span class="line"></span><br><span class="line">-group 根据文件所属组寻找文件</span><br><span class="line"></span><br><span class="line">-size 根据文件小大寻找文件</span><br><span class="line"> </span><br><span class="line">-o 表达式 或</span><br><span class="line"></span><br><span class="line">-a 表达式 与</span><br><span class="line"></span><br><span class="line">-not 表达式 非</span><br></pre></td></tr></table></figure><h3 id="类型参数列表："><a href="#类型参数列表：" class="headerlink" title="类型参数列表："></a>类型参数列表：</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">- **f**  普通文件</span><br><span class="line">- **l**  符号连接</span><br><span class="line">- **d**  目录</span><br><span class="line">- **c**  字符设备</span><br><span class="line">- **b**  块设备</span><br><span class="line">- **s**  套接字</span><br><span class="line">- **p**  Fifo</span><br></pre></td></tr></table></figure><h3 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line">[linux@linux txt]$ ll   <span class="comment">## 准备的测试文件</span></span><br><span class="line">total 248</span><br><span class="line">-rw-rw-r--. 1 linux linux 235373 Apr 18 00:10 hw.txt</span><br><span class="line">-rw-rw-r--. 1 linux linux      0 Apr 22 05:43 LINUX.pdf</span><br><span class="line">-rw-rw-r--. 1 linux linux      3 Apr 22 05:50 liujialing.jpg</span><br><span class="line">-rw-rw-r--. 1 linux linux      0 Apr 22 05:43 mingxing.pdf</span><br><span class="line">-rw-rw-r--. 1 linux linux     57 Apr 22 04:40 mingxing.txt</span><br><span class="line">-rw-rw-r--. 1 linux linux     66 Apr 22 05:15 sort.txt</span><br><span class="line">-rw-rw-r--. 1 linux linux    214 Apr 18 10:08 test.txt</span><br><span class="line">-rw-rw-r--. 1 linux linux     24 Apr 22 05:27 uniq.txt</span><br><span class="line"></span><br><span class="line">[linux@linux txt]$ find /home/linux/txt/ -name <span class="string">"*.txt"</span>  <span class="comment">## 查找文件名txt结尾的文件</span></span><br><span class="line">/home/linux/txt/uniq.txt</span><br><span class="line">/home/linux/txt/mingxing.txt</span><br><span class="line">/home/linux/txt/test.txt</span><br><span class="line">/home/linux/txt/hw.txt</span><br><span class="line">/home/linux/txt/sort.txt</span><br><span class="line"></span><br><span class="line"><span class="comment">## 忽略大小写查找文件名包含linux</span></span><br><span class="line">[linux@linux txt]$ find /home/linux/txt -iname <span class="string">"*linux*"</span>  </span><br><span class="line">/home/linux/txt/LINUX.pdf</span><br><span class="line"></span><br><span class="line"><span class="comment">## 查找文件名结尾是.txt或者.jpg的文件</span></span><br><span class="line">[linux@linux txt]$ find /home/linux/txt/ \( -name <span class="string">"*.txt"</span> -o -name <span class="string">"*.jpg"</span> \)   </span><br><span class="line">/home/linux/txt/liujialing.jpg</span><br><span class="line">/home/linux/txt/uniq.txt</span><br><span class="line">/home/linux/txt/mingxing.txt</span><br><span class="line">/home/linux/txt/test.txt</span><br><span class="line">/home/linux/txt/hw.txt</span><br><span class="line">/home/linux/txt/sort.txt</span><br><span class="line">另一种写法：find /home/linux/txt/ -name <span class="string">"*.txt"</span> -o -name <span class="string">"*.jpg"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用正则表达式的方式去查找上面条件的文件：</span></span><br><span class="line">[linux@linux txt]$ find /home/linux/txt/ -regex <span class="string">".*\(\.txt\|\.jpg\)$"</span></span><br><span class="line">/home/linux/txt/liujialing.jpg</span><br><span class="line">/home/linux/txt/uniq.txt</span><br><span class="line">/home/linux/txt/mingxing.txt</span><br><span class="line">/home/linux/txt/test.txt</span><br><span class="line">/home/linux/txt/hw.txt</span><br><span class="line">/home/linux/txt/sort.txt</span><br><span class="line"></span><br><span class="line"><span class="comment">## 查找.jpg结尾的文件，然后删掉</span></span><br><span class="line">[linux@linux txt]$ find /home/linux/txt -<span class="built_in">type</span> f -name <span class="string">"*.jpg"</span> -delete</span><br><span class="line">[linux@linux txt]$ ll</span><br><span class="line">total 248</span><br><span class="line">-rw-rw-r--. 1 linux linux 235373 Apr 18 00:10 hw.txt</span><br><span class="line">-rw-rw-r--. 1 linux linux      0 Apr 22 05:43 LINUX.pdf</span><br><span class="line">-rw-rw-r--. 1 linux linux      0 Apr 22 05:43 mingxing.pdf</span><br><span class="line">-rw-rw-r--. 1 linux linux     57 Apr 22 04:40 mingxing.txt</span><br><span class="line">-rw-rw-r--. 1 linux linux     66 Apr 22 05:15 sort.txt</span><br><span class="line">-rw-rw-r--. 1 linux linux    214 Apr 18 10:08 test.txt</span><br><span class="line">-rw-rw-r--. 1 linux linux     24 Apr 22 05:27 uniq.txt</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">## 查找5天以内创建的 .sh 文件, 并显示创建/更改时间</span></span><br><span class="line">find / -name <span class="string">"*sh"</span> -mtime -5 |xargs ls -l</span><br></pre></td></tr></table></figure><h1 id="3-Shell操作字符串"><a href="#3-Shell操作字符串" class="headerlink" title="3.  Shell操作字符串"></a>3.  Shell操作字符串</h1><h2 id="字符串截取"><a href="#字符串截取" class="headerlink" title="字符串截取"></a>字符串截取</h2><p>Linux中操作字符串，也是一项必备的技能。其中尤以截取字符串更加频繁，下面为大家介绍几种常用方式，截取字符串</p><p><strong>预先定义一个变量</strong>：WEBSITE=’<a href="http://hadoop//centos/huangbo.html&#39;" target="_blank" rel="noopener">http://hadoop//centos/huangbo.html&#39;</a> </p><ol><li><p><strong>#截取，*任意的,   删除<code>//</code>左边字符串（包括制定的分隔符），保留右边字符串</strong></p><blockquote><p>root@cts1:~ # echo ${WEBSITE#*//}<br>hadoop//centos/huangbo.html</p></blockquote></li><li><p><strong>##截取</strong>，<strong>删除左边字符串（包括指定的分隔符），保留右边字符串</strong>，和上边一个#不同的是，它一直找到最后，而不是像一个#那样找到一个就满足条件退出了。</p><blockquote><p>root@cts1:~ # echo ${WEBSITE##*//}<br>centos/huangbo.html</p></blockquote></li><li><p><strong>%截取，删除右边字符串（包括制定的分隔符），保留左边字符串</strong></p><blockquote><p>root@cts1:~ # echo ${WEBSITE%//*}<br><a href="http://hadoop" target="_blank" rel="noopener">http://hadoop</a></p></blockquote></li><li><p><strong>%%截取，删除右边字符串（包括指定的分隔符），保留左边字符串</strong>，和上边一个%不同的是，它一直找到最前，而不是像一个%那样找到一个就满足条件退出了。</p><blockquote><p>root@cts1:~ # echo ${WEBSITE%%//*}<br>http:</p></blockquote></li><li><p>从左边第几个字符开始，以及截取的字符的个数 </p><blockquote><p>root@cts1:~ # echo ${WEBSITE:2:2}<br>tp</p></blockquote></li><li><p>从左边第几个字符开始，一直到结束 </p><blockquote><p>root@cts1:~ # echo ${WEBSITE:2}<br>tp://hadoop//centos/huangbo.html</p></blockquote></li><li><p>从右边第几个字符开始，以及字符的个数, 从-4开始, 还是往右边截取 </p><blockquote><p>root@cts1:~ # echo ${WEBSITE:0-4:2</p><p>ht</p></blockquote></li><li><p>从右边第几个字符开始，一直到结束 </p><blockquote><p>root@cts1:~ # echo ${WEBSITE:0-4}<br>html</p></blockquote></li><li><p>利用awk进行字符串截取</p><blockquote><p><strong>echo $WEBSITE | awk ‘{print substr($1,2,6)}’</strong> </p><p>ttp://</p></blockquote></li><li><p>利用cut进行字符串截取 </p><blockquote><p>root@cts1:~ # echo $WEBSITE | cut -b 1-4                                                    http</p></blockquote></li><li><p>获取最后几个字符</p><blockquote><p>root@cts1:~ #  echo ${WEBSITE:(-3)}                                                           tml</p></blockquote></li><li><p>截取从倒数第3个字符后的2个字符</p><blockquote><p>root@cts1:~ # echo ${WEBSITE:(-3):2}<br>tm</p></blockquote></li></ol><h2 id="字符串替换"><a href="#字符串替换" class="headerlink" title="字符串替换"></a>字符串替换</h2><h4 id="使用格式"><a href="#使用格式" class="headerlink" title="使用格式"></a>使用格式</h4><blockquote><p><strong>${parameter/pattern/string}</strong> </p></blockquote><h4 id="例子-1"><a href="#例子-1" class="headerlink" title="例子"></a>例子</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义变量VAR：</span></span><br><span class="line">[linux@linux ~]$ VAR=<span class="string">"hello tom, hello kitty, hello xiaoming"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 替换第一个hello,  用`/`：</span></span><br><span class="line">[linux@linux ~]$ <span class="built_in">echo</span> <span class="variable">$&#123;VAR/hello/hi&#125;</span></span><br><span class="line">hi tom, hello kitty, hello xiaoming</span><br><span class="line"></span><br><span class="line"><span class="comment"># 替换所有hello, 用'//'：</span></span><br><span class="line">[linux@linux ~]$ <span class="built_in">echo</span> <span class="variable">$&#123;VAR//hello/hi&#125;</span></span><br><span class="line">hi tom, hi kitty, hi xiaoming</span><br></pre></td></tr></table></figure><h2 id="获取字符串长度"><a href="#获取字符串长度" class="headerlink" title="获取字符串长度"></a>获取字符串长度</h2><p>在此为大家提供五种方式获取某字符串的长度 </p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在此为大家提供五种方式获取某字符串的长度</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 1. 使用wc -L命令</span></span><br><span class="line">+----------------------------------------------------+</span><br><span class="line">| <span class="built_in">echo</span> <span class="variable">$&#123;WEBSITE&#125;</span> |wc -L    |</span><br><span class="line">|                                                    |</span><br><span class="line">| 35                                                 |</span><br><span class="line">+----------------------------------------------------+</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. 使用expr的方式去计算</span></span><br><span class="line">+---------------------------------------------------+</span><br><span class="line">| expr length <span class="variable">$&#123;WEBSITE&#125;</span>  |</span><br><span class="line">|                                                   |</span><br><span class="line">| 35                                                |</span><br><span class="line">+---------------------------------------------------+</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3. 通过awk + length的方式获取字符串长度</span></span><br><span class="line">+---------------------------------------------------------------------------+</span><br><span class="line">|<span class="built_in">echo</span> <span class="variable">$&#123;WEBSITE&#125;</span> | awk <span class="string">'&#123;print length($0)&#125;'</span>    |</span><br><span class="line">|                                                                           |</span><br><span class="line">| 35                                                                        |</span><br><span class="line">+---------------------------------------------------------------------------+</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4. 通过awk的方式计算以**\"\"**分隔的字段个数</span></span><br><span class="line">+-------------------------------------------------------------------------+</span><br><span class="line">|  <span class="built_in">echo</span> <span class="variable">$&#123;WEBSITE&#125;</span> |awk -F <span class="string">""</span> <span class="string">'&#123;print NF&#125;'</span>     |</span><br><span class="line">|                                                                         |</span><br><span class="line">| 35                                                                      |</span><br><span class="line">+-------------------------------------------------------------------------+</span><br><span class="line"></span><br><span class="line"><span class="comment"># 5. 通过\#的方式获取字符串（最简单，最常用）</span></span><br><span class="line">+----------------------------------------------+</span><br><span class="line">| <span class="built_in">echo</span> <span class="variable">$&#123;#WEBSITE&#125;</span> |</span><br><span class="line">|                                              |</span><br><span class="line">| 35                                           |</span><br><span class="line">+----------------------------------------------+</span><br></pre></td></tr></table></figure><h1 id="4-脚本自动安装MySql"><a href="#4-脚本自动安装MySql" class="headerlink" title="4. 脚本自动安装MySql"></a>4. 脚本自动安装MySql</h1><h4 id="这里先做个记录-之后会整理一份更详细的文档出来"><a href="#这里先做个记录-之后会整理一份更详细的文档出来" class="headerlink" title="这里先做个记录, 之后会整理一份更详细的文档出来."></a>这里先做个记录, 之后会整理一份更详细的文档出来.</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## auto install mysql</span></span><br><span class="line"><span class="comment">## 假如是第二次装，那么要先停掉服务，并且卸载之前的mysql</span></span><br><span class="line">service mysql stop</span><br><span class="line">EXISTS_RPMS=`rpm -qa | grep -i mysql`</span><br><span class="line"><span class="built_in">echo</span> <span class="variable">$&#123;EXISTS_RPMS&#125;</span></span><br><span class="line"><span class="keyword">for</span> RPM <span class="keyword">in</span> <span class="variable">$&#123;EXISTS_RPMS&#125;</span></span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">        rpm -e --nodeps <span class="variable">$&#123;RPM&#125;</span></span><br><span class="line"><span class="keyword">done</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## 删除残留文件</span></span><br><span class="line">rm -fr /usr/lib/mysql</span><br><span class="line">rm -fr /usr/include/mysql</span><br><span class="line">rm -f /etc/my.cnf</span><br><span class="line">rm -fr /var/lib/mysql</span><br><span class="line"></span><br><span class="line"><span class="comment">## 从服务器获取安装mysql的rpm包</span></span><br><span class="line">wget http://linux/soft/MySQL-client-5.6.26-1.linux_glibc2.5.x86_64.rpm</span><br><span class="line">wget http://linux/soft/MySQL-server-5.6.26-1.linux_glibc2.5.x86_64.rpm</span><br><span class="line"></span><br><span class="line"><span class="comment">## 删除之前的密码文件，以免产生干扰</span></span><br><span class="line">rm -rf /root/.mysql_secret</span><br><span class="line"></span><br><span class="line"><span class="comment">## 安装服务器</span></span><br><span class="line">rpm -ivh MySQL-server-5.6.26-1.linux_glibc2.5.x86_64.rpm</span><br><span class="line"></span><br><span class="line"><span class="comment">## 获取到生成的随机密码</span></span><br><span class="line"><span class="comment">##PSWD=`cat /root/.mysql_secret | awk -F ':' '&#123;print substr($4,2,16)&#125;'`</span></span><br><span class="line">PSWD=` grep -v <span class="string">'^$'</span> /root/.mysql_secret | awk -F <span class="string">':'</span> <span class="string">'&#123;print substr($4,2,16)&#125;'</span>`</span><br><span class="line"><span class="comment">##PSWD=$&#123;PWD:1:16&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## 安装客户端</span></span><br><span class="line">rpm -ivh MySQL-client-5.6.26-1.linux_glibc2.5.x86_64.rpm</span><br><span class="line"></span><br><span class="line"><span class="comment">## 然后删除刚刚下下来的rpm包</span></span><br><span class="line">rm -rf MySQL-client-5.6.26-1.linux_glibc2.5.x86_64.rpm</span><br><span class="line">rm -rf MySQL-server-5.6.26-1.linux_glibc2.5.x86_64.rpm</span><br><span class="line"></span><br><span class="line"><span class="comment">## 提示安装的步骤都完成了。</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"install mysql server and client is done .!!!!!!"</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## 打印出来刚刚生成的mysql初始密码</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"random password is:<span class="variable">$&#123;PSWD&#125;</span>"</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## 开启mysql服务</span></span><br><span class="line">service mysql start</span><br><span class="line"></span><br><span class="line"><span class="comment"># 手动第一次登陆，然后改掉密码</span></span><br><span class="line">[root@hadoop bin]<span class="comment"># mysql -uroot -pZjVIWvOGD18bT7oX</span></span><br><span class="line">mysql&gt; <span class="built_in">set</span> PASSWORD=PASSWORD(<span class="string">'root'</span>);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 现在就可以写脚本链接mysql进行操作了</span></span><br><span class="line">[root@hadoop bin]<span class="comment"># vi initMysql.sh</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"></span><br><span class="line">mysql -uroot -proot &lt;&lt; EOF</span><br><span class="line">       GRANT ALL PRIVILEGES ON *.* TO <span class="string">'root'</span>@<span class="string">'%'</span> IDENTIFIED BY <span class="string">'root'</span> WITH GRANT OPTION;</span><br><span class="line">       FLUSH PRIVILEGES;</span><br><span class="line">       use mysql;</span><br><span class="line">       select host, user, password from user;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;1-Shell操作日期时间&quot;&gt;&lt;a href=&quot;#1-Shell操作日期时间&quot; class=&quot;headerlink&quot; title=&quot;1.Shell操作日期时间&quot;&gt;&lt;/a&gt;1.Shell操作日期时间&lt;/h1&gt;&lt;h2 id=&quot;date&quot;&gt;&lt;a href=&quot;#date&quot;
      
    
    </summary>
    
      <category term="Linux" scheme="https://airpoet.github.io/categories/Linux/"/>
    
      <category term="学习笔记" scheme="https://airpoet.github.io/categories/Linux/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="原创" scheme="https://airpoet.github.io/tags/%E5%8E%9F%E5%88%9B/"/>
    
      <category term="技术" scheme="https://airpoet.github.io/tags/%E6%8A%80%E6%9C%AF/"/>
    
      <category term="Linux" scheme="https://airpoet.github.io/tags/Linux/"/>
    
  </entry>
  
</feed>
